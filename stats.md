# Model Stats
## New Models
- https://replicate.com/zerlowin/air_france
- https://replicate.com/buovier94/flux_stevenespinoza
- https://replicate.com/klovistore2/mini-pinscher
- https://replicate.com/unidigitalnews/fluxlora
- https://replicate.com/crivera/sketch-lora
- https://replicate.com/omarprama/hcwt2
- https://replicate.com/treebridge83/luke-lora
- https://replicate.com/omarprama/hcw-t
- https://replicate.com/tokaito14/color
- https://replicate.com/hexiaochun/minicpm_v26
- https://replicate.com/advaitchauhan/lucheng
- https://replicate.com/lucataco/flux-time100
- https://replicate.com/swaylou/flux1
- https://replicate.com/davisbrown/designer-architecture
- https://replicate.com/tokaito14/laura
- https://replicate.com/tokaito14/fullbody
- https://replicate.com/dcamsdev/klm-lora-flux
- https://replicate.com/juliananev/frutiger-aero

## Removed Models
- https://replicate.com/camenduru/hairfastgan

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [zerlowin/air_france](https://replicate.com/zerlowin/air_france) | null | 4 | 4 | 100.00% |
| [buovier94/flux_stevenespinoza](https://replicate.com/buovier94/flux_stevenespinoza) | null | 38 | 38 | 100.00% |
| [klovistore2/mini-pinscher](https://replicate.com/klovistore2/mini-pinscher) | A flux model trained on a dog | 24 | 24 | 100.00% |
| [unidigitalnews/fluxlora](https://replicate.com/unidigitalnews/fluxlora) | Use "Albert" as a Trigger-Word to create images with Albert Einstein. For Example "Albert as a businessman" | 21 | 21 | 100.00% |
| [crivera/sketch-lora](https://replicate.com/crivera/sketch-lora) | Create pencil sketches of anything | 6 | 6 | 100.00% |
| [omarprama/hcwt2](https://replicate.com/omarprama/hcwt2) | null | 2 | 2 | 100.00% |
| [treebridge83/luke-lora](https://replicate.com/treebridge83/luke-lora) | null | 11 | 11 | 100.00% |
| [omarprama/hcw-t](https://replicate.com/omarprama/hcw-t) | null | 2 | 2 | 100.00% |
| [tokaito14/color](https://replicate.com/tokaito14/color) | white model | 6 | 6 | 100.00% |
| [hexiaochun/minicpm_v26](https://replicate.com/hexiaochun/minicpm_v26) | minicpm 视频理解 | 37 | 37 | 100.00% |
| [advaitchauhan/lucheng](https://replicate.com/advaitchauhan/lucheng) | null | 11 | 11 | 100.00% |
| [lucataco/flux-time100](https://replicate.com/lucataco/flux-time100) | Flux finetune of the style: TIMES 100 Most Influential People in AI | 93 | 93 | 100.00% |
| [swaylou/flux1](https://replicate.com/swaylou/flux1) | null | 15 | 15 | 100.00% |
| [davisbrown/designer-architecture](https://replicate.com/davisbrown/designer-architecture) | Create professional architecture and interior designs | 71 | 71 | 100.00% |
| [tokaito14/laura](https://replicate.com/tokaito14/laura) | Model | 15 | 15 | 100.00% |
| [tokaito14/fullbody](https://replicate.com/tokaito14/fullbody) | Model | 9 | 9 | 100.00% |
| [dcamsdev/klm-lora-flux](https://replicate.com/dcamsdev/klm-lora-flux) | Creates realistic KLM flight attendants | 90 | 90 | 100.00% |
| [juliananev/frutiger-aero](https://replicate.com/juliananev/frutiger-aero) | null | 119 | 119 | 100.00% |
| [0xdeadd/bijay](https://replicate.com/0xdeadd/bijay) | A fine-tuned FLUX.1 model | 12 | 13 | 92.31% |
| [roelfrenkema/flux1.lora.zelenskyy](https://replicate.com/roelfrenkema/flux1.lora.zelenskyy) | On of my heroes and someone who will go into history as one. | 16 | 20 | 80.00% |
| [0xtuba/archillect-lora](https://replicate.com/0xtuba/archillect-lora) | Generates images in the style of Archillect | 220 | 283 | 77.74% |
| [levelsio/neon-tokyo](https://replicate.com/levelsio/neon-tokyo) | Take photos in the style of rainy Tokyo nights with neon lights | 333 | 429 | 77.62% |
| [paulccote/old-school-3d-renders](https://replicate.com/paulccote/old-school-3d-renders) | Creates an image in the style of an old school 3D render. Prefix: "An old school 3D render of". Suffix: "in the style of 3DRNDR" | 51 | 67 | 76.12% |
| [dunaevai135/tst_agt](https://replicate.com/dunaevai135/tst_agt) | null | 59 | 84 | 70.24% |
| [roelfrenkema/flux1.lora.kamalaharris](https://replicate.com/roelfrenkema/flux1.lora.kamalaharris) | Could just be the saviour of American democracy | 7 | 12 | 58.33% |
| [mikeei/dolphin-2.9-llama3-8b-gguf](https://replicate.com/mikeei/dolphin-2.9-llama3-8b-gguf) | Dolphin is uncensored. I have filtered the dataset to remove alignment and bias. This makes the model more compliant. | 661 | 1199 | 55.13% |
| [warf23/ai_glasses](https://replicate.com/warf23/ai_glasses) | null | 19 | 39 | 48.72% |
| [roelfrenkema/flux1.lora.donaldtrump](https://replicate.com/roelfrenkema/flux1.lora.donaldtrump) | Numer 1 in my gallery of dicators | 18 | 38 | 47.37% |
| [roelfrenkema/flux1.lora.gretathunberg](https://replicate.com/roelfrenkema/flux1.lora.gretathunberg) | The first Gen-Z hero IMHO. Go Greta | 3 | 7 | 42.86% |
| [aodianyun/qwen2-vl-7b](https://replicate.com/aodianyun/qwen2-vl-7b) | null | 3 | 7 | 42.86% |
| [simonheese/flux-thefinger](https://replicate.com/simonheese/flux-thefinger) | For my AI punk band The Buttredettes I wanted the option to generate images where they show the finger. This gesture is either censored in all major models or not trained. This lora should fix it. It's not working all the time, but more often than not. | 27 | 67 | 40.30% |
| [juniorsavoretti/santisavoretti](https://replicate.com/juniorsavoretti/santisavoretti) | null | 118 | 326 | 36.20% |
| [aodianyun/qwen2-vl-2b](https://replicate.com/aodianyun/qwen2-vl-2b) | null | 1 | 3 | 33.33% |
| [fofr/flux-wrong](https://replicate.com/fofr/flux-wrong) | Flux lora, use “WRNG” to trigger image generation | 90 | 274 | 32.85% |
| [bishorahu/prajwal](https://replicate.com/bishorahu/prajwal) | null | 18 | 56 | 32.14% |
| [roelfrenkema/flux1.lora.elonmusk](https://replicate.com/roelfrenkema/flux1.lora.elonmusk) | Dope brain malfunction. | 3 | 10 | 30.00% |
| [cddietz/michael](https://replicate.com/cddietz/michael) | null | 52 | 177 | 29.38% |
| [rainer1966-de/flux_rainer](https://replicate.com/rainer1966-de/flux_rainer) | null | 43 | 148 | 29.05% |
| [cristobalascencio/florentino](https://replicate.com/cristobalascencio/florentino) | null | 15 | 54 | 27.78% |
| [carlpuvosx/cerveza-presidente](https://replicate.com/carlpuvosx/cerveza-presidente) | null | 3 | 11 | 27.27% |
| [igorriti/flux-360](https://replicate.com/igorriti/flux-360) | Generate 360 panorama images | 51 | 198 | 25.76% |
| [fofr/flux-minecraft-movie](https://replicate.com/fofr/flux-minecraft-movie) | Flux lora, use "MNCRFTMOV" to trigger image generation | 135 | 527 | 25.62% |
| [lucataco/ollama-reflection-70b](https://replicate.com/lucataco/ollama-reflection-70b) | Ollama Reflection 70b | 60 | 238 | 25.21% |
| [sigil-wen/flux-ada-cyborg-style](https://replicate.com/sigil-wen/flux-ada-cyborg-style) | null | 2 | 8 | 25.00% |
| [omarprama/parfum](https://replicate.com/omarprama/parfum) | null | 2 | 8 | 25.00% |
| [advoworks/jacksonhuman](https://replicate.com/advoworks/jacksonhuman) | null | 5 | 20 | 25.00% |
| [marydotdev/sdxl-bb](https://replicate.com/marydotdev/sdxl-bb) | sdxl trained on bobs burgers | 137 | 563 | 24.33% |
| [advaitchauhan/amelia-woman](https://replicate.com/advaitchauhan/amelia-woman) | null | 4 | 17 | 23.53% |
| [vetkastar/comfy-flux](https://replicate.com/vetkastar/comfy-flux) | comfy with flux model, | 71 | 330 | 21.52% |
| [kazdatahelp/azhrq](https://replicate.com/kazdatahelp/azhrq) | null | 3 | 14 | 21.43% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [bytedance/sdxl-lightning-4step](https://replicate.com/bytedance/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 2576004 |
| [black-forest-labs/flux-schnell](https://replicate.com/black-forest-labs/flux-schnell) | The fastest image generation model tailored for local development and personal use | 1143641 |
| [falcons-ai/nsfw_image_detection](https://replicate.com/falcons-ai/nsfw_image_detection) | Falcons.ai Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 284084 |
| [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct) | An 8 billion parameter language model from Meta, fine tuned for chat completions | 259107 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 172052 |
| [meta/meta-llama-3-70b-instruct](https://replicate.com/meta/meta-llama-3-70b-instruct) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 133976 |
| [black-forest-labs/flux-pro](https://replicate.com/black-forest-labs/flux-pro) | State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. | 112114 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Generate image captions | 107975 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 97318 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 57792 |
| [black-forest-labs/flux-dev](https://replicate.com/black-forest-labs/flux-dev) | A 12 billion parameter rectified flow transformer capable of generating images from text descriptions | 38023 |
| [datacte/proteus-v0.2](https://replicate.com/datacte/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 34461 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 34443 |
| [lucataco/hyper-flux-8step](https://replicate.com/lucataco/hyper-flux-8step) | Hyper FLUX 8-step by ByteDance | 32766 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 32268 |
| [datacte/proteus-v0.3](https://replicate.com/datacte/proteus-v0.3) | ProteusV0.3: The Anime Update | 31251 |
| [yorickvp/llava-v1.6-mistral-7b](https://replicate.com/yorickvp/llava-v1.6-mistral-7b) | LLaVA v1.6: Large Language and Vision Assistant (Mistral-7B) | 30036 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 29649 |
| [mistralai/mixtral-8x7b-instruct-v0.1](https://replicate.com/mistralai/mixtral-8x7b-instruct-v0.1) | The Mixtral-8x7B-instruct-v0.1 Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts tuned to be a helpful assistant. | 29399 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 29164 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 22348 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x | 22069 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 20988 |
| [meta/meta-llama-3.1-405b-instruct](https://replicate.com/meta/meta-llama-3.1-405b-instruct) | Meta's flagship 405 billion parameter language model, fine-tuned for chat completions | 20829 |
| [smoretalk/rembg-enhance](https://replicate.com/smoretalk/rembg-enhance) | A background removal model enhanced with ViTMatte. | 20644 |
| [lucataco/juggernaut-xl-v9](https://replicate.com/lucataco/juggernaut-xl-v9) | Juggernaut XL v9 | 17831 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 16767 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 16229 |
| [lucataco/realistic-vision-v5.1](https://replicate.com/lucataco/realistic-vision-v5.1) | Implementation of Realistic Vision v5.1 with VAE | 15283 |
| [lucataco/flux-dev-lora](https://replicate.com/lucataco/flux-dev-lora) | FLUX.1-Dev LoRA explorer | 14110 |
| [yorickvp/llava-v1.6-vicuna-13b](https://replicate.com/yorickvp/llava-v1.6-vicuna-13b) | LLaVA v1.6: Large Language and Vision Assistant (Vicuna-13B) | 13842 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 12681 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | 🦙 LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 11115 |
| [omniedgeio/face-swap](https://replicate.com/omniedgeio/face-swap) | Face Swap | 10953 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 9749 |
| [mejiabrayan/logoai](https://replicate.com/mejiabrayan/logoai) | null | 9492 |
| [playgroundai/playground-v2.5-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 9390 |
| [lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) | FLUX.1-Dev Multi LoRA Explorer | 9231 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 9092 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 8861 |
| [xiankgx/face-swap](https://replicate.com/xiankgx/face-swap) | null | 8023 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! 🤗 | 7985 |
| [smoretalk/clip-interrogator-turbo](https://replicate.com/smoretalk/clip-interrogator-turbo) | @pharmapsychotic 's CLIP-Interrogator, but 3x faster and more accurate. Specialized on SDXL. | 7791 |
| [fofr/consistent-character](https://replicate.com/fofr/consistent-character) | Create images of a given character in different poses | 7402 |
| [pharmapsychotic/clip-interrogator](https://replicate.com/pharmapsychotic/clip-interrogator) | The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art! | 6584 |
| [replicate/all-mpnet-base-v2](https://replicate.com/replicate/all-mpnet-base-v2) | This is a language model that can be used to obtain document embeddings suitable for downstream tasks like semantic search and clustering. | 6386 |
| [snowflake/snowflake-arctic-instruct](https://replicate.com/snowflake/snowflake-arctic-instruct) | An efficient, intelligent, and truly open-source language model | 6102 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 5898 |
| [zsxkib/pulid](https://replicate.com/zsxkib/pulid) | 📖 PuLID: Pure and Lightning ID Customization via Contrastive Alignment | 5866 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 5733 |
| [shreejalmaharjan-27/website-screenshot](https://replicate.com/shreejalmaharjan-27/website-screenshot) | Capture a website screenshot | 5615 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 5489 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 5279 |
| [stability-ai/stable-diffusion-3](https://replicate.com/stability-ai/stable-diffusion-3) | A text-to-image model with greatly improved performance in image quality, typography, complex prompt understanding, and resource-efficiency | 4719 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting developed by the HF Diffusers team | 4665 |
| [fofr/realvisxl-v3-multi-controlnet-lora](https://replicate.com/fofr/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 4147 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 4120 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 4115 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 4069 |
| [xlabs-ai/flux-dev-realism](https://replicate.com/xlabs-ai/flux-dev-realism) | FLUX.1-dev with XLabs-AI’s realism lora | 3866 |
| [asiryan/blue-pencil-xl-v2](https://replicate.com/asiryan/blue-pencil-xl-v2) | Blue Pencil XL v2 Model (Text2Img, Img2Img and Inpainting) | 3419 |
| [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) | Base version of Llama 3, an 8 billion parameter language model from Meta. | 3352 |
| [asiryan/counterfeit-xl-v2](https://replicate.com/asiryan/counterfeit-xl-v2) | Counterfeit XL v2 Model (Text2Img, Img2Img and Inpainting) | 3314 |
| [asiryan/anything-v4.5](https://replicate.com/asiryan/anything-v4.5) | Anything V4.5 Model (Text2Img, Img2Img and Inpainting) | 3301 |
| [bfirsh/segformer-b0-finetuned-ade-512-512](https://replicate.com/bfirsh/segformer-b0-finetuned-ade-512-512) | null | 3224 |
| [smoosh-sh/baby-mystic](https://replicate.com/smoosh-sh/baby-mystic) | Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent | 3133 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 3122 |
| [lucataco/flux-schnell-lora](https://replicate.com/lucataco/flux-schnell-lora) | FLUX.1-Schnell LoRA explorer | 3120 |
| [asiryan/meina-mix-v11](https://replicate.com/asiryan/meina-mix-v11) | Meina Mix V11 Model (Text2Img, Img2Img and Inpainting) | 3066 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 3037 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 3029 |
| [mchong6/jojogan](https://replicate.com/mchong6/jojogan) | JoJoGAN: One Shot Face Stylization | 3000 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 2794 |
| [meta/llama-2-70b-chat](https://replicate.com/meta/llama-2-70b-chat) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 2589 |
| [fofr/style-transfer](https://replicate.com/fofr/style-transfer) | Transfer the style of one image to another | 2480 |
| [swook/inspyrenet](https://replicate.com/swook/inspyrenet) | Segment foreground objects with high resolution and matting, using InSPyReNet | 2462 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ⚡️ Fast audio transcription | whisper large-v3 | speaker diarization | word & sentence level timestamps | prompt | hotwords | 2460 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 2456 |
| [pnyompen/sd-controlnet-lora](https://replicate.com/pnyompen/sd-controlnet-lora) | SD1.5 Canny controlnet with LoRA support. | 2419 |
| [lucataco/moondream2](https://replicate.com/lucataco/moondream2) | moondream2 is a small vision language model designed to run efficiently on edge devices | 2354 |
| [135arvin/my_comfyui](https://replicate.com/135arvin/my_comfyui) | Run comfyui with api | 2307 |
| [chenxwh/sdxl-flash](https://replicate.com/chenxwh/sdxl-flash) | Fast sdxl with higher quality | 2299 |
| [chenxwh/depth-anything-v2](https://replicate.com/chenxwh/depth-anything-v2) | Depth estimation with faster inference speed, fewer parameters, and higher depth accuracy. | 2281 |
| [mark3labs/embeddings-gte-base](https://replicate.com/mark3labs/embeddings-gte-base) | General Text Embeddings (GTE) model. | 2261 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 2203 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 2152 |
| [daanelson/imagebind](https://replicate.com/daanelson/imagebind) | A model for text, audio, and image embeddings in one space | 2152 |
| [mistralai/mistral-7b-instruct-v0.2](https://replicate.com/mistralai/mistral-7b-instruct-v0.2) | The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1. | 2139 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 2120 |
| [cuuupid/idm-vton](https://replicate.com/cuuupid/idm-vton) | Best-in-class clothing virtual try on in the wild (non-commercial use only) | 2116 |
| [batouresearch/sdxl-controlnet-lora](https://replicate.com/batouresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 2005 |
| [konieshadow/fooocus-api](https://replicate.com/konieshadow/fooocus-api) | Third party Fooocus replicate model | 1823 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 1811 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 1792 |
| [juergengunz/real-esrgan-v2](https://replicate.com/juergengunz/real-esrgan-v2) | Real-ESRGAN Upscale with AI Face Correction | 1767 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 1732 |
| [nateraw/video-llava](https://replicate.com/nateraw/video-llava) | Video-LLaVA: Learning United Visual Representation by Alignment Before Projection | 1728 |
| [pseudoram/rvc-v2](https://replicate.com/pseudoram/rvc-v2) | Speech to speech with any RVC v2 trained AI voice | 1685 |
| [ostris/flux-dev-lora-trainer](https://replicate.com/ostris/flux-dev-lora-trainer) | Fine-tune FLUX.1-dev using ai-toolkit | 1683 |
| [bingbangboom-lab/flux-dreamscape](https://replicate.com/bingbangboom-lab/flux-dreamscape) | Flux lora, use "BSstyle004" to trigger image generation | 1666 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 1659 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 1595 |
| [ardianfe/music-gen-fn-200e](https://replicate.com/ardianfe/music-gen-fn-200e) | Create music for your content | 1587 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 1578 |
| [batouresearch/magic-image-refiner](https://replicate.com/batouresearch/magic-image-refiner) | A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling. | 1435 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 1389 |
| [tomasmcm/llamaguard-7b](https://replicate.com/tomasmcm/llamaguard-7b) | Source: llamas-community/LlamaGuard-7b ✦ Quant: TheBloke/LlamaGuard-7B-AWQ ✦ Llama-Guard is a 7B parameter Llama 2-based input-output safeguard model | 1338 |
| [cjwbw/anything-v4.0](https://replicate.com/cjwbw/anything-v4.0) | high-quality, highly detailed anime-style Stable Diffusion models | 1279 |
| [camenduru/instantmesh](https://replicate.com/camenduru/instantmesh) | InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models | 1152 |
| [vetkastar/fooocus](https://replicate.com/vetkastar/fooocus) | Image generation, Added: inpaint_strength loras_custom_urls | 1143 |
| [fofr/any-comfyui-workflow](https://replicate.com/fofr/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/fofr/cog-comfyui | 1131 |
| [simbrams/segformer-b5-finetuned-ade-640-640](https://replicate.com/simbrams/segformer-b5-finetuned-ade-640-640) | Semantic Segmentation | 1111 |
| [yorickvp/llava-v1.6-34b](https://replicate.com/yorickvp/llava-v1.6-34b) | LLaVA v1.6: Large Language and Vision Assistant (Nous-Hermes-2-34B) | 1101 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 1101 |
| [pnyompen/sdxl-controlnet-lora-small](https://replicate.com/pnyompen/sdxl-controlnet-lora-small) | SDXL Canny controlnet with LoRA support. | 1065 |
| [pengdaqian2020/image-tagger](https://replicate.com/pengdaqian2020/image-tagger) | image tagger | 1040 |
| [adirik/interior-design](https://replicate.com/adirik/interior-design) | Realistic interior design with text and image inputs | 1018 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 1004 |
| [asiryan/juggernaut-xl-v7](https://replicate.com/asiryan/juggernaut-xl-v7) | Juggernaut XL v7 Model (Text2Img, Img2Img and Inpainting) | 982 |
| [zust-ai/supir](https://replicate.com/zust-ai/supir) | null | 948 |
| [simbrams/ri](https://replicate.com/simbrams/ri) | Realistic Inpainting with ControlNET (M-LSD + SEG) | 937 |
| [meta/llama-2-13b-chat](https://replicate.com/meta/llama-2-13b-chat) | A 13 billion parameter language model from Meta, fine tuned for chat completions | 928 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 923 |
| [mrhan1993/fooocus-api](https://replicate.com/mrhan1993/fooocus-api) | null | 919 |
| [logerzhu/ad-inpaint](https://replicate.com/logerzhu/ad-inpaint) | Product advertising image generator | 882 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 879 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 870 |
| [swartype/sdxl-pixar](https://replicate.com/swartype/sdxl-pixar) | Create Pixar poster easily with SDXL Pixar. | 868 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 848 |
| [fofr/pulid-base](https://replicate.com/fofr/pulid-base) | Use a face to make images. Uses SDXL fine-tuned checkpoints. | 833 |
| [shanginn/supir](https://replicate.com/shanginn/supir) | null | 825 |
| [tgohblio/instant-id-multicontrolnet](https://replicate.com/tgohblio/instant-id-multicontrolnet) | InstantID. ControlNets. More base SDXL models. And the latest ByteDance's ⚡️SDXL-Lightning !⚡️ | 811 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 802 |
| [usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5](https://replicate.com/usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5) | Inpainting || multi-controlnet || single-controlnet || ip-adapter || ip adapter face || ip adapter plus || No ip adapter | 799 |
| [okaris/omni-zero](https://replicate.com/okaris/omni-zero) | Omni-Zero: A diffusion pipeline for zero-shot stylized portrait creation. | 787 |
| [hnesk/whisper-wordtimestamps](https://replicate.com/hnesk/whisper-wordtimestamps) | openai/whisper with exposed settings for word_timestamps | 773 |
| [mcai/deliberate-v2](https://replicate.com/mcai/deliberate-v2) | Generate a new image given any input text with Deliberate v2 | 772 |
| [fofr/realvisxl-v3](https://replicate.com/fofr/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 766 |
| [zf-kbot/photo-to-anime](https://replicate.com/zf-kbot/photo-to-anime) | Convert images to anime style | 761 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 753 |
| [cuuupid/glm-4v-9b](https://replicate.com/cuuupid/glm-4v-9b) | GLM-4V is a multimodal model released by Tsinghua University that is competitive with GPT-4o and establishes a new SOTA on several benchmarks, including OCR. | 752 |
| [lucataco/ai-toolkit](https://replicate.com/lucataco/ai-toolkit) | Ostris AI-Toolkit for Flux LoRA Training MVP (Use ostris/flux-dev-lora-trainer) | 751 |
| [peter65374/sam-vit](https://replicate.com/peter65374/sam-vit) | SAM(Segment Anything) ViT-H image encoder | 748 |
| [adirik/t2i-adapter-sdxl-depth-midas](https://replicate.com/adirik/t2i-adapter-sdxl-depth-midas) | Modify images using depth maps | 737 |
| [levelsio/disposable-camera](https://replicate.com/levelsio/disposable-camera) | Take photos with a disposable camera. Like this? Use this with yourself in it on my app PhotoAI.com | 732 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 726 |
| [xlabs-ai/flux-dev-controlnet](https://replicate.com/xlabs-ai/flux-dev-controlnet) | XLabs v3 canny, depth and soft edge controlnets for Flux.1 Dev | 723 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 720 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 710 |
| [fofr/epicrealismxl-lightning-hades](https://replicate.com/fofr/epicrealismxl-lightning-hades) | Fast and high quality lightning model, epiCRealismXL-Lightning Hades | 703 |
| [jagilley/controlnet-depth2img](https://replicate.com/jagilley/controlnet-depth2img) | Modify images using depth maps | 694 |
| [fofr/latent-consistency-model](https://replicate.com/fofr/latent-consistency-model) | Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet | 680 |
| [zsxkib/ic-light](https://replicate.com/zsxkib/ic-light) | ✍️✨Prompts to auto-magically relights your images | 679 |
| [mserro/upscaler-pro](https://replicate.com/mserro/upscaler-pro) | AI Photorealistic Image Ultra-Resolution, Restoration and Upscale! | 678 |
| [chigozienri/mediapipe-face](https://replicate.com/chigozienri/mediapipe-face) | batch or individual face detection with mediapipe | 678 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 666 |
| [wolverinn/realistic-background](https://replicate.com/wolverinn/realistic-background) | replace background with Stable Diffusion and ControlNet | 664 |
| [mikeei/dolphin-2.9-llama3-8b-gguf](https://replicate.com/mikeei/dolphin-2.9-llama3-8b-gguf) | Dolphin is uncensored. I have filtered the dataset to remove alignment and bias. This makes the model more compliant. | 661 |
| [playgroundai/playground-v2-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2-1024px-aesthetic) | Playground v2 is a diffusion-based text-to-image generative model trained from scratch by the research team at Playground | 632 |
| [mcai/edge-of-realism-v2.0-img2img](https://replicate.com/mcai/edge-of-realism-v2.0-img2img) | Generate a new image from an input image with Edge Of Realism - EOR v2.0 | 601 |
| [prompthero/openjourney-v4](https://replicate.com/prompthero/openjourney-v4) | SD 1.5 trained with +124k MJv4 images by PromptHero | 574 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 573 |
| [batouresearch/high-resolution-controlnet-tile](https://replicate.com/batouresearch/high-resolution-controlnet-tile) | UPDATE: new upscaling algorithm for a much improved image quality. Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination. | 568 |
| [pvitoria/chromagan](https://replicate.com/pvitoria/chromagan) | An Adversarial Approach for Picture Colorization | 546 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 541 |
| [philz1337x/controlnet-deliberate](https://replicate.com/philz1337x/controlnet-deliberate) | Modify images with canny edge detection and Deliberate model twitter: @philz1337x | 541 |
| [cjwbw/supir](https://replicate.com/cjwbw/supir) | Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This version uses LLaVA-13b for captioning. | 520 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | Integral cog of doiwear.it | 510 |
| [cuuupid/gte-qwen2-7b-instruct](https://replicate.com/cuuupid/gte-qwen2-7b-instruct) | Embed text with Qwen2-7b-Instruct | 508 |
| [atrifat/hate-speech-detector](https://replicate.com/atrifat/hate-speech-detector) | Detect hate speech or toxic comments in tweets/texts | 478 |
| [aleksa-codes/flux-ghibsky-illustration](https://replicate.com/aleksa-codes/flux-ghibsky-illustration) | Flux LoRA, use 'GHIBSKY style' to trigger generation, creates serene and enchanting landscapes with vibrant, surreal skies and intricate, Ghibli-inspired elements reminiscent of the atmospheric beauty found in Makoto Shinkai's works | 446 |
| [pwntus/flux-albert-einstein](https://replicate.com/pwntus/flux-albert-einstein) | A fine-tuned FLUX.1 model. Use trigger word "EINSTEIN". Created with ReFlux (https://reflux.replicate.dev). | 443 |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 439 |
| [prompthero/openjourney](https://replicate.com/prompthero/openjourney) | Stable Diffusion fine tuned on Midjourney v4 images. | 437 |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | null | 407 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 397 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 396 |
| [stability-ai/stable-diffusion-img2img](https://replicate.com/stability-ai/stable-diffusion-img2img) | Generate a new image from an input image with Stable Diffusion | 380 |
| [juergengunz/ultimate-portrait-upscale](https://replicate.com/juergengunz/ultimate-portrait-upscale) | Upscale Portrait Images with ControlNet Tile | 376 |
| [asiryan/absolutereality-v1.8.1](https://replicate.com/asiryan/absolutereality-v1.8.1) | AbsoluteReality V1.8.1 Model (Text2Img, Img2Img and Inpainting) | 365 |
| [google-research/frame-interpolation](https://replicate.com/google-research/frame-interpolation) | Frame Interpolation for Large Scene Motion | 363 |
| [mcai/absolutebeauty-v1.0-img2img](https://replicate.com/mcai/absolutebeauty-v1.0-img2img) | Generate a new image from an input image with AbsoluteReality v1.0 | 355 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 354 |
| [zsxkib/flux-dev-inpainting](https://replicate.com/zsxkib/flux-dev-inpainting) | 🎨 Fill in masked parts of images with FLUX.1-dev 🖌️ | 348 |
| [orpatashnik/styleclip](https://replicate.com/orpatashnik/styleclip) | Text-Driven Manipulation of StyleGAN Imagery | 346 |
| [tstramer/material-diffusion](https://replicate.com/tstramer/material-diffusion) | Stable diffusion fork for generating tileable outputs using v1.5 model | 339 |
| [cloneofsimo/realistic_vision_v1.3](https://replicate.com/cloneofsimo/realistic_vision_v1.3) | null | 337 |
| [soykertje/spleeter](https://replicate.com/soykertje/spleeter) | Spleeter is Deezer source separation library with pretrained models written in Python and uses Tensorflow. | 335 |
| [levelsio/neon-tokyo](https://replicate.com/levelsio/neon-tokyo) | Take photos in the style of rainy Tokyo nights with neon lights | 333 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 333 |
| [daanelson/whisperx](https://replicate.com/daanelson/whisperx) | Accelerated transcription of audio using WhisperX | 330 |
| [konieshadow/fooocus-api-realistic](https://replicate.com/konieshadow/fooocus-api-realistic) | Third party Fooocus replicate model with preset 'realistic' | 327 |
| [catacolabs/sdxl-ad-inpaint](https://replicate.com/catacolabs/sdxl-ad-inpaint) | Product advertising image generator using SDXL | 312 |
| [rmokady/clip_prefix_caption](https://replicate.com/rmokady/clip_prefix_caption) | Simple image captioning model using CLIP and GPT-2 | 307 |
| [batouresearch/magic-style-transfer](https://replicate.com/batouresearch/magic-style-transfer) | Restyle an image with the style of another one. I strongly suggest to upscale the results with Clarity AI | 302 |
| [tgohblio/instant-id-albedobase-xl](https://replicate.com/tgohblio/instant-id-albedobase-xl) | InstantID : Zero-shot Identity-Preserving Generation in Seconds with ⚡️LCM-LoRA⚡️. Using AlbedoBase-XL v2.0 as base model. | 302 |
| [fofr/sdxl-fresh-ink](https://replicate.com/fofr/sdxl-fresh-ink) | SDXL fine-tuned on photos of freshly inked tattoos | 295 |
| [lucataco/dreamshaper-xl-turbo](https://replicate.com/lucataco/dreamshaper-xl-turbo) | DreamShaper is a general purpose SD model that aims at doing everything well, photos, art, anime, manga. It's designed to match Midjourney and DALL-E. | 295 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 292 |
| [fofr/live-portrait](https://replicate.com/fofr/live-portrait) | Portrait animation using a driving video source | 291 |
| [okaris/live-portrait](https://replicate.com/okaris/live-portrait) | null | 290 |
| [fofr/flux-mjv3](https://replicate.com/fofr/flux-mjv3) | Flux lora trained on Midjourney v3 outputs from 2022, use "a dream, in the style of MJV3" to trigger generation, also try increasing lora strength above 1 | 283 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 281 |
| [andreasjansson/illusion](https://replicate.com/andreasjansson/illusion) | Monster Labs' control_v1p_sd15_qrcode_monster ControlNet on top of SD 1.5 | 280 |
| [adirik/flux-cinestill](https://replicate.com/adirik/flux-cinestill) | Flux lora, use "CNSTLL" to trigger | 273 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 268 |
| [qr2ai/outline](https://replicate.com/qr2ai/outline) | From Sketch to Reality: Transforming Outlines into Lifelike Images | 266 |
| [zsxkib/yolo-world](https://replicate.com/zsxkib/yolo-world) | Real-Time Open-Vocabulary Object Detection | 263 |
| [ali-vilab/i2vgen-xl](https://replicate.com/ali-vilab/i2vgen-xl) | RESEARCH/NON-COMMERCIAL USE ONLY: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models | 256 |
| [lucataco/sdxl-niji-se](https://replicate.com/lucataco/sdxl-niji-se) | SDXL_Niji_Special Edition | 247 |
| [cjwbw/seamless_communication](https://replicate.com/cjwbw/seamless_communication) | SeamlessM4T—Massively Multilingual & Multimodal Machine Translation | 246 |
| [lucataco/sdxl](https://replicate.com/lucataco/sdxl) | SDXL v1.0 - A text-to-image generative AI model that creates beautiful images | 243 |
| [fewjative/ultimate-sd-upscale](https://replicate.com/fewjative/ultimate-sd-upscale) | Ultimate SD Upscale with ControlNet Tile | 242 |
| [lambdal/stable-diffusion-image-variation](https://replicate.com/lambdal/stable-diffusion-image-variation) | Image Variations with Stable Diffusion | 240 |
| [heedster/realistic-vision-v5](https://replicate.com/heedster/realistic-vision-v5) | Deployment of Realistic vision v5.0 with xformers for fast inference | 235 |
| [davisbrown/flux-half-illustration](https://replicate.com/davisbrown/flux-half-illustration) | Flux lora, use "in the style of TOK" to trigger generation, creates half photo half illustrated elements | 233 |
| [yxzwayne/bge-reranker-v2-m3](https://replicate.com/yxzwayne/bge-reranker-v2-m3) | Newest balance-striking reranker model from BAAI. Outputs rank scores for query-doc pairs. FP16 inference enabled. | 231 |
| [lucataco/sdxl-lcm](https://replicate.com/lucataco/sdxl-lcm) | Latent Consistency Model (LCM): SDXL, distills the original model into a version that requires fewer steps (4 to 8 instead of the original 25 to 50) | 225 |
| [catacolabs/cartoonify](https://replicate.com/catacolabs/cartoonify) | Turn your image into a cartoon | 224 |
| [lucataco/ssd-1b](https://replicate.com/lucataco/ssd-1b) | Segmind Stable Diffusion Model (SSD-1B) is a distilled 50% smaller version of SDXL, offering a 60% speedup while maintaining high-quality text-to-image generation capabilities | 223 |
| [cjwbw/bigcolor](https://replicate.com/cjwbw/bigcolor) | Colorization using a Generative Color Prior for Natural Images | 223 |
| [zsxkib/clip-age-predictor](https://replicate.com/zsxkib/clip-age-predictor) | Age prediction using CLIP - Patched version of `https://replicate.com/andreasjansson/clip-age-predictor` that works with the new version of cog! | 222 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 222 |
| [0xtuba/archillect-lora](https://replicate.com/0xtuba/archillect-lora) | Generates images in the style of Archillect | 220 |
| [sdsgitaccount/flux-gmoveus](https://replicate.com/sdsgitaccount/flux-gmoveus) | Flux lora, use "GMOVEUS" to trigger movement MEME | 219 |
| [ai-forever/kandinsky-2.2](https://replicate.com/ai-forever/kandinsky-2.2) | multilingual text2image latent diffusion model | 218 |
| [mcai/babes-v2.0-img2img](https://replicate.com/mcai/babes-v2.0-img2img) | Generate a new image from an input image with Babes 2.0 | 213 |
| [adirik/grounding-dino](https://replicate.com/adirik/grounding-dino) | Detect everything with language! | 212 |
| [fictions-ai/autocaption](https://replicate.com/fictions-ai/autocaption) | Automatically add captions to a video | 211 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 210 |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | 8-step-lora-and-canny-controlnet > more are coming soon | 202 |
| [bxclib2/flux_img2img](https://replicate.com/bxclib2/flux_img2img) | A ready to use image to image workflow of flux | 201 |
| [abiruyt/text-extract-ocr](https://replicate.com/abiruyt/text-extract-ocr) | A simple OCR Model that can easily extract text from an image. | 199 |
| [adirik/realvisxl-v3.0-turbo](https://replicate.com/adirik/realvisxl-v3.0-turbo) | Photorealism with RealVisXL V3.0 Turbo based on SDXL | 197 |
| [lucataco/animate-diff](https://replicate.com/lucataco/animate-diff) | Animate Your Personalized Text-to-Image Diffusion Models | 197 |
| [prompthero/dreamshaper](https://replicate.com/prompthero/dreamshaper) | Generate a new image given any input text with Dreamshaper v7 | 194 |
| [andreasjansson/stable-diffusion-inpainting](https://replicate.com/andreasjansson/stable-diffusion-inpainting) | Inpainting using RunwayML's stable-diffusion-inpainting checkpoint | 193 |
| [open-mmlab/pia](https://replicate.com/open-mmlab/pia) | Personalized Image Animator | 189 |
| [fofr/illusions](https://replicate.com/fofr/illusions) | Create illusions with img2img and masking support | 189 |
| [batouresearch/open-dalle-1.1-lora](https://replicate.com/batouresearch/open-dalle-1.1-lora) | Better than SDXL at both prompt adherence and image quality, by dataautogpt3 | 186 |
| [delta-lock/ponynai3](https://replicate.com/delta-lock/ponynai3) | https://civitai.com/models/317902 | 185 |
| [hvision-nku/storydiffusion](https://replicate.com/hvision-nku/storydiffusion) | Consistent Self-Attention for Long-Range Image and Video Generation | 184 |
| [cjwbw/dreamshaper](https://replicate.com/cjwbw/dreamshaper) | Dream Shaper stable diffusion | 180 |
| [cdingram/face-swap](https://replicate.com/cdingram/face-swap) | Image to image face swapping | 179 |
| [daanelson/minigpt-4](https://replicate.com/daanelson/minigpt-4) | A model which generates text in response to an input image and prompt. | 177 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 176 |
| [timothybrooks/instruct-pix2pix](https://replicate.com/timothybrooks/instruct-pix2pix) | Edit images with human instructions | 176 |
| [prompthero/lookbook](https://replicate.com/prompthero/lookbook) | Fashion Diffusion by Dreamshot | 174 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | 😊 Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 166 |
| [iwasrobbed/sdxl-suspense](https://replicate.com/iwasrobbed/sdxl-suspense) | SDXL fine-tuned on the suspenseful style of old school comics | 164 |
| [m1guelpf/whisper-subtitles](https://replicate.com/m1guelpf/whisper-subtitles) | Generate subtitles from an audio file, using OpenAI's Whisper model. | 163 |
| [cloversid099/deepfake](https://replicate.com/cloversid099/deepfake) | DeepFake AI | 159 |
| [mcai/edge-of-realism-v2.0](https://replicate.com/mcai/edge-of-realism-v2.0) | Generate a new image given any input text with Edge Of Realism - EOR v2.0 | 156 |
| [lucataco/hyper-flux-16step](https://replicate.com/lucataco/hyper-flux-16step) | Hyper FLUX 16-step by ByteDance | 154 |
| [kyrick/prompt-parrot](https://replicate.com/kyrick/prompt-parrot) | Prompt Parrot generates text2image prompts from finetuned distilgpt2 | 153 |
| [christophy/stable-video-diffusion](https://replicate.com/christophy/stable-video-diffusion) | stable-video-diffusion | 152 |
| [anotherjesse/controlnet-inpaint-test](https://replicate.com/anotherjesse/controlnet-inpaint-test) | controlnet_v11p_sd15_inpainting demo | 152 |
| [cjwbw/sadtalker](https://replicate.com/cjwbw/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 150 |
| [mv-lab/swin2sr](https://replicate.com/mv-lab/swin2sr) | 3 Million Runs! AI Photorealistic Image Super-Resolution and Restoration | 149 |
| [fofr/tooncrafter](https://replicate.com/fofr/tooncrafter) | Create videos from illustrated input images | 146 |
| [cjwbw/stable-diffusion-v2-inpainting](https://replicate.com/cjwbw/stable-diffusion-v2-inpainting) | stable-diffusion-v2-inpainting | 146 |
| [samsa-ai/flux-childbook-illustration](https://replicate.com/samsa-ai/flux-childbook-illustration) | Flux Lora, use "in the style of TOK" in your prompt as trigger | 142 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 140 |
| [ai-forever/kandinsky-2](https://replicate.com/ai-forever/kandinsky-2) | text2img model trained on LAION HighRes and fine-tuned on internal datasets | 139 |
| [cswry/seesr](https://replicate.com/cswry/seesr) | SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution | 138 |
| [lucataco/open-dalle-v1.1](https://replicate.com/lucataco/open-dalle-v1.1) | A unique fusion that showcases exceptional prompt adherence and semantic understanding, it seems to be a step above base SDXL and a step closer to DALLE-3 in terms of prompt comprehension | 138 |
| [marydotdev/sdxl-bb](https://replicate.com/marydotdev/sdxl-bb) | sdxl trained on bobs burgers | 137 |
| [fofr/flux-minecraft-movie](https://replicate.com/fofr/flux-minecraft-movie) | Flux lora, use "MNCRFTMOV" to trigger image generation | 135 |
| [batouresearch/sdxl-outpainting-lora](https://replicate.com/batouresearch/sdxl-outpainting-lora) | An improved outpainting model that supports LoRA urls. This model uses PatchMatch to improve the mask quality. | 132 |
| [lucataco/realvisxl-v1.0](https://replicate.com/lucataco/realvisxl-v1.0) | Implementation of SDXL RealVisXL_V1.0 | 129 |
| [adirik/realvisxl-v4.0](https://replicate.com/adirik/realvisxl-v4.0) | Photorealism with RealVisXL V4.0 | 121 |
| [juliananev/frutiger-aero](https://replicate.com/juliananev/frutiger-aero) | null | 119 |
| [juniorsavoretti/santisavoretti](https://replicate.com/juniorsavoretti/santisavoretti) | null | 118 |
| [suno-ai/bark](https://replicate.com/suno-ai/bark) | 🔊 Text-Prompted Generative Audio Model | 118 |
| [lucataco/ip_adapter-sdxl-face](https://replicate.com/lucataco/ip_adapter-sdxl-face) | The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate SDXL images with an image prompt | 114 |
| [lucataco/qwen-vl-chat](https://replicate.com/lucataco/qwen-vl-chat) | A multimodal LLM-based AI assistant, which is trained with alignment techniques. Qwen-VL-Chat supports more flexible interaction, such as multi-round question answering, and creative capabilities. | 114 |
| [fofr/flux-mona-lisa](https://replicate.com/fofr/flux-mona-lisa) | Flux lora, use the term "MNALSA" to trigger generation | 111 |
| [lucataco/realistic-vision-v5](https://replicate.com/lucataco/realistic-vision-v5) | Realistic Vision v5.0 with VAE | 111 |
| [chenxwh/openvoice](https://replicate.com/chenxwh/openvoice) | Updated to OpenVoice v2: Versatile Instant Voice Cloning | 110 |
| [zsxkib/diffbir](https://replicate.com/zsxkib/diffbir) | ✨DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior | 108 |
| [deforum/deforum_stable_diffusion](https://replicate.com/deforum/deforum_stable_diffusion) | Animating prompts with stable diffusion | 106 |
| [datacte/proteus-v0.4-lightning](https://replicate.com/datacte/proteus-v0.4-lightning) | ProteusV0.4: The Style Update - enhances stylistic capabilities, similar to Midjourney's approach, rather than advancing prompt comprehension | 105 |
| [men1scus/birefnet](https://replicate.com/men1scus/birefnet) | Bilateral Reference for High-Resolution Dichotomous Image Segmentation (arXiv 2024) | 101 |
