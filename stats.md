# Model Stats
## New Models
- https://replicate.com/tennibel/emporin

## Removed Models
No models were removed today.

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [tennibel/emporin](https://replicate.com/tennibel/emporin) | null | 14 | 14 | 100.00% |
| [ultralytics/yoloe-11s](https://replicate.com/ultralytics/yoloe-11s) | Ultralytics YOLOE-L Real-Time Seeing Anything model with 26.2M parameters. Achieves 52.6 mAP50-95 on COCO dataset. Optimized for real-time inference with 6.2 ms speed on T4 GPU.. | 3083 | 3313 | 93.06% |
| [prunaai/stable-diffusion-cheetah](https://replicate.com/prunaai/stable-diffusion-cheetah) | This model is an optimised version of stable-diffusion by stability AI that is 3x faster and 3x cheaper. | 1372 | 1586 | 86.51% |
| [astears/comic-book](https://replicate.com/astears/comic-book) | null | 63 | 79 | 79.75% |
| [moonshotai/kimi-k2.5](https://replicate.com/moonshotai/kimi-k2.5) | Moonshot AI's latest open model. It unifies vision and text, thinking and non-thinking modes, and single-agent and multi-agent execution into one model | 10515 | 14831 | 70.90% |
| [prunaai/firered-image-edit](https://replicate.com/prunaai/firered-image-edit) | FireRed-Image-Edit is a general-purpose image editing model that delivers high-fidelity and consistent editing across a wide range of scenarios. | 2190 | 3300 | 66.36% |
| [kwaivgi/kling-o1](https://replicate.com/kwaivgi/kling-o1) | Modify an existing video through natural-language commands, changing subjects, environments, and visual style while preserving the original motion and timing. | 142 | 349 | 40.69% |
| [skullycute/prefectillustriousxlv60](https://replicate.com/skullycute/prefectillustriousxlv60) | Anime Illust model | 104 | 293 | 35.49% |
| [xai/grok-imagine-image](https://replicate.com/xai/grok-imagine-image) | SOTA image model from xAI | 1403 | 4239 | 33.10% |
| [minimax/speech-2.8-hd](https://replicate.com/minimax/speech-2.8-hd) | Minimax Speech 2.8 HD focuses on high-fidelity audio generation with features like studio-grade quality, flexible emotion control, multilingual support, and voice cloning capabilities | 733 | 3350 | 21.88% |
| [triadmusic/stems-separator](https://replicate.com/triadmusic/stems-separator) | Image to separate stems from a song, using demucs and spleeter | 40 | 186 | 21.51% |
| [bria/fibo-edit](https://replicate.com/bria/fibo-edit) | FIBO-Edit brings the power of structured prompt generation to image editing | 9 | 48 | 18.75% |
| [erikp9090/drerik-petersen](https://replicate.com/erikp9090/drerik-petersen) | null | 16 | 87 | 18.39% |
| [tencent/hunyuan-3d-3.1](https://replicate.com/tencent/hunyuan-3d-3.1) | 3D models with texture fidelity and geometry precision | 159 | 921 | 17.26% |
| [hjunior29/video-text-generator](https://replicate.com/hjunior29/video-text-generator) | Generate animated captions and text overlays for social media videos | 96 | 583 | 16.47% |
| [xai/grok-imagine-video](https://replicate.com/xai/grok-imagine-video) | Generate videos using xAI's Grok Imagine Video model | 6119 | 38003 | 16.10% |
| [prunaai/p-image-edit-lora](https://replicate.com/prunaai/p-image-edit-lora) | Use trained LoRAs from the https://replicate.com/prunaai/p-image-edit-trainer. Find or contribute LoRAs here: https://huggingface.co/collections/PrunaAI/p-image-edit-loras. | 211 | 1333 | 15.83% |
| [bytedance/dreamactor-m2.0](https://replicate.com/bytedance/dreamactor-m2.0) | Animate any character, humans, cartoons, animals, even non-humans, from a single image + driving video | 167 | 1077 | 15.51% |
| [prunaai/z-image-turbo-inpaint](https://replicate.com/prunaai/z-image-turbo-inpaint) | Inpaint version of z-image-turbo with lora support | 42 | 275 | 15.27% |
| [zsxkib/talknet-asd](https://replicate.com/zsxkib/talknet-asd) | üó£Ô∏è TalkNet-ASD: Detect who is speaking in a video | 2141 | 15079 | 14.20% |
| [deyoyk/asian](https://replicate.com/deyoyk/asian) | fund me so i can train with even more asian girls images :3 https://buymeacoffee.com/deyoyk | 12 | 85 | 14.12% |
| [elevenlabs/flash-v2.5](https://replicate.com/elevenlabs/flash-v2.5) | ElevenLabs's fastest speech synthesis model | 25 | 191 | 13.09% |
| [daanelson/flux-fill-dev-big](https://replicate.com/daanelson/flux-fill-dev-big) | Image inpainting with flux | 19 | 163 | 11.66% |
| [anthropic/claude-opus-4.6](https://replicate.com/anthropic/claude-opus-4.6) | Anthropic's most intelligent model with state-of-the-art coding, reasoning, and agentic capabilities | 609 | 5930 | 10.27% |
| [wan-video/wan2.6-i2v-flash](https://replicate.com/wan-video/wan2.6-i2v-flash) | Image-to-video generation with optional audio, multi-shot narrative support, and faster inference | 1064 | 10423 | 10.21% |
| [prunaai/gpt-oss-120b-fast](https://replicate.com/prunaai/gpt-oss-120b-fast) | This is a version of GPT-OSS-120B that is optimised by Pruna AI, free for now. | 3 | 30 | 10.00% |
| [xavriley/beat_this](https://replicate.com/xavriley/beat_this) | Detect beats in music | 26 | 278 | 9.35% |
| [zsxkib/seedvr2](https://replicate.com/zsxkib/seedvr2) | üî• SeedVR2: one-step video & image restoration with 3B/7B hot‚Äëswap and optional color fix üé¨‚ú® | 2710 | 31117 | 8.71% |
| [topazlabs/image-colorization](https://replicate.com/topazlabs/image-colorization) | Image colorization model from Topaz Labs | 10 | 122 | 8.20% |
| [topazlabs/dust-and-scratch-v2](https://replicate.com/topazlabs/dust-and-scratch-v2) | Remove dust and scratches from old photos | 10 | 130 | 7.69% |
| [gauravpuniyani08/ponywoman](https://replicate.com/gauravpuniyani08/ponywoman) | null | 3 | 41 | 7.32% |
| [sourceful/riverflow-2.0-pro](https://replicate.com/sourceful/riverflow-2.0-pro) | Agentic image model optimized for robust, high-precision generations supporting font control | 347 | 5133 | 6.76% |
| [sourceful/riverflow-2.0-fast](https://replicate.com/sourceful/riverflow-2.0-fast) | Agentic image model optimized for high-quality, fast generations supporting font control | 43 | 683 | 6.30% |
| [cdlane24399/grant-marshall](https://replicate.com/cdlane24399/grant-marshall) | null | 2 | 32 | 6.25% |
| [black-forest-labs/flux-2-klein-9b](https://replicate.com/black-forest-labs/flux-2-klein-9b) | 4 step distilled version of FLUX.2 [klein]. A foundation model for maximum flexibility and control | 4303 | 69210 | 6.22% |
| [invarrow/carai-offcial](https://replicate.com/invarrow/carai-offcial) | CarAI: Evaluate Car Damages | 76 | 1258 | 6.04% |
| [minimax/speech-2.8-turbo](https://replicate.com/minimax/speech-2.8-turbo) | Minimax Speech 2.8 Turbo: Turn text into natural, expressive speech with voice cloning, emotion control, and support for 40+ languages | 505 | 8439 | 5.98% |
| [ddvinh1/inswapper](https://replicate.com/ddvinh1/inswapper) | null | 99 | 1661 | 5.96% |
| [kwaivgi/kling-avatar-v2](https://replicate.com/kwaivgi/kling-avatar-v2) | Create avatar videos with realistic humans, animals, cartoons, or stylized characters | 77 | 1359 | 5.67% |
| [sourceful/riverflow-2.0-refsr](https://replicate.com/sourceful/riverflow-2.0-refsr) | Render product images with 100% accuracy and environmental blending | 7 | 126 | 5.56% |
| [onemadgeek/frames-to-video-merger](https://replicate.com/onemadgeek/frames-to-video-merger) | Convert a set of image frames (JPG or PNG) into a high-quality MP4 video. Automatically handles sorting and frame order for smooth playback. | 2 | 36 | 5.56% |
| [aisha-ai-official/cyber-realistic-pony-v8](https://replicate.com/aisha-ai-official/cyber-realistic-pony-v8) | null | 82 | 1494 | 5.49% |
| [google/veo-3.1-fast](https://replicate.com/google/veo-3.1-fast) | New and improved version of Veo 3 Fast, with higher-fidelity video, context-aware audio and last frame support | 20896 | 413049 | 5.06% |
| [black-forest-labs/flux-2-klein-9b-base-lora](https://replicate.com/black-forest-labs/flux-2-klein-9b-base-lora) | A version of FLUX.2 [klein] 9B-base that supports fast fine-tuned lora inference | 34 | 676 | 5.03% |
| [qwen/qwen3-tts](https://replicate.com/qwen/qwen3-tts) | A unified Text-to-Speech demo featuring three powerful modes: Voice, Clone and Design | 1782 | 35634 | 5.00% |
| [jichengdu/fish-speech](https://replicate.com/jichengdu/fish-speech) | Fish Speech V1.5-SOTA Open Source TTS | 72 | 1556 | 4.63% |
| [qwen/qwen-image-edit-2511](https://replicate.com/qwen/qwen-image-edit-2511) | An enhanced version over Qwen-Image-Edit-2509, featuring multiple improvements including notably better consistency | 96860 | 2097041 | 4.62% |
| [vetkastar/image-slicing](https://replicate.com/vetkastar/image-slicing) | Split one or multiple images into four equal parts | 7 | 153 | 4.58% |
| [triadmusic/whisper](https://replicate.com/triadmusic/whisper) | Model to detect speaks and split by word | 2 | 44 | 4.55% |
| [m-kunz/birefnet_portrait](https://replicate.com/m-kunz/birefnet_portrait) | Removes the background of images, optimized for human portraits | 9 | 204 | 4.41% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [black-forest-labs/flux-schnell](https://replicate.com/black-forest-labs/flux-schnell) | The fastest image generation model tailored for local development and personal use | 614409 |
| [prunaai/z-image-turbo](https://replicate.com/prunaai/z-image-turbo) | Z-Image Turbo is a super fast text-to-image model of 6B parameters developed by Tongyi-MAI. | 541038 |
| [google/nano-banana](https://replicate.com/google/nano-banana) | Google's latest image editing model in Gemini 2.5 | 410224 |
| [openai/gpt-4o-mini](https://replicate.com/openai/gpt-4o-mini) | Low latency, low cost version of OpenAI's GPT-4o model | 394730 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 237507 |
| [prunaai/p-image-edit](https://replicate.com/prunaai/p-image-edit) | A sub 1 second 0.01$ multi-image editing model built for production use cases. For image generation, check out p-image here: https://replicate.com/prunaai/p-image | 205134 |
| [jaaari/kokoro-82m](https://replicate.com/jaaari/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 165125 |
| [falcons-ai/nsfw_image_detection](https://replicate.com/falcons-ai/nsfw_image_detection) | Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 163034 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! ü§ó | 121104 |
| [black-forest-labs/flux-2-klein-4b](https://replicate.com/black-forest-labs/flux-2-klein-4b) | Very fast image generation and editing model. 4 steps distilled, sub-second inference for production and near real-time applications. | 118329 |
| [bytedance/seedream-4](https://replicate.com/bytedance/seedream-4) | Unified text-to-image generation and precise single-sentence editing at up to 4K resolution | 107161 |
| [black-forest-labs/flux-dev](https://replicate.com/black-forest-labs/flux-dev) | A 12 billion parameter rectified flow transformer capable of generating images from text descriptions | 98800 |
| [qwen/qwen-image-edit-2511](https://replicate.com/qwen/qwen-image-edit-2511) | An enhanced version over Qwen-Image-Edit-2509, featuring multiple improvements including notably better consistency | 96860 |
| [google/nano-banana-pro](https://replicate.com/google/nano-banana-pro) | Google's state of the art image generation and editing model üçåüçå | 96610 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 88846 |
| [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct) | An 8 billion parameter language model from Meta, fine tuned for chat completions | 87047 |
| [prunaai/p-image](https://replicate.com/prunaai/p-image) | A sub 1 second text-to-image model built for production use cases. | 80234 |
| [nicolascoutureau/video-utils](https://replicate.com/nicolascoutureau/video-utils) | null | 78951 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 74869 |
| [black-forest-labs/flux-kontext-pro](https://replicate.com/black-forest-labs/flux-kontext-pro) | A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language | 68152 |
| [adirik/grounding-dino](https://replicate.com/adirik/grounding-dino) | Detect everything with language! | 67375 |
| [851-labs/background-remover](https://replicate.com/851-labs/background-remover) | Remove backgrounds from images. | 66239 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 63397 |
| [openai/gpt-image-1.5](https://replicate.com/openai/gpt-image-1.5) | OpenAI's latest image generation model with better instruction following and adherence to prompts | 62882 |
| [wan-video/wan-2.2-i2v-fast](https://replicate.com/wan-video/wan-2.2-i2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B image-to-video | 52869 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 51123 |
| [meta/llama-4-maverick-instruct](https://replicate.com/meta/llama-4-maverick-instruct) | A 17 billion parameter model with 128 experts | 50893 |
| [lucataco/moondream2](https://replicate.com/lucataco/moondream2) | moondream2 is a small vision language model designed to run efficiently on edge devices | 47795 |
| [bytedance/seedream-4.5](https://replicate.com/bytedance/seedream-4.5) | Seedream 4.5: Upgraded Bytedance image model with stronger spatial understanding and world knowledge | 46409 |
| [black-forest-labs/flux-2-pro](https://replicate.com/black-forest-labs/flux-2-pro) | High-quality image generation and editing with support for eight reference images | 44918 |
| [bytedance/sdxl-lightning-4step](https://replicate.com/bytedance/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 42150 |
| [minimax/speech-02-turbo](https://replicate.com/minimax/speech-02-turbo) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Designed for real-time applications with low latency | 40810 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 40105 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x | 39599 |
| [black-forest-labs/flux-1.1-pro](https://replicate.com/black-forest-labs/flux-1.1-pro) | Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity. | 38990 |
| [aisha-ai-official/animagine-xl-v4-opt](https://replicate.com/aisha-ai-official/animagine-xl-v4-opt) | null | 36206 |
| [prunaai/flux-fast](https://replicate.com/prunaai/flux-fast) | This is the fastest Flux endpoint in the world. | 36203 |
| [zedge/stable-diffusion](https://replicate.com/zedge/stable-diffusion) | Private instance of stable-diffusion | 35704 |
| [prunaai/flux-kontext-fast](https://replicate.com/prunaai/flux-kontext-fast) | Ultra fast flux kontext endpoint | 35344 |
| [ideogram-ai/ideogram-v3-turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo) | Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles | 34852 |
| [bytedance/hyper-flux-8step](https://replicate.com/bytedance/hyper-flux-8step) | Hyper FLUX 8-step by ByteDance | 33690 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ‚ö°Ô∏è Blazing fast audio transcription with speaker diarization | Whisper Large V3 Turbo | word & sentence level timestamps | prompt | 29452 |
| [humbleworth/price-predict-v1](https://replicate.com/humbleworth/price-predict-v1) | Predicts the value of a domain name. | 28802 |
| [openai/gpt-5-nano](https://replicate.com/openai/gpt-5-nano) | Fastest, most cost-effective GPT-5 model from OpenAI | 28444 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | ü¶ô LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 27760 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 26187 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 22763 |
| [google/veo-3.1-fast](https://replicate.com/google/veo-3.1-fast) | New and improved version of Veo 3 Fast, with higher-fidelity video, context-aware audio and last frame support | 20896 |
| [openai/gpt-5-mini](https://replicate.com/openai/gpt-5-mini) | Faster version of OpenAI's flagship GPT-5 model | 18306 |
| [black-forest-labs/flux-1.1-pro-ultra](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra) | FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism. | 17235 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 16923 |
| [openai/clip](https://replicate.com/openai/clip) | Official CLIP models, generate CLIP (clip-vit-large-patch14) text & image embeddings | 15986 |
| [black-forest-labs/flux-kontext-dev](https://replicate.com/black-forest-labs/flux-kontext-dev) | Open-weight version of FLUX.1 Kontext | 15558 |
| [anthropic/claude-4-sonnet](https://replicate.com/anthropic/claude-4-sonnet) | Claude Sonnet 4 is a significant upgrade to 3.7, delivering superior coding and reasoning while responding more precisely to your instructions | 15459 |
| [tmappdev/lang-segment-anything](https://replicate.com/tmappdev/lang-segment-anything) | Segment Anything with prompts | 15325 |
| [black-forest-labs/flux-2-dev](https://replicate.com/black-forest-labs/flux-2-dev) | Quality image generation and editing with support for reference images | 14983 |
| [black-forest-labs/flux-krea-dev](https://replicate.com/black-forest-labs/flux-krea-dev) | An opinionated text-to-image model from Black Forest Labs in collaboration with Krea that excels in photorealism. Creates images that avoid the oversaturated "AI look". | 14832 |
| [google/gemini-2.5-flash](https://replicate.com/google/gemini-2.5-flash) | Google‚Äôs hybrid ‚Äúthinking‚Äù AI model optimized for speed and cost-efficiency | 14699 |
| [qwen/qwen-image-edit-plus](https://replicate.com/qwen/qwen-image-edit-plus) | The latest Qwen-Image‚Äôs iteration with improved multi-image editing, single-image consistency, and native support for ControlNet | 14457 |
| [anthropic/claude-4.5-sonnet](https://replicate.com/anthropic/claude-4.5-sonnet) | Claude Sonnet 4.5 is the best coding model to date, with significant improvements across the entire development lifecycle | 14454 |
| [openai/gpt-4.1-mini](https://replicate.com/openai/gpt-4.1-mini) | Fast, affordable version of GPT-4.1 | 13199 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Generate image captions | 12343 |
| [minimax/speech-02-hd](https://replicate.com/minimax/speech-02-hd) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Optimized for high-fidelity applications like voiceovers and audiobooks. | 12239 |
| [google/imagen-4-fast](https://replicate.com/google/imagen-4-fast) | Use this fast version of Imagen 4 when speed and cost are more important than quality | 11919 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 11887 |
| [alexgenovese/upscaler](https://replicate.com/alexgenovese/upscaler) | GFPGAN aims at developing Practical Algorithms for Real-world Face and Object Restoration | 11755 |
| [lucataco/codeformer](https://replicate.com/lucataco/codeformer) | Robust face restoration algorithm for old photos/AI-generated faces | 11167 |
| [bytedance/hyper-flux-16step](https://replicate.com/bytedance/hyper-flux-16step) | Hyper FLUX 16-step by ByteDance | 11029 |
| [google/imagen-4](https://replicate.com/google/imagen-4) | Google's Imagen 4 flagship model | 10876 |
| [black-forest-labs/flux-2-max](https://replicate.com/black-forest-labs/flux-2-max) | The highest fidelity image model from Black Forest Labs | 10698 |
| [moonshotai/kimi-k2.5](https://replicate.com/moonshotai/kimi-k2.5) | Moonshot AI's latest open model. It unifies vision and text, thinking and non-thinking modes, and single-agent and multi-agent execution into one model | 10515 |
| [meta/meta-llama-3-70b-instruct](https://replicate.com/meta/meta-llama-3-70b-instruct) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 10497 |
| [recraft-ai/recraft-crisp-upscale](https://replicate.com/recraft-ai/recraft-crisp-upscale) | Designed to make images sharper and cleaner, Crisp Upscale increases overall quality, making visuals suitable for web use or print-ready materials. | 10409 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 10313 |
| [victor-upmeet/whisperx-a40-large](https://replicate.com/victor-upmeet/whisperx-a40-large) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 for large audio files | 9916 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 9904 |
| [bytedance/seedance-1.5-pro](https://replicate.com/bytedance/seedance-1.5-pro) | A joint audio-video model that accurately follows complex instructions. | 9870 |
| [zedge/real-esrgan](https://replicate.com/zedge/real-esrgan) | Private instance of real-esrgan | 9373 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 9210 |
| [openai/gpt-5](https://replicate.com/openai/gpt-5) | OpenAI's new model excelling at coding, writing, and reasoning. | 8444 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 8374 |
| [anthropic/claude-3.7-sonnet](https://replicate.com/anthropic/claude-3.7-sonnet) | The most intelligent Claude model and the first hybrid reasoning model on the market (claude-3-7-sonnet-20250219) | 7979 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 7770 |
| [datacte/proteus-v0.2](https://replicate.com/datacte/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 7318 |
| [zsxkib/mmaudio](https://replicate.com/zsxkib/mmaudio) | Add sound to video using the MMAudio V2 model. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation. | 7309 |
| [bytedance/seedance-1-pro-fast](https://replicate.com/bytedance/seedance-1-pro-fast) | A faster and cheaper version of Seedance 1 Pro | 7259 |
| [recraft-ai/recraft-v3](https://replicate.com/recraft-ai/recraft-v3) | Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis | 7222 |
| [franz-biz/yolo-world-xl](https://replicate.com/franz-biz/yolo-world-xl) | Real-Time Open-Vocabulary Object Detection using the xl weights | 6806 |
| [recraft-ai/recraft-remove-background](https://replicate.com/recraft-ai/recraft-remove-background) | Automated background removal for images. Tuned for AI-generated content, product photos, portraits, and design workflows | 6567 |
| [cdingram/face-swap](https://replicate.com/cdingram/face-swap) | Image to image face swapping | 6407 |
| [men1scus/birefnet](https://replicate.com/men1scus/birefnet) | Bilateral Reference for High-Resolution Dichotomous Image Segmentation (CAAI AIR 2024) | 6363 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 6166 |
| [datacte/proteus-v0.3](https://replicate.com/datacte/proteus-v0.3) | ProteusV0.3: The Anime Update | 6145 |
| [xai/grok-imagine-video](https://replicate.com/xai/grok-imagine-video) | Generate videos using xAI's Grok Imagine Video model | 6119 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 6006 |
| [zedge/zoedepth](https://replicate.com/zedge/zoedepth) | null | 6003 |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | Advance Face Swap powered by pixalto.app | 5712 |
| [google/gemini-2.5-flash-image](https://replicate.com/google/gemini-2.5-flash-image) | Google's latest image generation model in Gemini 2.5 | 5468 |
| [qwen/qwen-edit-multiangle](https://replicate.com/qwen/qwen-edit-multiangle) | Camera-aware edits for Qwen/Qwen-Image-Edit-2509 with Lightning + multi-angle LoRA | 5407 |
| [kwaivgi/kling-v2.1](https://replicate.com/kwaivgi/kling-v2.1) | Use Kling v2.1 to generate 5s and 10s videos in 720p and 1080p resolution from a starting image (image-to-video) | 5245 |
| [kwaivgi/kling-v2.5-turbo-pro](https://replicate.com/kwaivgi/kling-v2.5-turbo-pro) | Kling 2.5 Turbo Pro: Unlock pro-level text-to-video and image-to-video creation with smooth motion, cinematic depth, and remarkable prompt adherence. | 5239 |
| [daanelson/imagebind](https://replicate.com/daanelson/imagebind) | A model for text, audio, and image embeddings in one space | 5161 |
| [minimax/image-01](https://replicate.com/minimax/image-01) | Minimax's first image model, with character reference support | 5149 |
| [comfyui/any-comfyui-workflow](https://replicate.com/comfyui/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/replicate/cog-comfyui | 5131 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 5115 |
| [kwaivgi/kling-v2.6-motion-control](https://replicate.com/kwaivgi/kling-v2.6-motion-control) | Enables precise control of character actions and expressions from a reference image. | 5062 |
| [black-forest-labs/flux-kontext-max](https://replicate.com/black-forest-labs/flux-kontext-max) | A premium text-based image editing model that delivers maximum performance and improved typography generation for transforming images through natural language prompts | 5029 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 4876 |
| [charlesmccarthy/addwatermark](https://replicate.com/charlesmccarthy/addwatermark) | Add a watermark to your videos using the power of Replicate brought to you from your friends at FullJourney.AI | 4783 |
| [philz1337x/crystal-upscaler](https://replicate.com/philz1337x/crystal-upscaler) | High-precision image upscaler optimized for portraits, faces and products. One of the upscale modes powered by Clarity AI. X:https://x.com/philz1337x | 4762 |
| [bytedance/seedance-1-lite](https://replicate.com/bytedance/seedance-1-lite) | A video generation model that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 720p resolution | 4678 |
| [topazlabs/image-upscale](https://replicate.com/topazlabs/image-upscale) | Professional-grade image upscaling, from Topaz Labs | 4602 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 4518 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 4429 |
| [prunaai/wan-2.2-image](https://replicate.com/prunaai/wan-2.2-image) | This model generates beautiful cinematic 2 megapixel images in 3-4 seconds and is derived from the Wan 2.2 model through optimisation techniques from the pruna package | 4366 |
| [qwen/qwen-image](https://replicate.com/qwen/qwen-image) | An image generation foundation model in the Qwen series that achieves significant advances in complex text rendering. | 4331 |
| [black-forest-labs/flux-fill-dev](https://replicate.com/black-forest-labs/flux-fill-dev) | Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro]. | 4324 |
| [fofr/flux-black-light](https://replicate.com/fofr/flux-black-light) | A flux lora fine-tuned on black light images | 4320 |
| [kwaivgi/kling-v2.6](https://replicate.com/kwaivgi/kling-v2.6) | Kling 2.6 Pro: Top-tier image-to-video with cinematic visuals, fluid motion, and native audio generation | 4313 |
| [black-forest-labs/flux-2-klein-9b](https://replicate.com/black-forest-labs/flux-2-klein-9b) | 4 step distilled version of FLUX.2 [klein]. A foundation model for maximum flexibility and control | 4303 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 4259 |
| [prunaai/hidream-l1-fast](https://replicate.com/prunaai/hidream-l1-fast) | This is an optimised version of the hidream-l1 model using the pruna ai optimisation toolkit! | 4193 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 4137 |
| [openai/gpt-4.1-nano](https://replicate.com/openai/gpt-4.1-nano) | Fastest, most cost-effective GPT-4.1 model from OpenAI | 3952 |
| [tencentarc/vqfr](https://replicate.com/tencentarc/vqfr) | Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder | 3873 |
| [google/gemini-3-flash](https://replicate.com/google/gemini-3-flash) | Google's most intelligent model built for speed with frontier intelligence, superior search, and grounding | 3814 |
| [black-forest-labs/flux-dev-lora](https://replicate.com/black-forest-labs/flux-dev-lora) | A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference | 3779 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 3611 |
| [minimax/speech-2.6-turbo](https://replicate.com/minimax/speech-2.6-turbo) | Low‚Äëlatency MiniMax Speech 2.6 Turbo brings multilingual, emotional text-to-speech to Replicate with 300+ voices and real-time friendly pricing | 3552 |
| [ryan5453/demucs](https://replicate.com/ryan5453/demucs) | Demucs is an audio source separator created by Facebook Research. | 3502 |
| [meta/meta-llama-3.1-405b-instruct](https://replicate.com/meta/meta-llama-3.1-405b-instruct) | Meta's flagship 405 billion parameter language model, fine-tuned for chat completions | 3388 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting by the HF Diffusers team | 3381 |
| [prunaai/flux-2-turbo](https://replicate.com/prunaai/flux-2-turbo) | Image generation and editing with a distilled FLUX.2 [dev] by FAL. | 3357 |
| [bria/remove-background](https://replicate.com/bria/remove-background) | Bria AI's remove background model | 3335 |
| [pollinations/modnet](https://replicate.com/pollinations/modnet) | A deep learning approach to remove background & adding new background image | 3273 |
| [runwayml/gen4-image](https://replicate.com/runwayml/gen4-image) | Runway's Gen-4 Image model with references. Use up to 3 reference images to create the exact image you need. Capture every angle. | 3262 |
| [meronym/speaker-diarization](https://replicate.com/meronym/speaker-diarization) | Segments an audio recording based on who is speaking | 3260 |
| [google/imagen-4-ultra](https://replicate.com/google/imagen-4-ultra) | Use this ultra version of Imagen 4 when quality matters more than speed and cost | 3227 |
| [google/gemini-3-pro](https://replicate.com/google/gemini-3-pro) | Google's most advanced reasoning Gemini model | 3221 |
| [aisha-ai-official/nsfw-flux-dev](https://replicate.com/aisha-ai-official/nsfw-flux-dev) | null | 3157 |
| [ultralytics/yoloe-11s](https://replicate.com/ultralytics/yoloe-11s) | Ultralytics YOLOE-L Real-Time Seeing Anything model with 26.2M parameters. Achieves 52.6 mAP50-95 on COCO dataset. Optimized for real-time inference with 6.2 ms speed on T4 GPU.. | 3083 |
| [qwen/qwen-image-edit](https://replicate.com/qwen/qwen-image-edit) | Edit images using a prompt. This model extends Qwen-Image‚Äôs unique text rendering capabilities to image editing tasks, enabling precise text editing | 3073 |
| [zedge/instantid](https://replicate.com/zedge/instantid) | null | 3048 |
| [aisha-ai-official/anillustrious-v4](https://replicate.com/aisha-ai-official/anillustrious-v4) | null | 3048 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 3038 |
| [zedge/emoji-generator](https://replicate.com/zedge/emoji-generator) | null | 3020 |
| [flux-kontext-apps/restore-image](https://replicate.com/flux-kontext-apps/restore-image) | Use FLUX Kontext to restore, fix scratches and damage, and colorize old photos | 2972 |
| [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) | Base version of Llama 3, an 8 billion parameter language model from Meta. | 2958 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 2954 |
| [black-forest-labs/flux-pro](https://replicate.com/black-forest-labs/flux-pro) | State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. | 2941 |
| [zedge/live-portrait](https://replicate.com/zedge/live-portrait) | null | 2913 |
| [zsxkib/qwen2-1.5b-instruct](https://replicate.com/zsxkib/qwen2-1.5b-instruct) | Qwen 2: A 1.5 billion parameter language model from Alibaba Cloud, fine tuned for chat completions | 2898 |
| [prunaai/flux.1-dev-lora](https://replicate.com/prunaai/flux.1-dev-lora) | This is a 3x faster FLUX.1 [dev] model from Black Forest Labs, optimised with pruna with minimal quality loss. | 2714 |
| [zsxkib/seedvr2](https://replicate.com/zsxkib/seedvr2) | üî• SeedVR2: one-step video & image restoration with 3B/7B hot‚Äëswap and optional color fix üé¨‚ú® | 2710 |
| [bytedance/seedance-1-pro](https://replicate.com/bytedance/seedance-1-pro) | A pro version of Seedance that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 1080p resolution | 2708 |
| [black-forest-labs/flux-depth-dev](https://replicate.com/black-forest-labs/flux-depth-dev) | Open-weight depth-aware image generation. Edit images while preserving spatial relationships. | 2693 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 2618 |
| [openai/gpt-image-1-mini](https://replicate.com/openai/gpt-image-1-mini) | A cost-efficient version of GPT Image 1 | 2548 |
| [bytedance/pulid](https://replicate.com/bytedance/pulid) | üìñ PuLID: Pure and Lightning ID Customization via Contrastive Alignment | 2456 |
| [prunaai/z-image-turbo-lora](https://replicate.com/prunaai/z-image-turbo-lora) | Lora version of Z-Image Turbo, which is a super fast text-to-image model of 6B parameters developed by Tongyi-MAI. | 2428 |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 2339 |
| [playgroundai/playground-v2.5-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 2332 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 2329 |
| [openai/gpt-image-1](https://replicate.com/openai/gpt-image-1) | A multimodal image generation model that creates high-quality images. You need to bring your own verified OpenAI key to use this model. Your OpenAI account will be charged for usage. | 2324 |
| [black-forest-labs/flux-fill-pro](https://replicate.com/black-forest-labs/flux-fill-pro) | Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results. | 2321 |
| [aisha-ai-official/miaomiao-harem-illustrious-v1](https://replicate.com/aisha-ai-official/miaomiao-harem-illustrious-v1) | null | 2240 |
| [soykertje/spleeter](https://replicate.com/soykertje/spleeter) | Spleeter is Deezer source separation library with pretrained models written in Python and uses Tensorflow. | 2239 |
| [prunaai/firered-image-edit](https://replicate.com/prunaai/firered-image-edit) | FireRed-Image-Edit is a general-purpose image editing model that delivers high-fidelity and consistent editing across a wide range of scenarios. | 2190 |
| [bytedance/seedream-3](https://replicate.com/bytedance/seedream-3) | A text-to-image model with support for native high-resolution (2K) image generation | 2181 |
| [zsxkib/talknet-asd](https://replicate.com/zsxkib/talknet-asd) | üó£Ô∏è TalkNet-ASD: Detect who is speaking in a video | 2141 |
| [adirik/interior-design](https://replicate.com/adirik/interior-design) | Realistic interior design with text and image inputs | 2092 |
| [recraft-ai/recraft-vectorize](https://replicate.com/recraft-ai/recraft-vectorize) | Convert raster images to high-quality SVG format with precision and clean vector paths, perfect for logos, icons, and scalable graphics. | 2091 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 2045 |
| [nateraw/audio-super-resolution](https://replicate.com/nateraw/audio-super-resolution) | AudioSR: Versatile Audio Super-resolution at Scale | 2023 |
| [firtoz/trellis](https://replicate.com/firtoz/trellis) | A powerful 3D asset generation model | 2012 |
| [luma/reframe-image](https://replicate.com/luma/reframe-image) | Change the aspect ratio of any photo using AI (not cropping) | 1972 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 1940 |
| [lucataco/frame-extractor](https://replicate.com/lucataco/frame-extractor) | Extract the first or last frame from any video file as a high-quality image | 1939 |
| [google/veo-3.1](https://replicate.com/google/veo-3.1) | New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support | 1871 |
| [pikachupichu25/image-faceswap](https://replicate.com/pikachupichu25/image-faceswap) | null | 1864 |
| [yorickvp/llava-v1.6-mistral-7b](https://replicate.com/yorickvp/llava-v1.6-mistral-7b) | LLaVA v1.6: Large Language and Vision Assistant (Mistral-7B) | 1847 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 1829 |
| [qwen/qwen-image-edit-plus-lora](https://replicate.com/qwen/qwen-image-edit-plus-lora) | Qwen Image Edit 2509 LoRA explorer, uses HuggingFace URLs to load any safetensor | 1828 |
| [qwen/qwen3-tts](https://replicate.com/qwen/qwen3-tts) | A unified Text-to-Speech demo featuring three powerful modes: Voice, Clone and Design | 1782 |
| [simbrams/segformer-b5-finetuned-ade-640-640](https://replicate.com/simbrams/segformer-b5-finetuned-ade-640-640) | Semantic Segmentation | 1727 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 1727 |
| [stability-ai/stable-diffusion-3.5-large-turbo](https://replicate.com/stability-ai/stable-diffusion-3.5-large-turbo) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, with a focus on fewer inference steps | 1715 |
| [bria/eraser](https://replicate.com/bria/eraser) | SOTA Object removal, enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use | 1686 |
| [abiruyt/text-extract-ocr](https://replicate.com/abiruyt/text-extract-ocr) | A simple OCR Model that can easily extract text from an image. | 1679 |
| [luma/photon-flash](https://replicate.com/luma/photon-flash) | Accelerated variant of Photon prioritizing speed while maintaining quality | 1656 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 1644 |
| [ideogram-ai/ideogram-v2](https://replicate.com/ideogram-ai/ideogram-v2) | An excellent image model with state of the art inpainting, prompt comprehension and text rendering | 1633 |
| [ardianfe/music-gen-fn-200e](https://replicate.com/ardianfe/music-gen-fn-200e) | Create music for your content | 1617 |
| [lucataco/flux-schnell-lora](https://replicate.com/lucataco/flux-schnell-lora) | FLUX.1-Schnell LoRA Explorer | 1603 |
| [wan-video/wan-2.2-5b-fast](https://replicate.com/wan-video/wan-2.2-5b-fast) | The fastest Wan 2.2 text-to-image and image-to-video model | 1583 |
| [kwaivgi/kling-v1.6-standard](https://replicate.com/kwaivgi/kling-v1.6-standard) | Generate 5s and 10s videos in 720p resolution at 30fps | 1557 |
| [tencent/hunyuanvideo-foley](https://replicate.com/tencent/hunyuanvideo-foley) | (Research & Non-commercial use only) Text-Video-to-Audio Synthesis: Generate realistic audio from video and text descriptions | 1528 |
| [stability-ai/stable-diffusion-3.5-large](https://replicate.com/stability-ai/stable-diffusion-3.5-large) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, thanks to Query-Key Normalization. | 1512 |
| [openai/sora-2](https://replicate.com/openai/sora-2) | OpenAI's Flagship video generation with synced audio | 1509 |
| [google/imagen-3](https://replicate.com/google/imagen-3) | Google's highest quality text-to-image model, capable of generating images with detail, rich lighting and beauty | 1495 |
| [pixverse/lipsync](https://replicate.com/pixverse/lipsync) | Generate realistic lipsync animations from audio for high-quality synchronization | 1492 |
| [smoosh-sh/baby-mystic](https://replicate.com/smoosh-sh/baby-mystic) | Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent | 1441 |
| [mrhan1993/fooocus-api](https://replicate.com/mrhan1993/fooocus-api) | null | 1436 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 1433 |
| [zf-kbot/inpaint-and-guess-prompt](https://replicate.com/zf-kbot/inpaint-and-guess-prompt) | Use a mask to inpaint the image or generate a prompt based on the mask. | 1419 |
| [lucataco/qwen3-embedding-8b](https://replicate.com/lucataco/qwen3-embedding-8b) | The Qwen3 Embedding model series is specifically designed for text embedding and ranking tasks | 1408 |
| [xai/grok-imagine-image](https://replicate.com/xai/grok-imagine-image) | SOTA image model from xAI | 1403 |
| [cuuupid/idm-vton](https://replicate.com/cuuupid/idm-vton) | Best-in-class clothing virtual try on in the wild (non-commercial use only) | 1390 |
| [prunaai/stable-diffusion-cheetah](https://replicate.com/prunaai/stable-diffusion-cheetah) | This model is an optimised version of stable-diffusion by stability AI that is 3x faster and 3x cheaper. | 1372 |
| [chenxwh/sdxl-flash](https://replicate.com/chenxwh/sdxl-flash) | Fast sdxl with higher quality | 1363 |
| [runwayml/gen4-aleph](https://replicate.com/runwayml/gen4-aleph) | A new way to edit, transform and generate video | 1293 |
| [google/upscaler](https://replicate.com/google/upscaler) | Upscale images 2x or 4x times | 1267 |
| [aisha-ai-official/wai-nsfw-illustrious-v11](https://replicate.com/aisha-ai-official/wai-nsfw-illustrious-v11) | null | 1200 |
| [replicate/train-rvc-model](https://replicate.com/replicate/train-rvc-model) | Train your own custom RVC model | 1181 |
| [microsoft/omniparser-v2](https://replicate.com/microsoft/omniparser-v2) | OmniParser is a screen parsing tool to convert general GUI screen to structured elements. | 1169 |
| [bria/image-3.2](https://replicate.com/bria/image-3.2) | Commercial-ready, trained entirely on licensed data, text-to-image model. With only 4B parameters provides exceptional aesthetics and text rendering. Evaluated to be on par to other leading models in the market | 1154 |
| [meta/llama-4-scout-instruct](https://replicate.com/meta/llama-4-scout-instruct) | A 17 billion parameter model with 16 experts | 1103 |
| [datalab-to/marker](https://replicate.com/datalab-to/marker) | Convert PDF to markdown + JSON quickly with high accuracy | 1102 |
| [smoretalk/rembg-enhance](https://replicate.com/smoretalk/rembg-enhance) | A background removal model enhanced with better matting | 1101 |
| [black-forest-labs/flux-2-flex](https://replicate.com/black-forest-labs/flux-2-flex) | Max-quality image generation and editing with support for ten reference images | 1068 |
| [wan-video/wan2.6-i2v-flash](https://replicate.com/wan-video/wan2.6-i2v-flash) | Image-to-video generation with optional audio, multi-shot narrative support, and faster inference | 1064 |
| [lucataco/qwen2-vl-7b-instruct](https://replicate.com/lucataco/qwen2-vl-7b-instruct) | Latest model in the Qwen family for chatting with video and image models | 1060 |
| [fofr/sdxl-fresh-ink](https://replicate.com/fofr/sdxl-fresh-ink) | SDXL fine-tuned on photos of freshly inked tattoos | 1029 |
| [fofr/style-transfer](https://replicate.com/fofr/style-transfer) | Transfer the style of one image to another | 1003 |
| [codeslake/ifan-defocus-deblur](https://replicate.com/codeslake/ifan-defocus-deblur) | Removes defocus blur in an image | 1000 |
| [anthropic/claude-4.5-haiku](https://replicate.com/anthropic/claude-4.5-haiku) | Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed | 990 |
| [qwen/qwen3-235b-a22b-instruct-2507](https://replicate.com/qwen/qwen3-235b-a22b-instruct-2507) | Updated Qwen3 model for instruction following | 977 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 945 |
| [resemble-ai/chatterbox-turbo](https://replicate.com/resemble-ai/chatterbox-turbo) | The fastest open source TTS model without sacrificing quality. | 942 |
| [resemble-ai/resemble-enhance](https://replicate.com/resemble-ai/resemble-enhance) | AI-driven audio enhancement for your audio files, powered by Resemble AI | 923 |
| [simbrams/ri](https://replicate.com/simbrams/ri) | Realistic Inpainting with ControlNET (M-LSD + SEG) | 918 |
| [openai/gpt-5-structured](https://replicate.com/openai/gpt-5-structured) | GPT-5 with support for structured outputs, web search and custom tools | 917 |
| [deepseek-ai/deepseek-v3.1](https://replicate.com/deepseek-ai/deepseek-v3.1) | Latest hybrid thinking model from Deepseek | 908 |
| [minimax/hailuo-02](https://replicate.com/minimax/hailuo-02) | Hailuo 2 is a text-to-video and image-to-video model that can make 6s or 10s videos at 768p (standard) or 1080p (pro). It excels at real world physics. | 892 |
| [declare-lab/tangoflux](https://replicate.com/declare-lab/tangoflux) | Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization | 872 |
| [openai/gpt-oss-20b](https://replicate.com/openai/gpt-oss-20b) | 20b open-weight language model from OpenAI | 862 |
| [prunaai/z-image-turbo-img2img](https://replicate.com/prunaai/z-image-turbo-img2img) | Image 2 Image version of z-image-turbo with lora support. | 860 |
| [black-forest-labs/flux-schnell-lora](https://replicate.com/black-forest-labs/flux-schnell-lora) | The fastest image generation model tailored for fine-tuned use | 829 |
| [shreejalmaharjan-27/tiktok-short-captions](https://replicate.com/shreejalmaharjan-27/tiktok-short-captions) | Generate Tiktok-Style Captions powered by Whisper (GPU) | 814 |
| [sesamo-srl/bge-reranker-v2-m3](https://replicate.com/sesamo-srl/bge-reranker-v2-m3) | Newest reranker model from BAAI (https://huggingface.co/BAAI/bge-reranker-v2-m3). FP16 inference enabled. Normalize param available | 809 |
| [openai/dall-e-3](https://replicate.com/openai/dall-e-3) | An AI system that can create realistic images and art from a description in natural language. | 807 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 805 |
| [delta-lock/ponynai3](https://replicate.com/delta-lock/ponynai3) | Models fine-tuned from Pony-XL series. | 804 |
| [luma/photon](https://replicate.com/luma/photon) | High-quality image generation model optimized for creative professional workflows and ultra-high fidelity outputs | 793 |
| [lucataco/trim-video](https://replicate.com/lucataco/trim-video) | Simple tool to quickly trim a video or audio file | 776 |
| [sdxl-based/consistent-character](https://replicate.com/sdxl-based/consistent-character) | Create images of a given character in different poses | 767 |
| [ideogram-ai/ideogram-v3-quality](https://replicate.com/ideogram-ai/ideogram-v3-quality) | The highest quality Ideogram v3 model. v3 creates images with stunning realism, creative designs, and consistent styles | 759 |
| [codeplugtech/background_remover](https://replicate.com/codeplugtech/background_remover) | Remove background from image | 750 |
| [minimax/speech-2.6-hd](https://replicate.com/minimax/speech-2.6-hd) | MiniMax Speech 2.6 HD delivers studio-quality multilingual text-to-audio on Replicate with nuanced prosody, subtitle export, and premium voices | 744 |
| [minimax/speech-2.8-hd](https://replicate.com/minimax/speech-2.8-hd) | Minimax Speech 2.8 HD focuses on high-fidelity audio generation with features like studio-grade quality, flexible emotion control, multilingual support, and voice cloning capabilities | 733 |
| [wan-video/wan-2.2-t2v-fast](https://replicate.com/wan-video/wan-2.2-t2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B text-to-video | 733 |
| [zf-kbot/photo-to-anime](https://replicate.com/zf-kbot/photo-to-anime) | Convert images to anime style | 731 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 713 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 688 |
| [datalab-to/ocr](https://replicate.com/datalab-to/ocr) | Detect and transcribe text in images with accurate bounding boxes, layout analysis, reding order, and table recognition, in 90 languages | 686 |
| [reve/create](https://replicate.com/reve/create) | Image generation model from Reve | 683 |
| [openai/gpt-5.2](https://replicate.com/openai/gpt-5.2) | The best model for coding and agentic tasks across industries | 668 |
| [prunaai/flux-schnell](https://replicate.com/prunaai/flux-schnell) | This is a 3x faster FLUX.1 [schnell] model from Black Forest Labs, optimised with pruna with minimal quality loss. Contact us for more at pruna.ai | 648 |
| [ibm-granite/granite-vision-3.3-2b](https://replicate.com/ibm-granite/granite-vision-3.3-2b) | Granite-vision-3.3-2b is a compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. | 647 |
| [cureau/force-align-wordstamps](https://replicate.com/cureau/force-align-wordstamps) | Takes audio (mp3) and a "source-of-truth" audio transcript (string) as input and returns precise timestamps. | 640 |
| [sdxl-based/realvisxl-v3-multi-controlnet-lora](https://replicate.com/sdxl-based/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 636 |
| [nvidia/sana-sprint-1.6b](https://replicate.com/nvidia/sana-sprint-1.6b) | SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation | 631 |
| [lucataco/ltx-video-0.9.8-distilled](https://replicate.com/lucataco/ltx-video-0.9.8-distilled) | Generate native long-form video, with controllability | 630 |
| [fottoai/remove-bg-2](https://replicate.com/fottoai/remove-bg-2) | Remove image background with custom model to better result. | 626 |
| [rafaelgalle/whisper-diarization-advanced](https://replicate.com/rafaelgalle/whisper-diarization-advanced) | Ultra-fast, customizable speech-to-text and speaker diarization for noisy, multi-speaker audio. Includes advanced noise reduction, stereo channel support, and flexible audio preprocessing‚Äîideal for call centers, meetings, and podcasts. | 616 |
| [ibm-granite/granite-4.0-h-small](https://replicate.com/ibm-granite/granite-4.0-h-small) | Granite-4.0-H-Small is a 32B parameter long-context instruct model finetuned from Granite-4.0-H-Small-Base using a combination of open source instruction datasets with permissive license and internally collected synthetic datasets. | 613 |
| [anthropic/claude-opus-4.6](https://replicate.com/anthropic/claude-opus-4.6) | Anthropic's most intelligent model with state-of-the-art coding, reasoning, and agentic capabilities | 609 |
| [fpsorg/emoji](https://replicate.com/fpsorg/emoji) | Make Emoji with AI. | 600 |
| [black-forest-labs/flux-2-klein-9b-base](https://replicate.com/black-forest-labs/flux-2-klein-9b-base) | Un-distilled version of FLUX.2 [klein]. A foundation model for maximum flexibility and control | 598 |
| [openai/gpt-5.1](https://replicate.com/openai/gpt-5.1) | The best model for coding and agentic tasks with configurable reasoning effort. | 590 |
| [lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) | FLUX.1-Dev Multi LoRA Explorer | 589 |
| [recraft-ai/recraft-v3-svg](https://replicate.com/recraft-ai/recraft-v3-svg) | Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles. | 588 |
| [black-forest-labs/flux-kontext-dev-lora](https://replicate.com/black-forest-labs/flux-kontext-dev-lora) | FLUX.1 Kontext[dev] image editing model for running lora finetunes | 588 |
| [leonardoai/lucid-origin](https://replicate.com/leonardoai/lucid-origin) | Artistic and high-quality visuals with improved prompt adherence, diversity, and definition | 578 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 578 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 575 |
| [black-forest-labs/flux-1.1-pro-ultra-finetuned](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra-finetuned) | Inference model for FLUX 1.1 [pro] Ultra using custom `finetune_id`. Supports 4MP images and raw mode for realism | 562 |
| [zsxkib/tool-merge-images](https://replicate.com/zsxkib/tool-merge-images) | Merge multiple images into clean horizontal or vertical strips with precise alignment and sizing controls. | 557 |
| [flux-kontext-apps/cartoonify](https://replicate.com/flux-kontext-apps/cartoonify) | Turn your image into a cartoon with FLUX.1 Kontext [pro] | 553 |
| [sepal/audiogen](https://replicate.com/sepal/audiogen) | Generate sounds from a text prompt | 550 |
| [idea-research/ram-grounded-sam](https://replicate.com/idea-research/ram-grounded-sam) | A Strong Image Tagging Model with Segment Anything | 548 |
| [anthropic/claude-3.5-haiku](https://replicate.com/anthropic/claude-3.5-haiku) | Anthropic's fastest, most cost-effective model, with a 200K token context window (claude-3-5-haiku-20241022) | 536 |
| [mattsays/sam3-image](https://replicate.com/mattsays/sam3-image) | A unified foundation model for prompt-based segmentation in images and videos | 529 |
| [bytedance/flux-pulid](https://replicate.com/bytedance/flux-pulid) | ‚ö°Ô∏èFLUX PuLID: FLUX-dev based Pure and Lightning ID Customization via Contrastive Alignmentüé≠ | 525 |
| [ideogram-ai/ideogram-v3-balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced) | Balance speed, quality and cost. Ideogram v3 creates images with stunning realism, creative designs, and consistent styles | 517 |
| [pnyompen/sdxl-controlnet-lora-small](https://replicate.com/pnyompen/sdxl-controlnet-lora-small) | SDXL Canny controlnet with LoRA support. | 517 |
| [sakemin/all-in-one-music-structure-analyzer](https://replicate.com/sakemin/all-in-one-music-structure-analyzer) | Cog implementation of mir-aidj(Taejun Kim)'s 'All-In-One Music Structure Analyzer' | 512 |
| [minimax/speech-2.8-turbo](https://replicate.com/minimax/speech-2.8-turbo) | Minimax Speech 2.8 Turbo: Turn text into natural, expressive speech with voice cloning, emotion control, and support for 40+ languages | 505 |
| [idan054/better-video-merge](https://replicate.com/idan054/better-video-merge) | Fix Diffrent Sizes for each clip. Fork of lucataco/cog-video-merge.git | 502 |
| [appmeloncreator/platmoji-beta](https://replicate.com/appmeloncreator/platmoji-beta) | This is an emoji generator fine tuned with Flux. (btw thx so much for the support on this) | 474 |
| [resemble-ai/chatterbox](https://replicate.com/resemble-ai/chatterbox) | Generate expressive, natural speech. Features unique emotion control, instant voice cloning from short audio, and built-in watermarking. | 473 |
| [ideogram-ai/ideogram-character](https://replicate.com/ideogram-ai/ideogram-character) | Generate consistent characters from a single reference image. Outputs can be in many styles. You can also use inpainting to add your character to an existing image. | 470 |
| [ostris/flux-dev-lora-trainer](https://replicate.com/ostris/flux-dev-lora-trainer) | Fine-tune FLUX.1-dev using ai-toolkit | 470 |
| [lightricks/ltx-2-fast](https://replicate.com/lightricks/ltx-2-fast) | Ideal for rapid ideation and mobile workflows. Perfect for creators who need instant feedback, real-time previews, or high-throughput content. | 469 |
| [runwayml/gen4-turbo](https://replicate.com/runwayml/gen4-turbo) | Generate 5s and 10s 720p videos fast | 463 |
| [wan-video/wan-2.2-s2v](https://replicate.com/wan-video/wan-2.2-s2v) | Generate a video from an audio clip and a reference image | 462 |
| [openai/gpt-4o](https://replicate.com/openai/gpt-4o) | OpenAI's high-intelligence chat model | 456 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | üòä Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 451 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 448 |
| [stability-ai/stable-diffusion-3](https://replicate.com/stability-ai/stable-diffusion-3) | A text-to-image model with greatly improved performance in image quality, typography, complex prompt understanding, and resource-efficiency | 445 |
| [lucataco/ace-step](https://replicate.com/lucataco/ace-step) | A Step Towards Music Generation Foundation Model text2music | 442 |
| [minimax/hailuo-2.3](https://replicate.com/minimax/hailuo-2.3) | A high-fidelity video generation model optimized for realistic human motion, cinematic VFX, expressive characters, and strong prompt and style adherence across both text-to-video and image-to-video workflows | 439 |
| [meta/llama-2-70b](https://replicate.com/meta/llama-2-70b) | Base version of Llama 2, a 70 billion parameter language model from Meta. | 439 |
| [google/imagen-3-fast](https://replicate.com/google/imagen-3-fast) | A faster and cheaper Imagen 3 model, for when price or speed are more important than final image quality | 434 |
| [minimax/video-01](https://replicate.com/minimax/video-01) | Generate 6s videos with prompts or images. (Also known as Hailuo). Use a subject reference to make a video with a character and the S2V-01 model. | 434 |
| [aisha-ai-official/prefect-pony-xl-v5](https://replicate.com/aisha-ai-official/prefect-pony-xl-v5) | null | 434 |
| [prunaai/flux-2-fast](https://replicate.com/prunaai/flux-2-fast) | A step-distilled version of flux 2 down to 1s. | 431 |
| [deepseek-ai/deepseek-r1](https://replicate.com/deepseek-ai/deepseek-r1) | A reasoning model trained with reinforcement learning, on par with OpenAI o1 | 431 |
| [dashed/whisperx-subtitles-replicate](https://replicate.com/dashed/whisperx-subtitles-replicate) | Generates subtitles from audio using whisperX (faster-whisper-large-v3) | 429 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 428 |
| [fofr/expression-editor](https://replicate.com/fofr/expression-editor) | Quickly edit the expression of a face | 427 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 422 |
| [stability-ai/stable-audio-2.5](https://replicate.com/stability-ai/stable-audio-2.5) | Generate high-quality music and sound from text prompts | 414 |
| [black-forest-labs/flux-2-klein-4b-base](https://replicate.com/black-forest-labs/flux-2-klein-4b-base) | Un-distilled version of FLUX.2 [klein]. Optimized for fine-tuning, customization, and post-training workflows | 412 |
| [resemble-ai/chatterbox-multilingual](https://replicate.com/resemble-ai/chatterbox-multilingual) | Generate expressive, natural speech in 23 languages. Features instant voice cloning from short audio, emotion control, and seamless cross-language voice transfer. | 411 |
| [melgor/stabledesign_interiordesign](https://replicate.com/melgor/stabledesign_interiordesign) | Transfer empty room into fabulous interior design | 410 |
| [vectradmin/sdxl-v-transparent](https://replicate.com/vectradmin/sdxl-v-transparent) | null | 407 |
| [qwen/qwen-image-2512](https://replicate.com/qwen/qwen-image-2512) | Qwen Image 2512 is an improved version of Qwen Image with more realistic human generation, finer textures, and stronger text rendering | 401 |
| [topazlabs/video-upscale](https://replicate.com/topazlabs/video-upscale) | Video Upscaling from Topaz Labs | 400 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 396 |
| [black-forest-labs/flux-redux-dev](https://replicate.com/black-forest-labs/flux-redux-dev) | Open-weight image variation model. Create new versions while preserving key elements of your original. | 394 |
| [ideogram-ai/ideogram-v2-turbo](https://replicate.com/ideogram-ai/ideogram-v2-turbo) | A fast image model with state of the art inpainting, prompt comprehension and text rendering. | 387 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 387 |
| [wan-video/wan-2.2-animate-replace](https://replicate.com/wan-video/wan-2.2-animate-replace) | Use Wan 2.2 Animate to replace a character in a video scene | 383 |
| [deepseek-ai/deepseek-v3](https://replicate.com/deepseek-ai/deepseek-v3) | DeepSeek-V3-0324 is the leading non-reasoning model, a milestone for open source | 378 |
| [lucataco/realistic-vision-v5.1](https://replicate.com/lucataco/realistic-vision-v5.1) | Implementation of Realistic Vision v5.1 with VAE | 376 |
| [minimax/music-01](https://replicate.com/minimax/music-01) | Quickly generate up to 1 minute of music with lyrics and vocals in the style of a reference track | 368 |
| [lucataco/flux-dev-lora](https://replicate.com/lucataco/flux-dev-lora) | FLUX.1-Dev LoRA Explorer (DEPRECATED Please use: black-forest-labs/flux-dev-lora) | 367 |
| [fofr/color-matcher](https://replicate.com/fofr/color-matcher) | Color match and white balance fixes for images | 366 |
| [lucataco/wan-2.2-first-last-frame](https://replicate.com/lucataco/wan-2.2-first-last-frame) | Wan 2.2 First and Last Frame using 8-step inference w/ Lightning LoRA | 365 |
| [meta/sam-2](https://replicate.com/meta/sam-2) | SAM 2: Segment Anything v2 (for Images) | 361 |
| [minimax/hailuo-2.3-fast](https://replicate.com/minimax/hailuo-2.3-fast) | A lower-latency image-to-video version of Hailuo 2.3 that preserves core motion quality, visual consistency, and stylization performance while enabling faster iteration cycles. | 352 |
| [sourceful/riverflow-2.0-pro](https://replicate.com/sourceful/riverflow-2.0-pro) | Agentic image model optimized for robust, high-precision generations supporting font control | 347 |
| [astelvida/genmoji-gen](https://replicate.com/astelvida/genmoji-gen) | null | 346 |
| [wan-video/wan-2.5-i2v](https://replicate.com/wan-video/wan-2.5-i2v) | Alibaba Wan 2.5 Image to video generation with background audio | 344 |
| [black-forest-labs/flux-canny-dev](https://replicate.com/black-forest-labs/flux-canny-dev) | Open-weight edge-guided image generation. Control structure and composition using Canny edge detection. | 338 |
| [kwaivgi/kling-v1.6-pro](https://replicate.com/kwaivgi/kling-v1.6-pro) | Generate 5s and 10s videos in 1080p resolution | 335 |
| [fictions-ai/autocaption](https://replicate.com/fictions-ai/autocaption) | Automatically add captions to a video | 334 |
| [replicate/fast-flux-trainer](https://replicate.com/replicate/fast-flux-trainer) | Train subjects or styles faster than ever | 328 |
| [cjwbw/videocrafter](https://replicate.com/cjwbw/videocrafter) | VideoCrafter2: Text-to-Video and Image-to-Video Generation and Editing | 328 |
| [ideogram-ai/ideogram-v2a](https://replicate.com/ideogram-ai/ideogram-v2a) | Like Ideogram v2, but faster and cheaper | 327 |
| [google/veo-3-fast](https://replicate.com/google/veo-3-fast) | A faster and cheaper version of Google‚Äôs Veo 3 video model, with audio | 318 |
| [lightricks/ltx-video-0.9.7-distilled](https://replicate.com/lightricks/ltx-video-0.9.7-distilled) | Faster slight quality reduction compared to LTX-Video 13b | 316 |
| [sdxl-based/realvisxl-v3](https://replicate.com/sdxl-based/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 313 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 311 |
| [lqhl/realesrgan](https://replicate.com/lqhl/realesrgan) | Image restoration and face enhancement | 310 |
| [gewoonjaap/flux-emoji](https://replicate.com/gewoonjaap/flux-emoji) | Easily create emojis using Flux Dev | 303 |
| [saattrupdan/multilingual-e5-large-instruct](https://replicate.com/saattrupdan/multilingual-e5-large-instruct) | multilingual-e5-large-instruct: A multi-language text embedding model with custom query instructions. | 303 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 303 |
| [flux-kontext-apps/change-haircut](https://replicate.com/flux-kontext-apps/change-haircut) | Quickly change someone's hair style and hair color, powered by FLUX.1 Kontext [pro] | 299 |
| [openai/gpt-oss-120b](https://replicate.com/openai/gpt-oss-120b) | 120b open-weight language model from OpenAI | 294 |
| [runwayml/gen4-image-turbo](https://replicate.com/runwayml/gen4-image-turbo) | Gen-4 Image Turbo is cheaper and 2.5x faster than Gen-4 Image. An image model with references, use up to 3 reference images to create the exact image you need. Capture every angle. | 292 |
| [black-forest-labs/flux-depth-pro](https://replicate.com/black-forest-labs/flux-depth-pro) | Professional depth-aware image generation. Edit images while preserving spatial relationships. | 291 |
| [ibm-granite/granite-3.3-8b-instruct](https://replicate.com/ibm-granite/granite-3.3-8b-instruct) | Granite-3.3-8B-Instruct is a 8-billion parameter 128K context length language model fine-tuned for improved reasoning and instruction-following capabilities. | 291 |
| [cjwbw/sadtalker](https://replicate.com/cjwbw/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 288 |
| [arielreplicate/robust_video_matting](https://replicate.com/arielreplicate/robust_video_matting) | extract foreground of a video | 287 |
| [wan-video/wan-2.5-i2v-fast](https://replicate.com/wan-video/wan-2.5-i2v-fast) | Wan 2.5 image-to-video, optimized for speed | 286 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 286 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 279 |
| [meta/meta-llama-3-70b](https://replicate.com/meta/meta-llama-3-70b) | Base version of Llama 3, a 70 billion parameter language model from Meta. | 275 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 275 |
| [lucataco/deepseek-ocr](https://replicate.com/lucataco/deepseek-ocr) | Convert documents to markdown, extract raw text, and locate specific content | 273 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 272 |
| [asiryan/realism-xl](https://replicate.com/asiryan/realism-xl) | Realism XL Model (Text2Img, Img2Img and Inpainting) | 269 |
| [awerks/whisperx](https://replicate.com/awerks/whisperx) | Fast automatic speech recognition (70x realtime with large-v2) with word-level timestamps and speaker diarization. | 266 |
| [sync/lipsync-2-pro](https://replicate.com/sync/lipsync-2-pro) | Studio-grade lipsync in minutes, not weeks | 265 |
| [black-forest-labs/flux-canny-pro](https://replicate.com/black-forest-labs/flux-canny-pro) | Professional edge-guided image generation. Control structure and composition using Canny edge detection | 265 |
| [cjwbw/seamless_communication](https://replicate.com/cjwbw/seamless_communication) | SeamlessM4T‚ÄîMassively Multilingual & Multimodal Machine Translation | 265 |
| [openai/sora-2-pro](https://replicate.com/openai/sora-2-pro) | OpenAI's Most advanced synced-audio video generation | 259 |
| [ndreca/hunyuan3d-2](https://replicate.com/ndreca/hunyuan3d-2) | [Turbo Mode] Scaling Diffusion Models for High Resolution Textured 3D Assets Generation | 258 |
| [pixverse/pixverse-v4.5](https://replicate.com/pixverse/pixverse-v4.5) | Quickly make 5s or 8s videos at 540p, 720p or 1080p. It has enhanced motion, prompt coherence and handles complex actions well. | 252 |
| [alphanumericuser/kokoro-82m](https://replicate.com/alphanumericuser/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 249 |
| [elevenlabs/v3](https://replicate.com/elevenlabs/v3) | The most expressive Text to Speech model | 246 |
| [pseudoram/rvc-v2](https://replicate.com/pseudoram/rvc-v2) | Speech to speech with any RVC v2 trained AI voice | 243 |
| [fermatresearch/bisenet-faces](https://replicate.com/fermatresearch/bisenet-faces) | A Cog implementation of BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation [Face Parsing] (https://github.com/yakhyo/face-parsing). | 242 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 238 |
| [minimax/voice-cloning](https://replicate.com/minimax/voice-cloning) | Clone voices to use with Minimax's speech-02-hd and speech-02-turbo | 236 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 234 |
| [aisha-ai-official/pony-realism-v2.2](https://replicate.com/aisha-ai-official/pony-realism-v2.2) | null | 233 |
| [arielreplicate/deoldify_image](https://replicate.com/arielreplicate/deoldify_image) | Add colours to old images | 230 |
| [pixverse/pixverse-v5](https://replicate.com/pixverse/pixverse-v5) | Create 5s-8s videos with enhanced character movement, visual effects, and exclusive 1080p-8s support. Optimized for anime characters and complex actions | 229 |
| [aaronaftab/mirage-ghibli](https://replicate.com/aaronaftab/mirage-ghibli) | Ghiblify any image, 10x cheaper/faster than GPT 4o | 229 |
| [recraft-ai/recraft-20b-svg](https://replicate.com/recraft-ai/recraft-20b-svg) | Affordable and fast vector images | 228 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 228 |
| [shreejalmaharjan-27/website-screenshot](https://replicate.com/shreejalmaharjan-27/website-screenshot) | Capture a website screenshot | 227 |
| [devgmstudios/pony-realism-v23](https://replicate.com/devgmstudios/pony-realism-v23) | Latest Pony Realism Model. Try it with WEIGHTS on creatorframes.com | 225 |
| [colinmcdonnell22/ghiblify-3](https://replicate.com/colinmcdonnell22/ghiblify-3) | null | 225 |
| [zust-ai/supir](https://replicate.com/zust-ai/supir) | null | 224 |
| [chenxwh/depth-anything-v2](https://replicate.com/chenxwh/depth-anything-v2) | Depth estimation with faster inference speed, fewer parameters, and higher depth accuracy. | 223 |
| [lightricks/ltx-2-distilled](https://replicate.com/lightricks/ltx-2-distilled) | LTX-2: The first open source audio-video model | 214 |
| [wan-video/wan-2.6-i2v](https://replicate.com/wan-video/wan-2.6-i2v) | Alibaba Wan 2.6 image to video generation model | 214 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 214 |
| [bytedance/latentsync](https://replicate.com/bytedance/latentsync) | LatentSync: generate high-quality lip sync animations | 214 |
| [prunaai/p-image-edit-lora](https://replicate.com/prunaai/p-image-edit-lora) | Use trained LoRAs from the https://replicate.com/prunaai/p-image-edit-trainer. Find or contribute LoRAs here: https://huggingface.co/collections/PrunaAI/p-image-edit-loras. | 211 |
| [lucataco/video-merge](https://replicate.com/lucataco/video-merge) | Simple tool to merge together separate video snippets | 210 |
| [fofr/latent-consistency-model](https://replicate.com/fofr/latent-consistency-model) | Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet | 210 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 209 |
| [nvidia/sana](https://replicate.com/nvidia/sana) | A fast image model with wide artistic range and resolutions up to 4096x4096 | 205 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 205 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | Integral cog of doiwear.it | 203 |
| [flux-kontext-apps/text-removal](https://replicate.com/flux-kontext-apps/text-removal) | Remove all text from an image with FLUX.1 Kontext | 199 |
| [google/veo-3](https://replicate.com/google/veo-3) | Sound on: Google‚Äôs flagship Veo 3 text to video model, with audio | 198 |
| [minimax/music-1.5](https://replicate.com/minimax/music-1.5) | Music-1.5: Full-length songs (up to 4 mins) with natural vocals & rich instrumentation | 198 |
| [meta/llama-guard-4-12b](https://replicate.com/meta/llama-guard-4-12b) | null | 198 |
| [aisha-ai-official/likereality-pony-v1](https://replicate.com/aisha-ai-official/likereality-pony-v1) | null | 198 |
| [recraft-ai/recraft-20b](https://replicate.com/recraft-ai/recraft-20b) | Affordable and fast images | 193 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 193 |
| [xlabs-ai/flux-dev-controlnet](https://replicate.com/xlabs-ai/flux-dev-controlnet) | XLabs v3 canny, depth and soft edge controlnets for Flux.1 Dev | 192 |
| [perceptron-ai-inc/isaac-0.1](https://replicate.com/perceptron-ai-inc/isaac-0.1) | an open-source, 2B-parameter model built for real-world applications | 191 |
| [uglyrobot/sora2-watermark-remover](https://replicate.com/uglyrobot/sora2-watermark-remover) | Removes the watermark from Sora 2 videos using a trained model and IOpaint | 191 |
| [minimax/hailuo-02-fast](https://replicate.com/minimax/hailuo-02-fast) | A low cost and fast version of Hailuo 02. Generate 6s and 10s videos in 512p | 185 |
| [fofr/toolkit](https://replicate.com/fofr/toolkit) | Video toolkit ‚Äì convert, make GIFs, extract audio | 183 |
| [bytedance/omni-human-1.5](https://replicate.com/bytedance/omni-human-1.5) | A film-grade digital human model that generates realistic video from a single image, audio clip, and optional text prompt. | 178 |
| [lucataco/video-audio-merge](https://replicate.com/lucataco/video-audio-merge) | merge a video and an audio file | 178 |
| [fermatresearch/sdxl-controlnet-lora](https://replicate.com/fermatresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 174 |
| [georgedavila/bart-large-mnli-classifier](https://replicate.com/georgedavila/bart-large-mnli-classifier) | Zero-shot classifier which classifies text into categories of your choosing. Returns a dictionary of the most likely class and all class likelihoods. | 173 |
| [bytedance/dreamactor-m2.0](https://replicate.com/bytedance/dreamactor-m2.0) | Animate any character, humans, cartoons, animals, even non-humans, from a single image + driving video | 167 |
| [bria/expand-image](https://replicate.com/bria/expand-image) | Bria Expand expands images beyond their borders in high quality. Resizing the image by generating new pixels to expand to the desired aspect ratio. Trained exclusively on licensed data for safe and risk-free commercial use | 167 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 164 |
| [reve/edit](https://replicate.com/reve/edit) | Image editing model from Reve | 163 |
| [xlabs-ai/flux-dev-realism](https://replicate.com/xlabs-ai/flux-dev-realism) | FLUX.1-dev with XLabs-AI‚Äôs realism lora | 163 |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | Fast FLUX DEV -> Flux Controlnet Canny, Controlnet Depth , Controlnet Line Art, Controlnet Upscaler - You can use just one controlnet or All - LORAs: HyperFlex LoRA , Add Details LoRA , Realism LoRA | 162 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 161 |
| [openai/o4-mini](https://replicate.com/openai/o4-mini) | OpenAI's fast, lightweight reasoning model | 160 |
| [tencent/hunyuan-3d-3.1](https://replicate.com/tencent/hunyuan-3d-3.1) | 3D models with texture fidelity and geometry precision | 159 |
| [usamaehsan/qwen-image-edit-fastest-2](https://replicate.com/usamaehsan/qwen-image-edit-fastest-2) | 400+ images in 1$ 1024 resolution// 2s /img on L40S GPU, check description and examples | 155 |
| [openai/gpt-4.1](https://replicate.com/openai/gpt-4.1) | OpenAI's Flagship GPT model for complex tasks. | 154 |
| [logerzhu/ad-inpaint](https://replicate.com/logerzhu/ad-inpaint) | Product advertising image generator | 154 |
| [sync/lipsync-2](https://replicate.com/sync/lipsync-2) | Generate realistic lipsyncs with Sync Labs' 2.0 model | 153 |
| [tmappdev/change_video_bg](https://replicate.com/tmappdev/change_video_bg) | Change or Replace Video Background with any Image | 153 |
| [lightricks/ltx-2-pro](https://replicate.com/lightricks/ltx-2-pro) | Delivers high visual fidelity with fast turnaround. Great for daily content creation, marketing teams, and iterative creative workflows. | 151 |
| [okaris/live-portrait](https://replicate.com/okaris/live-portrait) | null | 151 |
| [flux-kontext-apps/multi-image-kontext-pro](https://replicate.com/flux-kontext-apps/multi-image-kontext-pro) | An experimental model with FLUX Kontext Pro that can combine two input images | 149 |
| [google/lyria-2](https://replicate.com/google/lyria-2) | Lyria 2 is a music generation model that produces 48kHz stereo audio through text-based prompts | 147 |
| [stability-ai/stable-diffusion-3.5-medium](https://replicate.com/stability-ai/stable-diffusion-3.5-medium) | 2.5 billion parameter image model with improved MMDiT-X architecture | 147 |
| [kwaivgi/kling-o1](https://replicate.com/kwaivgi/kling-o1) | Modify an existing video through natural-language commands, changing subjects, environments, and visual style while preserving the original motion and timing. | 142 |
| [bytedance/bagel](https://replicate.com/bytedance/bagel) | ü•ØByteDance Seed's Bagel Unified multimodal AI that generates images, edits images, and understands images in one 7B parameter modelü•Ø | 141 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 141 |
| [catacolabs/cartoonify](https://replicate.com/catacolabs/cartoonify) | Turn your image into a cartoon | 140 |
| [luma/reframe-video](https://replicate.com/luma/reframe-video) | Change the aspect ratio of any video up to 30 seconds long, outputs will be 720p | 138 |
| [rhelsing/basic-pitch](https://replicate.com/rhelsing/basic-pitch) | Spotify's Basic Pitch Model | 137 |
| [flux-kontext-apps/face-to-many-kontext](https://replicate.com/flux-kontext-apps/face-to-many-kontext) | Become a character, in style | 136 |
| [ahmdyassr/detect-crop-face](https://replicate.com/ahmdyassr/detect-crop-face) | A simple model to detect and crop face found in image, made for https://outfit.fm | 135 |
| [jd7h/propainter](https://replicate.com/jd7h/propainter) | Object removal, video completion and video outpainting | 135 |
| [lilekitty/kaneko-gen](https://replicate.com/lilekitty/kaneko-gen) | Generates unrestricted images from text prompts using a fine-tuned Stable Diffusion model | 133 |
| [kwaivgi/kling-lip-sync](https://replicate.com/kwaivgi/kling-lip-sync) | Add lip-sync to any video with an audio file or text | 132 |
| [bria/increase-resolution](https://replicate.com/bria/increase-resolution) | Bria Increase resolution upscales the resolution of any image. It increases resolution using a dedicated upscaling method that preserves the original image content without regeneration. | 130 |
| [lebonze/museai](https://replicate.com/lebonze/museai) | I fed the beast my oil paintings, made in the south of France. (version ec0d4305 is my fav) | 130 |
| [stability-ai/stable-diffusion-img2img](https://replicate.com/stability-ai/stable-diffusion-img2img) | Generate a new image from an input image with Stable Diffusion | 130 |
| [xinntao/esrgan](https://replicate.com/xinntao/esrgan) | Image 4x super-resolution | 130 |
| [flux-kontext-apps/professional-headshot](https://replicate.com/flux-kontext-apps/professional-headshot) | Create a professional headshot photo from any single image | 129 |
| [bria/generate-background](https://replicate.com/bria/generate-background) | Bria Background Generation allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use | 127 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 127 |
| [xai/grok-4](https://replicate.com/xai/grok-4) | Grok 4 is xAI‚Äôs most advanced reasoning model. Excels at logical thinking and in-depth analysis. Ideal for insightful discussions and complex problem-solving. | 126 |
| [flux-kontext-apps/multi-image-kontext-max](https://replicate.com/flux-kontext-apps/multi-image-kontext-max) | An experimental FLUX Kontext model that can combine two input images | 126 |
| [reve/edit-fast](https://replicate.com/reve/edit-fast) | Reve's fast image edit model at only $0.01 per edit | 124 |
| [okaris/roop](https://replicate.com/okaris/roop) | chameleonn: one-click face swap (formerly roop) | 122 |
| [lucataco/hermes-2-pro-llama-3-8b](https://replicate.com/lucataco/hermes-2-pro-llama-3-8b) | Hermes 2 Pro is an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house | 120 |
| [wan-video/wan-2.5-t2v-fast](https://replicate.com/wan-video/wan-2.5-t2v-fast) | Wan 2.5 text-to-video, optimized for speed | 118 |
| [ardianfe/demucs-prod](https://replicate.com/ardianfe/demucs-prod) | sound separation with demucs | 115 |
| [replicate/seamless-texture](https://replicate.com/replicate/seamless-texture) | null | 114 |
| [lucataco/sadtalker](https://replicate.com/lucataco/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 112 |
| [lucataco/vectorized-dot-grid](https://replicate.com/lucataco/vectorized-dot-grid) | Vectorized dot grid - by Brett from Designjoy | 110 |
| [veed/fabric-1.0](https://replicate.com/veed/fabric-1.0) | VEED Fabric 1.0 is an image-to-video API that turns any image into a talking video | 109 |
| [bria/genfill](https://replicate.com/bria/genfill) | Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use. | 109 |
| [anthropic/claude-3.5-sonnet](https://replicate.com/anthropic/claude-3.5-sonnet) | Anthropic's most intelligent language model to date, with a 200K token context window and image understanding (claude-3-5-sonnet-20241022) | 109 |
| [juergengunz/real-esrgan-v2](https://replicate.com/juergengunz/real-esrgan-v2) | Real-ESRGAN Upscale with AI Face Correction | 109 |
| [havocy28/ai-detector](https://replicate.com/havocy28/ai-detector) | Detect AI Generated Text with Fast-DetectGPT | 109 |
| [minimax/video-01-live](https://replicate.com/minimax/video-01-live) | An image-to-video (I2V) model specifically trained for Live2D and general animation use cases | 108 |
| [lightweight-ai/model1](https://replicate.com/lightweight-ai/model1) | flux_schnell model img2img inference | 107 |
| [aisha-ai-official/illust3relustion](https://replicate.com/aisha-ai-official/illust3relustion) | null | 107 |
| [twn39/lama](https://replicate.com/twn39/lama) | ü¶ô LaMa Image Inpainting, Resolution-robust Large Mask Inpainting with Fourier Convolutions, WACV 2022 | 106 |
| [skullycute/prefectillustriousxlv60](https://replicate.com/skullycute/prefectillustriousxlv60) | Anime Illust model | 104 |
| [pixverse/pixverse-v5.6](https://replicate.com/pixverse/pixverse-v5.6) | Latest video model from Pixverse with astonishing physics | 103 |
| [littlemonsterzhang/wai90_sdxl](https://replicate.com/littlemonsterzhang/wai90_sdxl) | WAI-NSFW-illustrious-SDXL  v.90 | 102 |
| [okaris/omni-zero](https://replicate.com/okaris/omni-zero) | Omni-Zero: A diffusion pipeline for zero-shot stylized portrait creation. | 101 |
