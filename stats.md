# Model Stats
## New Models
- https://replicate.com/batouresearch/magic-style-transfer
- https://replicate.com/camenduru/animatediff-lightning-4-step
- https://replicate.com/cjwbw/animagine-xl-3.1
- https://replicate.com/cjwbw/starcoder2-15b
- https://replicate.com/jd7h/open-sora-512
- https://replicate.com/sepehr/mirage-gpu

## Removed Models
- https://replicate.com/midllle/material-maker

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [batouresearch/magic-style-transfer](https://replicate.com/batouresearch/magic-style-transfer) | An image in the style of the other one. I strongly suggest to upscale the results with Clarity AI | 57 | 57 | 100.00% |
| [camenduru/animatediff-lightning-4-step](https://replicate.com/camenduru/animatediff-lightning-4-step) | AnimateDiff-Lightning: Cross-Model Diffusion Distillation | 295 | 295 | 100.00% |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 193 | 193 | 100.00% |
| [cjwbw/starcoder2-15b](https://replicate.com/cjwbw/starcoder2-15b) | Language Models for Code | 11 | 11 | 100.00% |
| [jd7h/open-sora-512](https://replicate.com/jd7h/open-sora-512) | Open-Sora: Democratizing Efficient Video Production for All. This is the 512x512 video generation variant. | 22 | 22 | 100.00% |
| [sepehr/mirage-gpu](https://replicate.com/sepehr/mirage-gpu) | null | 244 | 244 | 100.00% |
| [cjwbw/cogvlm](https://replicate.com/cjwbw/cogvlm) | powerful open-source visual language model | 68435 | 82412 | 83.04% |
| [peter65374/openbuddy-mistral-7b](https://replicate.com/peter65374/openbuddy-mistral-7b) | Openbuddy finetuned mistral-7b in GPTQ quantization in 4bits by TheBloke | 26 | 65 | 40.00% |
| [danielguedesb/pix2pix](https://replicate.com/danielguedesb/pix2pix) | null | 63 | 163 | 38.65% |
| [zelenioncode/e56b28f4-4504-454b-8c04-89a970cce61a](https://replicate.com/zelenioncode/e56b28f4-4504-454b-8c04-89a970cce61a) | Model for the AiPicture | 12 | 34 | 35.29% |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 532369 | 1531548 | 34.76% |
| [codingdudecom/sdxl-mandala](https://replicate.com/codingdudecom/sdxl-mandala) | SDXL model for mandalas coloring pages and coloring book designs | 13 | 39 | 33.33% |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 10513 | 37139 | 28.31% |
| [k-amir/ootdifussiondc](https://replicate.com/k-amir/ootdifussiondc) | Virtual dressing room fullbody | 53 | 221 | 23.98% |
| [camenduru/apisr](https://replicate.com/camenduru/apisr) | APISR: Anime Production Inspired Real-World Anime Super-Resolution | 31 | 130 | 23.85% |
| [havocy28/ai-detector](https://replicate.com/havocy28/ai-detector) | Detect AI Generated Text | 15 | 69 | 21.74% |
| [wolverinn/realistic-background](https://replicate.com/wolverinn/realistic-background) | replace background with Stable Diffusion and ControlNet | 6427 | 32529 | 19.76% |
| [ieit-yuan/yuan2.0-2b-februa](https://replicate.com/ieit-yuan/yuan2.0-2b-februa) | Yuan2.0 is a new generation LLM developed by IEIT System, enhanced the model's understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects. | 5 | 27 | 18.52% |
| [growthmkt/virtualtryon](https://replicate.com/growthmkt/virtualtryon) | null | 74 | 435 | 17.01% |
| [erickluis00/all-in-one-audio](https://replicate.com/erickluis00/all-in-one-audio) | AI Music Structure Analyzer + Stem Splitter using Demucs & Mdx-Net with Python-Audio-Separator | 12 | 74 | 16.22% |
| [expa-ai/diffuser-c-c-2024](https://replicate.com/expa-ai/diffuser-c-c-2024) | null | 91 | 611 | 14.89% |
| [ieit-yuan/yuan2.0-51b](https://replicate.com/ieit-yuan/yuan2.0-51b) | Yuan2.0 is a new generation LLM developed by IEIT System, enhanced the model's understanding of semantics, mathematics, reasoning, code, knowledge, and other aspects. | 4 | 27 | 14.81% |
| [wolverinn/segment-selected-object](https://replicate.com/wolverinn/segment-selected-object) | segment anything & remove anything | 1 | 7 | 14.29% |
| [copilot-us/maria-prymachenko](https://replicate.com/copilot-us/maria-prymachenko) | Inspired by the vibrant and imaginative style of Ukrainian folk artist Maria Prymachenko, this AI model specializes in creating whimsical and colorful artworks that reflect the essence of traditional folklore and nature themes. | 21 | 151 | 13.91% |
| [adirik/realvisxl-v4.0-lightning](https://replicate.com/adirik/realvisxl-v4.0-lightning) | Photorealism with RealVisXL V4.0 Lightning | 330 | 2396 | 13.77% |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | 34821 | 254496 | 13.68% |
| [ninehills/bge-reranker-large](https://replicate.com/ninehills/bge-reranker-large) | BAAI/bge-reranker-large Model with fp16 | 19 | 146 | 13.01% |
| [myaiteam2/audio-trimmer-with-fade](https://replicate.com/myaiteam2/audio-trimmer-with-fade) | I been making Ai music and keep trying to end the song and waste alot of credits, so instead i just coded a audio trimmer with a fade last 2.5 seconds options ha. Enjoy! | 2 | 16 | 12.50% |
| [lucataco/olmo-7b](https://replicate.com/lucataco/olmo-7b) | OLMo is a series of Open Language Models designed to enable the science of language models | 6 | 49 | 12.24% |
| [meepo-pro-player/invoker](https://replicate.com/meepo-pro-player/invoker) | null | 345 | 2842 | 12.14% |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Twitter/X: @philz1337x | 3963 | 33997 | 11.66% |
| [tvytlx/llama7b](https://replicate.com/tvytlx/llama7b) | null | 9 | 83 | 10.84% |
| [cudanexus/stickergp](https://replicate.com/cudanexus/stickergp) | null | 13 | 120 | 10.83% |
| [growthmkt/prompt](https://replicate.com/growthmkt/prompt) | null | 35 | 327 | 10.70% |
| [vetkastar/image_tune](https://replicate.com/vetkastar/image_tune) | Applies various image effects and transformations to enhance and manipulate images. | 48 | 458 | 10.48% |
| [adirik/sdxl-prompt-to-prompt](https://replicate.com/adirik/sdxl-prompt-to-prompt) | Image editing with Prompt-to-Prompt for SDXL | 14 | 139 | 10.07% |
| [hamelsmu/honeycomb-4-awq](https://replicate.com/hamelsmu/honeycomb-4-awq) | Honeycomb NLQ Generator hosted with vLLM + AWQ Quantized | 1 | 10 | 10.00% |
| [adirik/multilingual-e5-base](https://replicate.com/adirik/multilingual-e5-base) | Multilingual E5-large language embedding model | 1 | 10 | 10.00% |
| [fofr/replicate-tshirt](https://replicate.com/fofr/replicate-tshirt) | Tshirt designs with a hidden Replicate logo | 31 | 311 | 9.97% |
| [turian/insanely-fast-whisper-with-video](https://replicate.com/turian/insanely-fast-whisper-with-video) | whisper-large-v3, incredibly fast, with video transcription | 421 | 4233 | 9.95% |
| [lucataco/playground-v2.5-1024px-aesthetic](https://replicate.com/lucataco/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 3344 | 35721 | 9.36% |
| [cjwbw/c4ai-command-r-v01](https://replicate.com/cjwbw/c4ai-command-r-v01) | CohereForAI c4ai-command-r-v01, Quantized model through bitsandbytes, 8-bit precision | 2 | 22 | 9.09% |
| [fofr/frames-to-video](https://replicate.com/fofr/frames-to-video) | Convert a set of frames to a video | 85 | 958 | 8.87% |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | null | 9 | 102 | 8.82% |
| [adirik/realvisxl-v4.0](https://replicate.com/adirik/realvisxl-v4.0) | Photorealism with RealVisXL V4.0 | 464 | 5361 | 8.66% |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 15214 | 182902 | 8.32% |
| [philz1337x/multidiffusion-upscaler](https://replicate.com/philz1337x/multidiffusion-upscaler) | High resolution image Upscaler and Enhancer. Twitter/X: @philz1337x | 70 | 870 | 8.05% |
| [camenduru/dynami-crafter-interpolation-320x512](https://replicate.com/camenduru/dynami-crafter-interpolation-320x512) | DynamiCrafter: Animating Open-domain Images with Video Diffusion Priors | 22 | 279 | 7.89% |
| [jyoung105/playground-v2.5](https://replicate.com/jyoung105/playground-v2.5) | State-of-the-art text to image "with turbo speed" | 858 | 10904 | 7.87% |
| [nateraw/defog-sqlcoder-7b-2](https://replicate.com/nateraw/defog-sqlcoder-7b-2) | A capable large language model for natural language to SQL generation. | 8 | 104 | 7.69% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [yan-ops/face_swap](https://replicate.com/yan-ops/face_swap) | null | 946831 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 532369 |
| [pengdaqian2020/image-tagger](https://replicate.com/pengdaqian2020/image-tagger) | image tagger | 259721 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 212043 |
| [abiruyt/text-extract-ocr](https://replicate.com/abiruyt/text-extract-ocr) | A simple OCR Model that can easily extract text from an image. | 210717 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Bootstrapping Language-Image Pre-training | 197310 |
| [peter65374/face-swap-detect](https://replicate.com/peter65374/face-swap-detect) | Multiple faces swap and detection by through insightface lib with GFPGAN enhancement. | 170598 |
| [mistralai/mixtral-8x7b-instruct-v0.1](https://replicate.com/mistralai/mixtral-8x7b-instruct-v0.1) | The Mixtral-8x7B-instruct-v0.1 Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts tuned to be a helpful assistant. | 160978 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 74879 |
| [cjwbw/cogvlm](https://replicate.com/cjwbw/cogvlm) | powerful open-source visual language model | 68435 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 62567 |
| [lucataco/sdxl-lightning-4step](https://replicate.com/lucataco/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 56567 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 48615 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 43757 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 40598 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 36871 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 35179 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | 34821 |
| [mistralai/mistral-7b-instruct-v0.2](https://replicate.com/mistralai/mistral-7b-instruct-v0.2) | The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1. | 34775 |
| [ai-forever/kandinsky-2.2](https://replicate.com/ai-forever/kandinsky-2.2) | multilingual text2image latent diffusion model | 32238 |
| [replicate/hello-world](https://replicate.com/replicate/hello-world) | A tiny model that says hello | 26189 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 25811 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 20247 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 19957 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 18813 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 18442 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 17509 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 15214 |
| [lucataco/faceswap](https://replicate.com/lucataco/faceswap) | (Research & Non-commercial use only) Faceswap with face enhancer | 14544 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 14077 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 13193 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 13044 |
| [lucataco/ssd-1b](https://replicate.com/lucataco/ssd-1b) | Segmind Stable Diffusion Model (SSD-1B) is a distilled 50% smaller version of SDXL, offering a 60% speedup while maintaining high-quality text-to-image generation capabilities | 11781 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 11038 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 10513 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 10441 |
| [okaris/roop](https://replicate.com/okaris/roop) | chameleonn: one-click face swap (formerly roop) | 10010 |
| [lucataco/proteus-v0.2](https://replicate.com/lucataco/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 9097 |
| [lucataco/nsfw_image_detection](https://replicate.com/lucataco/nsfw_image_detection) | Falcons.ai Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 7509 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 7349 |
| [meta/llama-2-13b-chat](https://replicate.com/meta/llama-2-13b-chat) | A 13 billion parameter language model from Meta, fine tuned for chat completions | 7229 |
| [meta/llama-2-70b-chat](https://replicate.com/meta/llama-2-70b-chat) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 7026 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 6933 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 6816 |
| [konieshadow/fooocus-api](https://replicate.com/konieshadow/fooocus-api) | Third party Fooocus replicate model | 6724 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 6509 |
| [wolverinn/realistic-background](https://replicate.com/wolverinn/realistic-background) | replace background with Stable Diffusion and ControlNet | 6427 |
| [ai-forever/kandinsky-2](https://replicate.com/ai-forever/kandinsky-2) | text2img model trained on LAION HighRes and fine-tuned on internal datasets | 6037 |
| [batouresearch/magic-image-refiner](https://replicate.com/batouresearch/magic-image-refiner) | A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling. | 5960 |
| [omniedgeio/face-swap](https://replicate.com/omniedgeio/face-swap) | Face Swap | 5951 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 5917 |
| [daanelson/imagebind](https://replicate.com/daanelson/imagebind) | A model for text, audio, and image embeddings in one space | 5831 |
| [mistralai/mistral-7b-v0.1](https://replicate.com/mistralai/mistral-7b-v0.1) | A 7 billion parameter language model from Mistral. | 5785 |
| [cjwbw/anything-v4.0](https://replicate.com/cjwbw/anything-v4.0) | high-quality, highly detailed anime-style Stable Diffusion models | 5732 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 5599 |
| [lucataco/ms-img2vid](https://replicate.com/lucataco/ms-img2vid) | Turn any image into a video | 4791 |
| [pharmapsychotic/clip-interrogator](https://replicate.com/pharmapsychotic/clip-interrogator) | The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art! | 4755 |
| [mcai/babes-v2.0-img2img](https://replicate.com/mcai/babes-v2.0-img2img) | Generate a new image from an input image with Babes 2.0 | 4667 |
| [fofr/latent-consistency-model](https://replicate.com/fofr/latent-consistency-model) | Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet | 4631 |
| [batouresearch/sdxl-controlnet-lora](https://replicate.com/batouresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 4074 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Twitter/X: @philz1337x | 3963 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | 🦙 LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 3848 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 3808 |
| [prompthero/openjourney](https://replicate.com/prompthero/openjourney) | Stable Diffusion fine tuned on Midjourney v4 images. | 3698 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 3571 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 3532 |
| [lucataco/playground-v2.5-1024px-aesthetic](https://replicate.com/lucataco/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 3344 |
| [bfirsh/segformer-b0-finetuned-ade-512-512](https://replicate.com/bfirsh/segformer-b0-finetuned-ade-512-512) | null | 3190 |
| [heedster/realistic-vision-v5](https://replicate.com/heedster/realistic-vision-v5) | Deployment of Realistic vision v5.0 with xformers for fast inference | 3033 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 3030 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! 🤗 | 3003 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 2898 |
| [hnesk/whisper-wordtimestamps](https://replicate.com/hnesk/whisper-wordtimestamps) | openai/whisper with exposed settings for word_timestamps | 2861 |
| [fofr/realvisxl-v3](https://replicate.com/fofr/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 2819 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 2677 |
| [aussielabs/musicgen](https://replicate.com/aussielabs/musicgen) | Deployment of Meta's MusicGen | 2674 |
| [lucataco/realistic-vision-v5.1](https://replicate.com/lucataco/realistic-vision-v5.1) | Implementation of Realistic Vision v5.1 with VAE | 2558 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 2510 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 2477 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 2432 |
| [methexis-inc/img2prompt](https://replicate.com/methexis-inc/img2prompt) | Get an approximate text prompt, with style, matching an image.  (Optimized for stable-diffusion (clip ViT-L/14)) | 2196 |
| [usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5](https://replicate.com/usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5) | Inpainting || multi-controlnet || single-controlnet || ip-adapter || ip adapter face || ip adapter plus || No ip adapter | 2195 |
| [fofr/realvisxl-v3-multi-controlnet-lora](https://replicate.com/fofr/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 2195 |
| [fofr/any-comfyui-workflow](https://replicate.com/fofr/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/fofr/cog-comfyui | 2141 |
| [mejiabrayan/logoai](https://replicate.com/mejiabrayan/logoai) | null | 2012 |
| [spuuntries/flatdolphinmaid-8x7b-gguf](https://replicate.com/spuuntries/flatdolphinmaid-8x7b-gguf) | Undi95's FlatDolphinMaid 8x7B Mixtral Merge, GGUF Q5_K_M quantized by TheBloke. | 1997 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 1950 |
| [philz1337/controlnet-deliberate](https://replicate.com/philz1337/controlnet-deliberate) | Modify images with canny edge detection and Deliberate model twitter: @philipp1337x | 1927 |
| [mv-lab/swin2sr](https://replicate.com/mv-lab/swin2sr) | 3 Million Runs! AI Photorealistic Image Super-Resolution and Restoration | 1914 |
| [mistralai/mistral-7b-instruct-v0.1](https://replicate.com/mistralai/mistral-7b-instruct-v0.1) | An instruction-tuned 7 billion parameter language model from Mistral | 1851 |
| [yorickvp/llava-v1.6-34b](https://replicate.com/yorickvp/llava-v1.6-34b) | LLaVA v1.6: Large Language and Vision Assistant (Nous-Hermes-2-34B) | 1829 |
| [juergengunz/real-esrgan-v2](https://replicate.com/juergengunz/real-esrgan-v2) | Real-ESRGAN Upscale with AI Face Correction | 1824 |
| [orpatashnik/styleclip](https://replicate.com/orpatashnik/styleclip) | Text-Driven Manipulation of StyleGAN Imagery | 1800 |
| [lucataco/sdxl-clip-interrogator](https://replicate.com/lucataco/sdxl-clip-interrogator) | CLIP Interrogator for SDXL optimizes text prompts to match a given image | 1792 |
| [fofr/prompt-classifier](https://replicate.com/fofr/prompt-classifier) | Determines the toxicity of text to image prompts, llama-13b fine-tune. [SAFETY_RANKING] between 0 (safe) and 10 (toxic) | 1741 |
| [mark3labs/embeddings-gte-base](https://replicate.com/mark3labs/embeddings-gte-base) | General Text Embeddings (GTE) model. | 1685 |
| [konieshadow/fooocus-api-realistic](https://replicate.com/konieshadow/fooocus-api-realistic) | Third party Fooocus replicate model with preset 'realistic' | 1653 |
| [arielreplicate/deoldify_image](https://replicate.com/arielreplicate/deoldify_image) | Add colours to old images | 1636 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 1599 |
| [swartype/sdxl-pixar](https://replicate.com/swartype/sdxl-pixar) | Create Pixar poster easily with SDXL Pixar. | 1593 |
| [lambdal/text-to-pokemon](https://replicate.com/lambdal/text-to-pokemon) | Generate Pokémon from a text description | 1556 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 1535 |
| [pvitoria/chromagan](https://replicate.com/pvitoria/chromagan) | An Adversarial Approach for Picture Colorization | 1514 |
| [lucataco/animate-diff](https://replicate.com/lucataco/animate-diff) | Animate Your Personalized Text-to-Image Diffusion Models | 1507 |
| [catacolabs/sdxl-ad-inpaint](https://replicate.com/catacolabs/sdxl-ad-inpaint) | Product advertising image generator using SDXL | 1506 |
| [lucataco/vicuna-33b-v1.3](https://replicate.com/lucataco/vicuna-33b-v1.3) | lmsys/vicuna-33b-v1.3 | 1486 |
| [andreasjansson/sheep-duck-llama-2-70b-v1-1-gguf](https://replicate.com/andreasjansson/sheep-duck-llama-2-70b-v1-1-gguf) | null | 1445 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 1441 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 1342 |
| [lucataco/dreamshaper-xl-lightning](https://replicate.com/lucataco/dreamshaper-xl-lightning) | dreamshaper-xl-lightning is a Stable Diffusion model that has been fine-tuned on SDXL | 1267 |
| [lucataco/sdxl](https://replicate.com/lucataco/sdxl) | SDXL v1.0 - A text-to-image generative AI model that creates beautiful images | 1256 |
| [nateraw/goliath-120b](https://replicate.com/nateraw/goliath-120b) | An auto-regressive causal LM created by combining 2x finetuned Llama-2 70B into one. | 1193 |
| [lucataco/realvisxl2-lcm](https://replicate.com/lucataco/realvisxl2-lcm) | RealvisXL-v2.0 with LCM LoRA - requires fewer steps (4 to 8 instead of the original 40 to 50) | 1185 |
| [cloneofsimo/realistic_vision_v1.3](https://replicate.com/cloneofsimo/realistic_vision_v1.3) | null | 1181 |
| [prompthero/openjourney-v4](https://replicate.com/prompthero/openjourney-v4) | SD 1.5 trained with +124k MJv4 images by PromptHero | 1175 |
| [asiryan/blue-pencil-xl-v2](https://replicate.com/asiryan/blue-pencil-xl-v2) | Blue Pencil XL v2 Model (Text2Img, Img2Img and Inpainting) | 1166 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 1162 |
| [catacolabs/cartoonify](https://replicate.com/catacolabs/cartoonify) | Turn your image into a cartoon | 1160 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 1137 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ⚡️ Fast audio transcription | whisper v3 | speaker diarization | word level timestamps | prompt | 1132 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 1129 |
| [nateraw/video-llava](https://replicate.com/nateraw/video-llava) | Video-LLaVA: Learning United Visual Representation by Alignment Before Projection | 1124 |
| [rmokady/clip_prefix_caption](https://replicate.com/rmokady/clip_prefix_caption) | Simple image captioning model using CLIP and GPT-2 | 1093 |
| [fofr/sdxl-multi-controlnet-lora](https://replicate.com/fofr/sdxl-multi-controlnet-lora) | Multi-controlnet, lora loading, img2img, inpainting | 1043 |
| [cjwbw/anything-v3-better-vae](https://replicate.com/cjwbw/anything-v3-better-vae) | high-quality, highly detailed anime style stable-diffusion with better VAE | 1028 |
| [tstramer/material-diffusion](https://replicate.com/tstramer/material-diffusion) | Stable diffusion fork for generating tileable outputs using v1.5 model | 1026 |
| [daanelson/minigpt-4](https://replicate.com/daanelson/minigpt-4) | A model which generates text in response to an input image and prompt. | 1016 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting developed by the HF Diffusers team | 1015 |
| [batouresearch/high-resolution-controlnet-tile](https://replicate.com/batouresearch/high-resolution-controlnet-tile) | Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination. | 1005 |
| [anotherjesse/zeroscope-v2-xl](https://replicate.com/anotherjesse/zeroscope-v2-xl) | Zeroscope V2 XL & 576w | 1004 |
| [antoinelyset/openhermes-2-mistral-7b-awq](https://replicate.com/antoinelyset/openhermes-2-mistral-7b-awq) | null | 998 |
| [lucataco/codeformer](https://replicate.com/lucataco/codeformer) | Robust face restoration algorithm for old photos/AI-generated faces - (A40 GPU) | 974 |
| [jagilley/controlnet-depth2img](https://replicate.com/jagilley/controlnet-depth2img) | Modify images using depth maps | 971 |
| [catio-apps/photoaistudio-generate](https://replicate.com/catio-apps/photoaistudio-generate) | https://www.photoaistudio.com. Take a picture of your face and instantly get any profile picture you want. Only 1 photo, no training needed. | 960 |
| [batouresearch/open-dalle-1.1-lora](https://replicate.com/batouresearch/open-dalle-1.1-lora) | Better than SDXL at both prompt adherence and image quality, by dataautogpt3 | 945 |
| [asiryan/realistic-vision-v6.0-b1](https://replicate.com/asiryan/realistic-vision-v6.0-b1) | Realistic Vision V6.0 B1 Model (Text2Img, Img2Img and Inpainting) | 917 |
| [lucataco/realvisxl-v2.0](https://replicate.com/lucataco/realvisxl-v2.0) | Implementation of SDXL RealVisXL_V2.0 | 911 |
| [asiryan/juggernaut-xl-v7](https://replicate.com/asiryan/juggernaut-xl-v7) | Juggernaut XL v7 Model (Text2Img, Img2Img and Inpainting) | 903 |
| [nandycc/sdxl-app-icons](https://replicate.com/nandycc/sdxl-app-icons) | Fine tuned to generate awesome app icons, by aistartupkit.com | 897 |
| [mcai/dreamshaper-v6-img2img](https://replicate.com/mcai/dreamshaper-v6-img2img) | Generate a new image from an input image with DreamShaper V6 | 896 |
| [cjwbw/supir](https://replicate.com/cjwbw/supir) | Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This version uses LLaVA-13b for captioning. | 894 |
| [jyoung105/playground-v2.5](https://replicate.com/jyoung105/playground-v2.5) | State-of-the-art text to image "with turbo speed" | 858 |
| [lucataco/dreamshaper-xl-turbo](https://replicate.com/lucataco/dreamshaper-xl-turbo) | DreamShaper is a general purpose SD model that aims at doing everything well, photos, art, anime, manga. It's designed to match Midjourney and DALL-E. | 801 |
| [replicate-internal/llama-2-70b-triton](https://replicate.com/replicate-internal/llama-2-70b-triton) | null | 787 |
| [playgroundai/playground-v2-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2-1024px-aesthetic) | Playground v2 is a diffusion-based text-to-image generative model trained from scratch by the research team at Playground | 773 |
| [andreasjansson/stable-diffusion-inpainting](https://replicate.com/andreasjansson/stable-diffusion-inpainting) | Inpainting using RunwayML's stable-diffusion-inpainting checkpoint | 752 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 737 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 696 |
| [cjwbw/bigcolor](https://replicate.com/cjwbw/bigcolor) | Colorization using a Generative Color Prior for Natural Images | 677 |
| [lucataco/open-dalle-v1.1](https://replicate.com/lucataco/open-dalle-v1.1) | A unique fusion that showcases exceptional prompt adherence and semantic understanding, it seems to be a step above base SDXL and a step closer to DALLE-3 in terms of prompt comprehension | 663 |
| [yoyo-nb/thin-plate-spline-motion-model](https://replicate.com/yoyo-nb/thin-plate-spline-motion-model) | Thin-Plate Spline Motion Model for Image Animation | 656 |
| [luosiallen/latent-consistency-model](https://replicate.com/luosiallen/latent-consistency-model) | Synthesizing High-Resolution Images with Few-Step Inference | 655 |
| [fewjative/ultimate-sd-upscale](https://replicate.com/fewjative/ultimate-sd-upscale) | Ultimate SD Upscale with ControlNet Tile | 637 |
| [alaradirik/t2i-adapter-sdxl-depth-midas](https://replicate.com/alaradirik/t2i-adapter-sdxl-depth-midas) | Modify images using depth maps | 619 |
| [lucataco/proteus-v0.4-lightning](https://replicate.com/lucataco/proteus-v0.4-lightning) | ProteusV0.4: The Style Update - enhances stylistic capabilities, similar to Midjourney's approach, rather than advancing prompt comprehension | 607 |
| [mcai/deliberate-v2](https://replicate.com/mcai/deliberate-v2) | Generate a new image given any input text with Deliberate v2 | 600 |
| [timothybrooks/instruct-pix2pix](https://replicate.com/timothybrooks/instruct-pix2pix) | Edit images with human instructions | 599 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 592 |
| [lucataco/sdxl-lcm](https://replicate.com/lucataco/sdxl-lcm) | Latent Consistency Model (LCM): SDXL, distills the original model into a version that requires fewer steps (4 to 8 instead of the original 25 to 50) | 585 |
| [cjwbw/dreamshaper](https://replicate.com/cjwbw/dreamshaper) | Dream Shaper stable diffusion | 585 |
| [usamaehsan/instant-id-x-juggernaut](https://replicate.com/usamaehsan/instant-id-x-juggernaut) | null | 583 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 534 |
| [meta/codellama-13b](https://replicate.com/meta/codellama-13b) | A 13 billion parameter Llama tuned for code completion | 497 |
| [logerzhu/ad-inpaint](https://replicate.com/logerzhu/ad-inpaint) | Product advertising image generator | 497 |
| [mcai/edge-of-realism-v2.0-img2img](https://replicate.com/mcai/edge-of-realism-v2.0-img2img) | Generate a new image from an input image with Edge Of Realism - EOR v2.0 | 488 |
| [412392713/vtoonify](https://replicate.com/412392713/vtoonify) | Portrait Style Transfer with VToonify | 468 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 465 |
| [adirik/realvisxl-v4.0](https://replicate.com/adirik/realvisxl-v4.0) | Photorealism with RealVisXL V4.0 | 464 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 455 |
| [alaradirik/t2i-adapter-sdxl-openpose](https://replicate.com/alaradirik/t2i-adapter-sdxl-openpose) | Modify images using human pose | 449 |
| [andreasjansson/illusion](https://replicate.com/andreasjansson/illusion) | Monster Labs' control_v1p_sd15_qrcode_monster ControlNet on top of SD 1.5 | 446 |
| [cjwbw/rudalle-sr](https://replicate.com/cjwbw/rudalle-sr) | Real-ESRGAN super-resolution model from ruDALL-E | 429 |
| [nateraw/nous-hermes-2-solar-10.7b](https://replicate.com/nateraw/nous-hermes-2-solar-10.7b) | Nous Hermes 2 - SOLAR 10.7B is the flagship Nous Research model on the SOLAR 10.7B base model.. | 423 |
| [turian/insanely-fast-whisper-with-video](https://replicate.com/turian/insanely-fast-whisper-with-video) | whisper-large-v3, incredibly fast, with video transcription | 421 |
| [tencentarc/vqfr](https://replicate.com/tencentarc/vqfr) | Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder | 417 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 406 |
| [01-ai/yi-34b-chat](https://replicate.com/01-ai/yi-34b-chat) | The Yi series models are large language models trained from scratch by developers at 01.AI. | 404 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 379 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 379 |
| [zsxkib/clip-age-predictor](https://replicate.com/zsxkib/clip-age-predictor) | Age prediction using CLIP - Patched version of `https://replicate.com/andreasjansson/clip-age-predictor` that works with the new version of cog! | 368 |
| [batouresearch/sdxl-outpainting-lora](https://replicate.com/batouresearch/sdxl-outpainting-lora) | An improved outpainting model that supports LoRA urls. This model uses PatchMatch to improve the mask quality. | 362 |
| [suno-ai/bark](https://replicate.com/suno-ai/bark) | 🔊 Text-Prompted Generative Audio Model | 358 |
| [lucataco/juggernaut-xl-v9](https://replicate.com/lucataco/juggernaut-xl-v9) | Juggernaut XL v9 | 352 |
| [cjwbw/damo-text-to-video](https://replicate.com/cjwbw/damo-text-to-video) | Multi-stage text-to-video generation | 352 |
| [anotherjesse/controlnet-inpaint-test](https://replicate.com/anotherjesse/controlnet-inpaint-test) | controlnet_v11p_sd15_inpainting demo | 348 |
| [meepo-pro-player/invoker](https://replicate.com/meepo-pro-player/invoker) | null | 345 |
| [ali-vilab/i2vgen-xl](https://replicate.com/ali-vilab/i2vgen-xl) | RESEARCH/NON-COMMERCIAL USE ONLY: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models | 343 |
| [lucataco/sdxl-img-blend](https://replicate.com/lucataco/sdxl-img-blend) | SDXL Image Blending | 338 |
| [stability-ai/stable-diffusion-img2img](https://replicate.com/stability-ai/stable-diffusion-img2img) | Generate a new image from an input image with Stable Diffusion | 331 |
| [adirik/realvisxl-v4.0-lightning](https://replicate.com/adirik/realvisxl-v4.0-lightning) | Photorealism with RealVisXL V4.0 Lightning | 330 |
| [cloversid099/deepfake](https://replicate.com/cloversid099/deepfake) | DeepFake AI | 329 |
| [nateraw/openchat_3.5-awq](https://replicate.com/nateraw/openchat_3.5-awq) | OpenChat: Advancing Open-source Language Models with Mixed-Quality Data | 326 |
| [lucataco/realistic-vision-v5-img2img](https://replicate.com/lucataco/realistic-vision-v5-img2img) | Realistic Vision v5.0 Image 2 Image | 324 |
| [doriandarko/sdxl-hiroshinagai](https://replicate.com/doriandarko/sdxl-hiroshinagai) | SDXL model trained on Hiroshi Nagai's illustrations. | 312 |
| [asiryan/dark-sushi-mix-225d](https://replicate.com/asiryan/dark-sushi-mix-225d) | Dark Sushi Mix 2.25D Model with vae-ft-mse-840000-ema (Text2Img, Img2Img) | 309 |
| [fameengine/fame-lob-realvisxl-v20](https://replicate.com/fameengine/fame-lob-realvisxl-v20) | Lob RealVis XL | 302 |
| [alqasemy2020/whisper-jax](https://replicate.com/alqasemy2020/whisper-jax) | Faster and cheaper Whisper-AI Large-v2 responses. JAX implementation of OpenAI's Whisper model for up to 15x speed-up (doesn't support TPU). | 297 |
| [camenduru/animatediff-lightning-4-step](https://replicate.com/camenduru/animatediff-lightning-4-step) | AnimateDiff-Lightning: Cross-Model Diffusion Distillation | 295 |
| [lucataco/qwen-vl-chat](https://replicate.com/lucataco/qwen-vl-chat) | A multimodal LLM-based AI assistant, which is trained with alignment techniques. Qwen-VL-Chat supports more flexible interaction, such as multi-round question answering, and creative capabilities. | 294 |
| [mcai/absolutebeauty-v1.0](https://replicate.com/mcai/absolutebeauty-v1.0) | Generate a new image given any input text with AbsoluteReality v1.0 | 294 |
| [mcai/absolutebeauty-v1.0-img2img](https://replicate.com/mcai/absolutebeauty-v1.0-img2img) | Generate a new image from an input image with AbsoluteReality v1.0 | 292 |
| [adirik/styletts2](https://replicate.com/adirik/styletts2) | Generates speech from text | 291 |
| [lucataco/bakllava](https://replicate.com/lucataco/bakllava) | BakLLaVA-1 is a Mistral 7B base augmented with the LLaVA 1.5 architecture | 291 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 291 |
| [prompthero/lookbook](https://replicate.com/prompthero/lookbook) | Fashion Diffusion by PromptHero | 288 |
| [prompthero/dreamshaper](https://replicate.com/prompthero/dreamshaper) | Generate a new image given any input text with Dreamshaper v7 | 286 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 283 |
| [wolverinn/realisticoutpainter](https://replicate.com/wolverinn/realisticoutpainter) | outpaint with stable diffusion and ControlNet | 278 |
| [lambdal/stable-diffusion-image-variation](https://replicate.com/lambdal/stable-diffusion-image-variation) | Image Variations with Stable Diffusion | 277 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 276 |
| [fofr/video-to-frames](https://replicate.com/fofr/video-to-frames) | Split a video into frames | 275 |
| [lucataco/proteus-v0.4](https://replicate.com/lucataco/proteus-v0.4) | ProteusV0.4: The Style Update | 271 |
| [tstramer/midjourney-diffusion](https://replicate.com/tstramer/midjourney-diffusion) | null | 264 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 262 |
| [underthestar2021/meinamix-public](https://replicate.com/underthestar2021/meinamix-public) | null | 254 |
| [expa-ai/onepiece](https://replicate.com/expa-ai/onepiece) | null | 251 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 246 |
| [sepehr/mirage-gpu](https://replicate.com/sepehr/mirage-gpu) | null | 244 |
| [adirik/realvisxl-v3.0-turbo](https://replicate.com/adirik/realvisxl-v3.0-turbo) | Photorealism with RealVisXL V3.0 Turbo based on SDXL | 242 |
| [meta/codellama-34b-instruct](https://replicate.com/meta/codellama-34b-instruct) | A 34 billion parameter Llama tuned for coding and conversation | 240 |
| [google-deepmind/gemma-7b-it](https://replicate.com/google-deepmind/gemma-7b-it) | 7B instruct version of Google’s Gemma model | 237 |
| [deforum/deforum_stable_diffusion](https://replicate.com/deforum/deforum_stable_diffusion) | Animating prompts with stable diffusion | 234 |
| [cjwbw/stable-diffusion-v2-inpainting](https://replicate.com/cjwbw/stable-diffusion-v2-inpainting) | stable-diffusion-v2-inpainting | 230 |
| [tommoore515/material_stable_diffusion](https://replicate.com/tommoore515/material_stable_diffusion) | Stable diffusion fork for generating tileable outputs | 230 |
| [lucataco/ip-adapter-faceid](https://replicate.com/lucataco/ip-adapter-faceid) | (Research only) IP-Adapter-FaceID can generate various style images conditioned on a face with only text prompts | 229 |
| [lucataco/dreamshaper7-img2img-lcm](https://replicate.com/lucataco/dreamshaper7-img2img-lcm) | Dreamshaper-7 img2img with LCM LoRA for faster inference | 226 |
| [yorickvp/llava-v1.6-mistral-7b](https://replicate.com/yorickvp/llava-v1.6-mistral-7b) | LLaVA v1.6: Large Language and Vision Assistant (Mistral-7B) | 224 |
| [retrocirce/zero_shot_audio_source_separation](https://replicate.com/retrocirce/zero_shot_audio_source_separation) | Zero shot Sound separation by arbitrary query samples | 218 |
| [412392713/animeganv2](https://replicate.com/412392713/animeganv2) | Demo for AnimeGanv2 Face Portrait | 214 |
| [pwntus/sdxl-gta-v](https://replicate.com/pwntus/sdxl-gta-v) | A fine-tuned SDXL based on GTA V art | 213 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 209 |
| [andreasjansson/stable-diffusion-animation](https://replicate.com/andreasjansson/stable-diffusion-animation) | Animate Stable Diffusion by interpolating between two prompts | 209 |
| [lucataco/illusion-diffusion-hq](https://replicate.com/lucataco/illusion-diffusion-hq) | Monster Labs QrCode ControlNet on top of SD Realistic Vision v5.1 | 200 |
| [methexis-inc/img2aestheticscore](https://replicate.com/methexis-inc/img2aestheticscore) | null | 199 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 193 |
| [cjwbw/waifu-diffusion](https://replicate.com/cjwbw/waifu-diffusion) | Stable Diffusion on Danbooru images | 191 |
| [cswry/seesr](https://replicate.com/cswry/seesr) | SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution | 190 |
| [zsxkib/animate-diff](https://replicate.com/zsxkib/animate-diff) | 🎨 AnimateDiff (w/ MotionLoRAs for Panning, Zooming, etc): Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning | 190 |
| [catio-apps/interioraidesigns-generate](https://replicate.com/catio-apps/interioraidesigns-generate) | https://www.interioraidesigns.com. Take a picture of your room and see how your room looks in different themes. Remodel your room today. | 188 |
| [lucataco/sdxl-niji-se](https://replicate.com/lucataco/sdxl-niji-se) | SDXL_Niji_Special Edition | 188 |
| [sky-admin/ghost_mix_v2](https://replicate.com/sky-admin/ghost_mix_v2) | null | 188 |
| [google-research/frame-interpolation](https://replicate.com/google-research/frame-interpolation) | Frame Interpolation for Large Scene Motion | 188 |
| [daanelson/whisperx](https://replicate.com/daanelson/whisperx) | Accelerated transcription of audio using WhisperX | 183 |
| [zylim0702/sdxl-lora-customize-model](https://replicate.com/zylim0702/sdxl-lora-customize-model) | Introducing a text-to-image AI that crafts stunning 1024x1024 visuals. Load LoRa models via URLs for instant outputs. Train using this link: https://replicate.com/zylim0702/sdxl-lora-customize-training. | 180 |
| [subscriptions10x/sdxl-inpainting](https://replicate.com/subscriptions10x/sdxl-inpainting) | null | 177 |
| [tgohblio/instant-id-albedobase-xl](https://replicate.com/tgohblio/instant-id-albedobase-xl) | InstantID : Zero-shot Identity-Preserving Generation in Seconds with ⚡️LCM-LoRA⚡️. Using AlbedoBase-XL v2.0 as base model. | 174 |
| [lucataco/sadtalker](https://replicate.com/lucataco/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 170 |
| [sontungpytn/comfyui-lora-upscaler](https://replicate.com/sontungpytn/comfyui-lora-upscaler) | null | 167 |
| [alaradirik/t2i-adapter-sdxl-sketch](https://replicate.com/alaradirik/t2i-adapter-sdxl-sketch) | Modify images using sketches | 167 |
| [kyrick/prompt-parrot](https://replicate.com/kyrick/prompt-parrot) | Prompt Parrot generates text2image prompts from finetuned distilgpt2 | 166 |
| [mcai/realistic-vision-v2.0](https://replicate.com/mcai/realistic-vision-v2.0) | Generate a new image given any input text with Realistic Vision V2.0 | 164 |
| [fofr/musicgen-choral](https://replicate.com/fofr/musicgen-choral) | MusicGen fine-tuned on chamber choir music | 162 |
| [pollinations/modnet](https://replicate.com/pollinations/modnet) | A deep learning approach to remove background & adding new background image | 161 |
| [jagilley/controlnet-canny](https://replicate.com/jagilley/controlnet-canny) | Modify images using canny edge detection | 160 |
| [andreasjansson/deepfloyd-if](https://replicate.com/andreasjansson/deepfloyd-if) | The DeepFloyd IF model has been initially released as a non-commercial research-only model. Please make sure you read and abide to the license before using it. | 154 |
| [alaradirik/t2i-adapter-sdxl-canny](https://replicate.com/alaradirik/t2i-adapter-sdxl-canny) | Modify images using canny edges | 153 |
| [pagebrain/epicphotogasm-v1](https://replicate.com/pagebrain/epicphotogasm-v1) | T4 GPU, negative embeddings, img2img, inpainting, safety checker, KarrasDPM, pruned fp16 safetensor | 153 |
| [chiragpandya7/insightface_swap_enhance_v2](https://replicate.com/chiragpandya7/insightface_swap_enhance_v2) | null | 146 |
| [cjwbw/videocrafter](https://replicate.com/cjwbw/videocrafter) | VideoCrafter2: Text-to-Video and Image-to-Video Generation and Editing | 143 |
| [yangxy/gpen](https://replicate.com/yangxy/gpen) | Blind Face Restoration in the Wild | 143 |
| [lucataco/real-esrgan](https://replicate.com/lucataco/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale (for larger images) | 138 |
| [jagilley/controlnet-seg](https://replicate.com/jagilley/controlnet-seg) | Modify images using semantic segmentation | 138 |
| [asiryan/kandinsky-3.0](https://replicate.com/asiryan/kandinsky-3.0) | Kandinsky 3.0 Model (Text2Img and Img2Img) | 137 |
| [google-deepmind/gemma-2b-it](https://replicate.com/google-deepmind/gemma-2b-it) | 2B instruct version of Google’s Gemma model | 136 |
| [arielreplicate/robust_video_matting](https://replicate.com/arielreplicate/robust_video_matting) | extract foreground of a video | 135 |
| [fofr/lcm-animation](https://replicate.com/fofr/lcm-animation) | Fast animation using a latent consistency model | 134 |
| [viktorfa/oot_diffusion](https://replicate.com/viktorfa/oot_diffusion) | Virtual dressing room | 129 |
| [open-mmlab/pia](https://replicate.com/open-mmlab/pia) | Personalized Image Animator | 125 |
| [lucataco/realistic-vision-v5](https://replicate.com/lucataco/realistic-vision-v5) | Realistic Vision v5.0 with VAE | 125 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | 😊 Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 124 |
| [alexgenovese/upscaler](https://replicate.com/alexgenovese/upscaler) | GFPGAN aims at developing Practical Algorithms for Real-world Face Restoration | 120 |
| [lucataco/realvisxl-v1.0](https://replicate.com/lucataco/realvisxl-v1.0) | Implementation of SDXL RealVisXL_V1.0 | 117 |
| [nateraw/audio-super-resolution](https://replicate.com/nateraw/audio-super-resolution) | AudioSR: Versatile Audio Super-resolution at Scale | 114 |
| [lucataco/pasd-magnify](https://replicate.com/lucataco/pasd-magnify) | (Academic and Non-commercial use only) Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization | 112 |
| [cjwbw/supir-v0f](https://replicate.com/cjwbw/supir-v0f) | Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This is the SUPIR-v0F model and does NOT use LLaVA-13b. | 109 |
| [gfodor/instructblip](https://replicate.com/gfodor/instructblip) | Image captioning via vision-language models with instruction tuning | 105 |
| [lucataco/proteus-v0.3](https://replicate.com/lucataco/proteus-v0.3) | ProteusV0.3: The Anime Update | 104 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 104 |
| [tomasmcm/starling-lm-7b-alpha](https://replicate.com/tomasmcm/starling-lm-7b-alpha) | Source: berkeley-nest/Starling-LM-7B-alpha ✦ Quant: TheBloke/Starling-LM-7B-alpha-AWQ ✦ An open large language model (LLM) trained by Reinforcement Learning from AI Feedback (RLAIF) | 103 |
| [asiryan/realistic-vision-v4](https://replicate.com/asiryan/realistic-vision-v4) | Realistic Vision V4.0 Model (Text2Img, Img2Img and Inpainting) | 101 |
