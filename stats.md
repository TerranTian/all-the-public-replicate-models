# Model Stats
## New Models
- https://replicate.com/eiby777/olmocr-2-7b-1025-fp8
- https://replicate.com/espressotechie/ai-hst-vg
- https://replicate.com/lucataco/gpt-oss-safeguard-20b
- https://replicate.com/marfisthelaziest/librosam

## Removed Models
- https://replicate.com/budgetpixel/wai-illustrious-sdxl-v15

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [eiby777/olmocr-2-7b-1025-fp8](https://replicate.com/eiby777/olmocr-2-7b-1025-fp8) | Quantized to FP8 Version of olmOCR-2-7B-1025, using llmcompressor. | 10 | 10 | 100.00% |
| [espressotechie/ai-hst-vg](https://replicate.com/espressotechie/ai-hst-vg) | Hair swap | 204 | 204 | 100.00% |
| [lucataco/gpt-oss-safeguard-20b](https://replicate.com/lucataco/gpt-oss-safeguard-20b) | classify text content based on safety policies that you provide and perform a suite of foundational safety tasks | 1 | 1 | 100.00% |
| [marfisthelaziest/librosam](https://replicate.com/marfisthelaziest/librosam) | null | 44 | 44 | 100.00% |
| [minimax/speech-2.6-hd](https://replicate.com/minimax/speech-2.6-hd) | MiniMax Speech 2.6 HD delivers studio-quality multilingual text-to-audio on Replicate with nuanced prosody, subtitle export, and premium voices | 260 | 279 | 93.19% |
| [minimax/speech-2.6-turbo](https://replicate.com/minimax/speech-2.6-turbo) | Low‚Äëlatency MiniMax Speech 2.6 Turbo brings multilingual, emotional text-to-speech to Replicate with 300+ voices and real-time friendly pricing | 106 | 122 | 86.89% |
| [emersimeon/image-audio-video](https://replicate.com/emersimeon/image-audio-video) | Add an image and a song and generate a video | 15 | 18 | 83.33% |
| [bria/fibo](https://replicate.com/bria/fibo) | SOTA Open source model trained on licensed data, transforming intent into structured control for precise, high-quality AI image generation in enterprise and agentic workflows. | 275 | 377 | 72.94% |
| [elevenlabs/v3](https://replicate.com/elevenlabs/v3) | The most expressive Text to Speech model | 168 | 250 | 67.20% |
| [elevenlabs/music](https://replicate.com/elevenlabs/music) | Compose a song from a prompt or a composition plan | 62 | 100 | 62.00% |
| [vufinder/vggt-1b](https://replicate.com/vufinder/vggt-1b) | Feed-forward neural network that directly infers all key 3D attributes of a scene. | 111 | 200 | 55.50% |
| [elevenlabs/turbo-v2.5](https://replicate.com/elevenlabs/turbo-v2.5) | High quality, low latency text to speech in 32 languages | 35 | 64 | 54.69% |
| [chase-aldridge/chases-model](https://replicate.com/chase-aldridge/chases-model) | null | 97 | 202 | 48.02% |
| [jigsawstack/nsfw](https://replicate.com/jigsawstack/nsfw) | Quickly detect nudity, violence, hentai, porn and more NSFW content in images. | 21 | 46 | 45.65% |
| [elevenlabs/v2-multilingual](https://replicate.com/elevenlabs/v2-multilingual) | Generate multilingual text-to-speech audio in over 30 languages | 16 | 36 | 44.44% |
| [eiby777/manga_globes](https://replicate.com/eiby777/manga_globes) | Detect and classify speech bubbles in manga images | 3 | 7 | 42.86% |
| [nvidia/nemotron-nano-v2-12b-vl](https://replicate.com/nvidia/nemotron-nano-v2-12b-vl) | A multi-modal AI model for visual Q&A, summarization, and data extraction, supporting text, images, and video. | 24 | 56 | 42.86% |
| [bytedance/seedance-1-pro-fast](https://replicate.com/bytedance/seedance-1-pro-fast) | A faster and cheaper version of Seedance 1 Pro | 5079 | 14972 | 33.92% |
| [zsxkib/whisper-lazyloading](https://replicate.com/zsxkib/whisper-lazyloading) | Convert speech in audio to text w/ `tiny`, `small`, `base`, and `large-v3` models | 194 | 623 | 31.14% |
| [emersimeon/azlyrics-replicate](https://replicate.com/emersimeon/azlyrics-replicate) | null | 11 | 36 | 30.56% |
| [founderfeed/midjourney](https://replicate.com/founderfeed/midjourney) | Midjourney Wrapper by WaveSpeedAPI provider | 39 | 138 | 28.26% |
| [idan054/sarra-video-maker-v1](https://replicate.com/idan054/sarra-video-maker-v1) | Cool | 125 | 519 | 24.08% |
| [richards630620/nobira](https://replicate.com/richards630620/nobira) | null | 28 | 126 | 22.22% |
| [fofr/qwen-my-subconscious](https://replicate.com/fofr/qwen-my-subconscious) | Qwen fine-tuned on trippy and vibrant FLUX Pro outputs | 22 | 101 | 21.78% |
| [richards630620/natalmark](https://replicate.com/richards630620/natalmark) | null | 13 | 60 | 21.67% |
| [lucataco/split-screen-video](https://replicate.com/lucataco/split-screen-video) | Combines two videos into a single split-screen layout | 137 | 669 | 20.48% |
| [krishtal16/aisha](https://replicate.com/krishtal16/aisha) | null | 1 | 5 | 20.00% |
| [lightricks/ltx-2-fast](https://replicate.com/lightricks/ltx-2-fast) | Ideal for rapid ideation and mobile workflows. Perfect for creators who need instant feedback, real-time previews, or high-throughput content. | 874 | 4895 | 17.85% |
| [google/gemini-2.5-flash](https://replicate.com/google/gemini-2.5-flash) | Google‚Äôs hybrid ‚Äúthinking‚Äù AI model optimized for speed and cost-efficiency | 3852 | 22318 | 17.26% |
| [minimax/hailuo-2.3](https://replicate.com/minimax/hailuo-2.3) | A high-fidelity video generation model optimized for realistic human motion, cinematic VFX, expressive characters, and strong prompt and style adherence across both text-to-video and image-to-video workflows | 290 | 1795 | 16.16% |
| [adirik/multilingual-e5-large](https://replicate.com/adirik/multilingual-e5-large) | Multilingual E5-large language embedding model | 144 | 893 | 16.13% |
| [zx-xch/tiktok-lifestyle-slideshow](https://replicate.com/zx-xch/tiktok-lifestyle-slideshow) | Generate luxury lifestyle TikTok slideshow images. | 48 | 306 | 15.69% |
| [lucataco/qwen3-vl-8b-instruct](https://replicate.com/lucataco/qwen3-vl-8b-instruct) | A powerful vision-language model in the Qwen series | 516 | 3339 | 15.45% |
| [ghostljj/sora2-watermark-remover-fix](https://replicate.com/ghostljj/sora2-watermark-remover-fix) | Removes the watermark from Sora 2 videos using a trained model and IOpaint (Fixed watermark detection leaks and production errors.) | 3 | 20 | 15.00% |
| [lucataco/frame-extractor](https://replicate.com/lucataco/frame-extractor) | Extract the first or last frame from any video file as a high-quality image | 76152 | 543676 | 14.01% |
| [bytedance/sa2va-4b-video](https://replicate.com/bytedance/sa2va-4b-video) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 8 | 58 | 13.79% |
| [bytedance/omni-human-1.5](https://replicate.com/bytedance/omni-human-1.5) | A film-grade digital human model that generates realistic video from a single image, audio clip, and optional text prompt. | 57 | 496 | 11.49% |
| [reve/remix](https://replicate.com/reve/remix) | Image generation model from Reve which handles multiple input reference images | 1091 | 10053 | 10.85% |
| [lightricks/ltx-2-pro](https://replicate.com/lightricks/ltx-2-pro) | Delivers high visual fidelity with fast turnaround. Great for daily content creation, marketing teams, and iterative creative workflows. | 319 | 3063 | 10.41% |
| [kwaivgi/kling-v2.5-turbo-pro](https://replicate.com/kwaivgi/kling-v2.5-turbo-pro) | Kling 2.5 Turbo Pro: Unlock pro-level text-to-video and image-to-video creation with smooth motion, cinematic depth, and remarkable prompt adherence. | 45759 | 444854 | 10.29% |
| [lucataco/trim-video](https://replicate.com/lucataco/trim-video) | Simple tool to quickly trim a video or audio file | 416 | 4532 | 9.18% |
| [tommoore515/pix2pix_tf_albedo2pbrmaps](https://replicate.com/tommoore515/pix2pix_tf_albedo2pbrmaps) | pix2pix model for predicting pbr texture maps from an albedo texture | 848 | 9468 | 8.96% |
| [datalab-to/marker](https://replicate.com/datalab-to/marker) | Convert PDF to markdown + JSON quickly with high accuracy | 62 | 694 | 8.93% |
| [datalab-to/ocr](https://replicate.com/datalab-to/ocr) | Detect and transcribe text in images with accurate bounding boxes, layout analysis, reding order, and table recognition, in 90 languages | 43 | 482 | 8.92% |
| [shapestudio/owesa](https://replicate.com/shapestudio/owesa) | null | 14 | 157 | 8.92% |
| [anthropic/claude-4.5-haiku](https://replicate.com/anthropic/claude-4.5-haiku) | Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed | 346 | 4059 | 8.52% |
| [marcilph/hailey](https://replicate.com/marcilph/hailey) | A confident woman strides down a city street in a crop top and jeans, embodying strength and style. | 4 | 47 | 8.51% |
| [minimax/hailuo-2.3-fast](https://replicate.com/minimax/hailuo-2.3-fast) | A lower-latency image-to-video version of Hailuo 2.3 that preserves core motion quality, visual consistency, and stylization performance while enabling faster iteration cycles. | 44 | 519 | 8.48% |
| [powerpdw/autovid-chibi](https://replicate.com/powerpdw/autovid-chibi) | A LoRA fine-tuned model for generating cute anime-style images. | 26 | 307 | 8.47% |
| [flux-kontext-apps/multi-image-kontext-pro](https://replicate.com/flux-kontext-apps/multi-image-kontext-pro) | An experimental model with FLUX Kontext Pro that can combine two input images | 46415 | 548662 | 8.46% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [black-forest-labs/flux-schnell](https://replicate.com/black-forest-labs/flux-schnell) | The fastest image generation model tailored for local development and personal use | 970460 |
| [google/nano-banana](https://replicate.com/google/nano-banana) | Google's latest image editing model in Gemini 2.5 | 653236 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 395292 |
| [bytedance/seedream-4](https://replicate.com/bytedance/seedream-4) | Unified text-to-image generation and precise single-sentence editing at up to 4K resolution | 294565 |
| [jaaari/kokoro-82m](https://replicate.com/jaaari/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 267769 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 251996 |
| [black-forest-labs/flux-kontext-pro](https://replicate.com/black-forest-labs/flux-kontext-pro) | A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language | 244731 |
| [prunaai/flux.1-dev](https://replicate.com/prunaai/flux.1-dev) | This is the fastest Flux Dev endpoint in the world, contact us for more at pruna.ai | 217927 |
| [prunaai/flux-kontext-dev](https://replicate.com/prunaai/flux-kontext-dev) | Fast endpoint for Flux Kontext, optimized with pruna framework | 139979 |
| [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct) | An 8 billion parameter language model from Meta, fine tuned for chat completions | 118266 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 111640 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 107259 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 96436 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! ü§ó | 87184 |
| [black-forest-labs/flux-dev](https://replicate.com/black-forest-labs/flux-dev) | A 12 billion parameter rectified flow transformer capable of generating images from text descriptions | 86382 |
| [qwen/qwen-image-edit-plus](https://replicate.com/qwen/qwen-image-edit-plus) | The latest Qwen-Image‚Äôs iteration with improved multi-image editing, single-image consistency, and native support for ControlNet | 83004 |
| [alphanumericuser/kokoro-82m](https://replicate.com/alphanumericuser/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 81032 |
| [black-forest-labs/flux-1.1-pro](https://replicate.com/black-forest-labs/flux-1.1-pro) | Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity. | 79696 |
| [lucataco/frame-extractor](https://replicate.com/lucataco/frame-extractor) | Extract the first or last frame from any video file as a high-quality image | 76152 |
| [adirik/grounding-dino](https://replicate.com/adirik/grounding-dino) | Detect everything with language! | 76018 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 54954 |
| [meta/meta-llama-3-70b-instruct](https://replicate.com/meta/meta-llama-3-70b-instruct) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 54711 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x | 53687 |
| [aisha-ai-official/animagine-xl-v4-opt](https://replicate.com/aisha-ai-official/animagine-xl-v4-opt) | null | 52713 |
| [nicolascoutureau/video-utils](https://replicate.com/nicolascoutureau/video-utils) | null | 52617 |
| [minimax/speech-02-turbo](https://replicate.com/minimax/speech-02-turbo) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Designed for real-time applications with low latency | 49023 |
| [851-labs/background-remover](https://replicate.com/851-labs/background-remover) | Remove backgrounds from images. | 48894 |
| [flux-kontext-apps/multi-image-kontext-pro](https://replicate.com/flux-kontext-apps/multi-image-kontext-pro) | An experimental model with FLUX Kontext Pro that can combine two input images | 46415 |
| [kwaivgi/kling-v2.5-turbo-pro](https://replicate.com/kwaivgi/kling-v2.5-turbo-pro) | Kling 2.5 Turbo Pro: Unlock pro-level text-to-video and image-to-video creation with smooth motion, cinematic depth, and remarkable prompt adherence. | 45759 |
| [lucataco/moondream2](https://replicate.com/lucataco/moondream2) | moondream2 is a small vision language model designed to run efficiently on edge devices | 43499 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 42873 |
| [bytedance/sdxl-lightning-4step](https://replicate.com/bytedance/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 41244 |
| [openai/gpt-5-nano](https://replicate.com/openai/gpt-5-nano) | Fastest, most cost-effective GPT-5 model from OpenAI | 39641 |
| [ideogram-ai/ideogram-v3-turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo) | Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles | 39223 |
| [black-forest-labs/flux-kontext-dev](https://replicate.com/black-forest-labs/flux-kontext-dev) | Open-weight version of FLUX.1 Kontext | 39198 |
| [google/imagen-4](https://replicate.com/google/imagen-4) | Google's Imagen 4 flagship model | 38487 |
| [black-forest-labs/flux-krea-dev](https://replicate.com/black-forest-labs/flux-krea-dev) | An opinionated text-to-image model from Black Forest Labs in collaboration with Krea that excels in photorealism. Creates images that avoid the oversaturated "AI look". | 38315 |
| [wan-video/wan-2.2-i2v-fast](https://replicate.com/wan-video/wan-2.2-i2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B image-to-video | 35690 |
| [prunaai/hidream-l1-fast](https://replicate.com/prunaai/hidream-l1-fast) | This is an optimised version of the hidream-l1 model using the pruna ai optimisation toolkit! | 35147 |
| [black-forest-labs/flux-kontext-max](https://replicate.com/black-forest-labs/flux-kontext-max) | A premium text-based image editing model that delivers maximum performance and improved typography generation for transforming images through natural language prompts | 34296 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | ü¶ô LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 31929 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 31919 |
| [black-forest-labs/flux-1.1-pro-ultra](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra) | FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism. | 31652 |
| [falcons-ai/nsfw_image_detection](https://replicate.com/falcons-ai/nsfw_image_detection) | Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 30713 |
| [bytedance/hyper-flux-8step](https://replicate.com/bytedance/hyper-flux-8step) | Hyper FLUX 8-step by ByteDance | 30674 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 25381 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 23600 |
| [google/imagen-4-fast](https://replicate.com/google/imagen-4-fast) | Use this fast version of Imagen 4 when speed and cost are more important than quality | 22148 |
| [humbleworth/price-predict-v1](https://replicate.com/humbleworth/price-predict-v1) | Predicts the value of a domain name. | 20987 |
| [lucataco/qwen3-embedding-8b](https://replicate.com/lucataco/qwen3-embedding-8b) | The Qwen3 Embedding model series is specifically designed for text embedding and ranking tasks | 19828 |
| [recraft-ai/recraft-v3](https://replicate.com/recraft-ai/recraft-v3) | Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis | 19342 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 18813 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 18459 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Generate image captions | 17776 |
| [alexgenovese/upscaler](https://replicate.com/alexgenovese/upscaler) | GFPGAN aims at developing Practical Algorithms for Real-world Face and Object Restoration | 16410 |
| [openai/gpt-image-1](https://replicate.com/openai/gpt-image-1) | A multimodal image generation model that creates high-quality images. You need to bring your own verified OpenAI key to use this model. Your OpenAI account will be charged for usage. | 16291 |
| [deepseek-ai/deepseek-v3](https://replicate.com/deepseek-ai/deepseek-v3) | DeepSeek-V3-0324 is the leading non-reasoning model, a milestone for open source | 15984 |
| [zsxkib/mmaudio](https://replicate.com/zsxkib/mmaudio) | Add sound to video using the MMAudio V2 model. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation. | 15401 |
| [recraft-ai/recraft-crisp-upscale](https://replicate.com/recraft-ai/recraft-crisp-upscale) | Designed to make images sharper and cleaner, Crisp Upscale increases overall quality, making visuals suitable for web use or print-ready materials. | 14864 |
| [lucataco/codeformer](https://replicate.com/lucataco/codeformer) | Robust face restoration algorithm for old photos/AI-generated faces | 14464 |
| [bytedance/seedance-1-lite](https://replicate.com/bytedance/seedance-1-lite) | A video generation model that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 720p resolution | 14141 |
| [kwaivgi/kling-v2.1](https://replicate.com/kwaivgi/kling-v2.1) | Use Kling v2.1 to generate 5s and 10s videos in 720p and 1080p resolution from a starting image (image-to-video) | 13863 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 13504 |
| [pixverse/pixverse-v5](https://replicate.com/pixverse/pixverse-v5) | Create 5s-8s videos with enhanced character movement, visual effects, and exclusive 1080p-8s support. Optimized for anime characters and complex actions | 13209 |
| [black-forest-labs/flux-dev-lora](https://replicate.com/black-forest-labs/flux-dev-lora) | A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference | 13034 |
| [bytedance/seedance-1-pro](https://replicate.com/bytedance/seedance-1-pro) | A pro version of Seedance that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 1080p resolution | 12445 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 11167 |
| [bytedance/pulid](https://replicate.com/bytedance/pulid) | üìñ PuLID: Pure and Lightning ID Customization via Contrastive Alignment | 11164 |
| [black-forest-labs/flux-pro](https://replicate.com/black-forest-labs/flux-pro) | State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. | 11039 |
| [zsxkib/molmo-7b](https://replicate.com/zsxkib/molmo-7b) | allenai/Molmo-7B-D-0924, Answers questions and caption about images | 10012 |
| [google/imagen-4-ultra](https://replicate.com/google/imagen-4-ultra) | Use this ultra version of Imagen 4 when quality matters more than speed and cost | 9936 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 9606 |
| [topazlabs/image-upscale](https://replicate.com/topazlabs/image-upscale) | Professional-grade image upscaling, from Topaz Labs | 9470 |
| [men1scus/birefnet](https://replicate.com/men1scus/birefnet) | Bilateral Reference for High-Resolution Dichotomous Image Segmentation (CAAI AIR 2024) | 8615 |
| [minimax/image-01](https://replicate.com/minimax/image-01) | Minimax's first image model, with character reference support | 8521 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 7973 |
| [anthropic/claude-3.7-sonnet](https://replicate.com/anthropic/claude-3.7-sonnet) | The most intelligent Claude model and the first hybrid reasoning model on the market (claude-3-7-sonnet-20250219) | 7573 |
| [qwen/qwen-image-edit](https://replicate.com/qwen/qwen-image-edit) | Edit images using a prompt. This model extends Qwen-Image‚Äôs unique text rendering capabilities to image editing tasks, enabling precise text editing | 7488 |
| [bytedance/seedream-3](https://replicate.com/bytedance/seedream-3) | A text-to-image model with support for native high-resolution (2K) image generation | 7161 |
| [ideogram-ai/ideogram-v2a](https://replicate.com/ideogram-ai/ideogram-v2a) | Like Ideogram v2, but faster and cheaper | 7083 |
| [bytedance/hyper-flux-16step](https://replicate.com/bytedance/hyper-flux-16step) | Hyper FLUX 16-step by ByteDance | 7045 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 6900 |
| [qwen/qwen-image](https://replicate.com/qwen/qwen-image) | An image generation foundation model in the Qwen series that achieves significant advances in complex text rendering. | 6762 |
| [datacte/proteus-v0.2](https://replicate.com/datacte/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 6425 |
| [prunaai/wan-2.2-image](https://replicate.com/prunaai/wan-2.2-image) | This model generates beautiful cinematic 2 megapixel images in 3-4 seconds and is derived from the Wan 2.2 model through optimisation techniques from the pruna package | 6257 |
| [cdingram/face-swap](https://replicate.com/cdingram/face-swap) | Image to image face swapping | 6192 |
| [datacte/proteus-v0.3](https://replicate.com/datacte/proteus-v0.3) | ProteusV0.3: The Anime Update | 6109 |
| [openai/gpt-4o-mini](https://replicate.com/openai/gpt-4o-mini) | Low latency, low cost version of OpenAI's GPT-4o model | 6083 |
| [pharmapsychotic/clip-interrogator](https://replicate.com/pharmapsychotic/clip-interrogator) | The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art! | 5947 |
| [smoretalk/clip-interrogator-turbo](https://replicate.com/smoretalk/clip-interrogator-turbo) | @pharmapsychotic 's CLIP-Interrogator, but 3x faster and more accurate. Specialized on SDXL. | 5864 |
| [minimax/speech-02-hd](https://replicate.com/minimax/speech-02-hd) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Optimized for high-fidelity applications like voiceovers and audiobooks. | 5821 |
| [fofr/flux-black-light](https://replicate.com/fofr/flux-black-light) | A flux lora fine-tuned on black light images | 5799 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 5681 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 5540 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ‚ö°Ô∏è Blazing fast audio transcription with speaker diarization | Whisper Large V3 Turbo | word & sentence level timestamps | prompt | 5442 |
| [zsxkib/ic-light](https://replicate.com/zsxkib/ic-light) | ‚úçÔ∏è‚ú®Prompts to auto-magically relights your images | 5356 |
| [google/imagen-3](https://replicate.com/google/imagen-3) | Google's highest quality text-to-image model, capable of generating images with detail, rich lighting and beauty | 5080 |
| [bytedance/seedance-1-pro-fast](https://replicate.com/bytedance/seedance-1-pro-fast) | A faster and cheaper version of Seedance 1 Pro | 5079 |
| [fofr/any-comfyui-workflow](https://replicate.com/fofr/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/replicate/cog-comfyui | 4976 |
| [victor-upmeet/whisperx-a40-large](https://replicate.com/victor-upmeet/whisperx-a40-large) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 for large audio files | 4954 |
| [ideogram-ai/ideogram-character](https://replicate.com/ideogram-ai/ideogram-character) | Generate consistent characters from a single reference image. Outputs can be in many styles. You can also use inpainting to add your character to an existing image. | 4928 |
| [flux-kontext-apps/restore-image](https://replicate.com/flux-kontext-apps/restore-image) | Use FLUX Kontext to restore, fix scratches and damage, and colorize old photos | 4746 |
| [wan-video/wan-2.2-5b-fast](https://replicate.com/wan-video/wan-2.2-5b-fast) | The fastest Wan 2.2 text-to-image and image-to-video model | 4705 |
| [aisha-ai-official/anillustrious-v4](https://replicate.com/aisha-ai-official/anillustrious-v4) | null | 4657 |
| [tmappdev/lang-segment-anything](https://replicate.com/tmappdev/lang-segment-anything) | Segment Anything with prompts | 4639 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 4527 |
| [pollinations/modnet](https://replicate.com/pollinations/modnet) | A deep learning approach to remove background & adding new background image | 4488 |
| [meta/llama-4-maverick-instruct](https://replicate.com/meta/llama-4-maverick-instruct) | A 17 billion parameter model with 128 experts | 4477 |
| [openai/gpt-5](https://replicate.com/openai/gpt-5) | OpenAI's new model excelling at coding, writing, and reasoning. | 4428 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 4332 |
| [meta/meta-llama-3.1-405b-instruct](https://replicate.com/meta/meta-llama-3.1-405b-instruct) | Meta's flagship 405 billion parameter language model, fine-tuned for chat completions | 3921 |
| [ideogram-ai/ideogram-v2-turbo](https://replicate.com/ideogram-ai/ideogram-v2-turbo) | A fast image model with state of the art inpainting, prompt comprehension and text rendering. | 3854 |
| [google/gemini-2.5-flash](https://replicate.com/google/gemini-2.5-flash) | Google‚Äôs hybrid ‚Äúthinking‚Äù AI model optimized for speed and cost-efficiency | 3852 |
| [lucataco/flux-schnell-lora](https://replicate.com/lucataco/flux-schnell-lora) | FLUX.1-Schnell LoRA Explorer | 3821 |
| [ideogram-ai/ideogram-v3-quality](https://replicate.com/ideogram-ai/ideogram-v3-quality) | The highest quality Ideogram v3 model. v3 creates images with stunning realism, creative designs, and consistent styles | 3819 |
| [black-forest-labs/flux-fill-pro](https://replicate.com/black-forest-labs/flux-fill-pro) | Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results. | 3756 |
| [black-forest-labs/flux-fill-dev](https://replicate.com/black-forest-labs/flux-fill-dev) | Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro]. | 3733 |
| [openai/gpt-5-structured](https://replicate.com/openai/gpt-5-structured) | GPT-5 with support for structured outputs, web search and custom tools | 3684 |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | null | 3570 |
| [meronym/speaker-diarization](https://replicate.com/meronym/speaker-diarization) | Segments an audio recording based on who is speaking | 3553 |
| [franz-biz/yolo-world-xl](https://replicate.com/franz-biz/yolo-world-xl) | Real-Time Open-Vocabulary Object Detection using the xl weights | 3516 |
| [google/imagen-3-fast](https://replicate.com/google/imagen-3-fast) | A faster and cheaper Imagen 3 model, for when price or speed are more important than final image quality | 3488 |
| [charlesmccarthy/addwatermark](https://replicate.com/charlesmccarthy/addwatermark) | Add a watermark to your videos using the power of Replicate brought to you from your friends at FullJourney.AI | 3451 |
| [ardianfe/music-gen-fn-200e](https://replicate.com/ardianfe/music-gen-fn-200e) | Create music for your content | 3442 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 3383 |
| [bria/remove-background](https://replicate.com/bria/remove-background) | Bria AI's remove background model | 3343 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 3283 |
| [openai/gpt-4.1-nano](https://replicate.com/openai/gpt-4.1-nano) | Fastest, most cost-effective GPT-4.1 model from OpenAI | 3266 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 3260 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 3225 |
| [aisha-ai-official/wai-nsfw-illustrious-v11](https://replicate.com/aisha-ai-official/wai-nsfw-illustrious-v11) | null | 3164 |
| [black-forest-labs/flux-schnell-lora](https://replicate.com/black-forest-labs/flux-schnell-lora) | The fastest image generation model tailored for fine-tuned use | 3143 |
| [black-forest-labs/flux-depth-dev](https://replicate.com/black-forest-labs/flux-depth-dev) | Open-weight depth-aware image generation. Edit images while preserving spatial relationships. | 3133 |
| [zf-kbot/inpaint-and-guess-prompt](https://replicate.com/zf-kbot/inpaint-and-guess-prompt) | Use a mask to inpaint the image or generate a prompt based on the mask. | 3120 |
| [pseudoram/rvc-v2](https://replicate.com/pseudoram/rvc-v2) | Speech to speech with any RVC v2 trained AI voice | 3028 |
| [prunaai/flux.1-dev-lora](https://replicate.com/prunaai/flux.1-dev-lora) | This is a 3x faster FLUX.1 [dev] model from Black Forest Labs, optimised with pruna with minimal quality loss. | 3014 |
| [bria/image-3.2](https://replicate.com/bria/image-3.2) | Commercial-ready, trained entirely on licensed data, text-to-image model. With only 4B parameters provides exceptional aesthetics and text rendering. Evaluated to be on par to other leading models in the market | 2937 |
| [smoosh-sh/baby-mystic](https://replicate.com/smoosh-sh/baby-mystic) | Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent | 2920 |
| [zsxkib/qwen2-1.5b-instruct](https://replicate.com/zsxkib/qwen2-1.5b-instruct) | Qwen 2: A 1.5 billion parameter language model from Alibaba Cloud, fine tuned for chat completions | 2881 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 2860 |
| [nvidia/sana-sprint-1.6b](https://replicate.com/nvidia/sana-sprint-1.6b) | SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation | 2856 |
| [meta/llama-4-scout-instruct](https://replicate.com/meta/llama-4-scout-instruct) | A 17 billion parameter model with 16 experts | 2856 |
| [ideogram-ai/ideogram-v2](https://replicate.com/ideogram-ai/ideogram-v2) | An excellent image model with state of the art inpainting, prompt comprehension and text rendering | 2737 |
| [philz1337x/crystal-upscaler](https://replicate.com/philz1337x/crystal-upscaler) | High-precision image upscaler optimized for portraits and faces. One of the upscale modes powered by Clarity AI. X:https://x.com/philz1337x | 2730 |
| [anthropic/claude-3.5-haiku](https://replicate.com/anthropic/claude-3.5-haiku) | Anthropic's fastest, most cost-effective model, with a 200K token context window (claude-3-5-haiku-20241022) | 2729 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 2639 |
| [lucataco/flux-dev-lora](https://replicate.com/lucataco/flux-dev-lora) | FLUX.1-Dev LoRA Explorer (DEPRECATED Please use: black-forest-labs/flux-dev-lora) | 2615 |
| [mrhan1993/fooocus-api](https://replicate.com/mrhan1993/fooocus-api) | null | 2548 |
| [ryan5453/demucs](https://replicate.com/ryan5453/demucs) | Demucs is an audio source separator created by Facebook Research. | 2483 |
| [kwaivgi/kling-v1.6-standard](https://replicate.com/kwaivgi/kling-v1.6-standard) | Generate 5s and 10s videos in 720p resolution at 30fps | 2469 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting by the HF Diffusers team | 2454 |
| [anthropic/claude-4-sonnet](https://replicate.com/anthropic/claude-4-sonnet) | Claude Sonnet 4 is a significant upgrade to 3.7, delivering superior coding and reasoning while responding more precisely to your instructions | 2423 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 2409 |
| [openai/gpt-5-mini](https://replicate.com/openai/gpt-5-mini) | Faster version of OpenAI's flagship GPT-5 model | 2406 |
| [minimax/hailuo-02](https://replicate.com/minimax/hailuo-02) | Hailuo 2 is a text-to-video and image-to-video model that can make 6s or 10s videos at 768p (standard) or 1080p (pro). It excels at real world physics. | 2362 |
| [stability-ai/stable-diffusion-3.5-large](https://replicate.com/stability-ai/stable-diffusion-3.5-large) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, thanks to Query-Key Normalization. | 2290 |
| [simbrams/segformer-b5-finetuned-ade-640-640](https://replicate.com/simbrams/segformer-b5-finetuned-ade-640-640) | Semantic Segmentation | 2217 |
| [rafaelgalle/whisper-diarization-advanced](https://replicate.com/rafaelgalle/whisper-diarization-advanced) | Ultra-fast, customizable speech-to-text and speaker diarization for noisy, multi-speaker audio. Includes advanced noise reduction, stereo channel support, and flexible audio preprocessing‚Äîideal for call centers, meetings, and podcasts. | 2212 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 2154 |
| [bria/eraser](https://replicate.com/bria/eraser) | SOTA Object removal, enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use | 2109 |
| [openai/sora-2](https://replicate.com/openai/sora-2) | OpenAI's Flagship video generation with synced audio | 2087 |
| [google/veo-3.1](https://replicate.com/google/veo-3.1) | New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support | 2032 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 2006 |
| [playgroundai/playground-v2.5-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 1997 |
| [cuuupid/idm-vton](https://replicate.com/cuuupid/idm-vton) | Best-in-class clothing virtual try on in the wild (non-commercial use only) | 1985 |
| [codeplugtech/background_remover](https://replicate.com/codeplugtech/background_remover) | Remove background from image | 1913 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 1911 |
| [runwayml/gen4-image](https://replicate.com/runwayml/gen4-image) | Runway's Gen-4 Image model with references. Use up to 3 reference images to create the exact image you need. Capture every angle. | 1827 |
| [fofr/realvisxl-v3-multi-controlnet-lora](https://replicate.com/fofr/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 1822 |
| [lucataco/deepseek-ocr](https://replicate.com/lucataco/deepseek-ocr) | Convert documents to markdown, extract raw text, and locate specific content | 1803 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 1781 |
| [adirik/interior-design](https://replicate.com/adirik/interior-design) | Realistic interior design with text and image inputs | 1768 |
| [wan-video/wan-2.5-i2v](https://replicate.com/wan-video/wan-2.5-i2v) | Alibaba Wan 2.5 Image to video generation with background audio | 1696 |
| [anthropic/claude-4.5-sonnet](https://replicate.com/anthropic/claude-4.5-sonnet) | Claude Sonnet 4.5 is the best coding model to date, with significant improvements across the entire development lifecycle | 1686 |
| [firtoz/trellis](https://replicate.com/firtoz/trellis) | A powerful 3D asset generation model | 1664 |
| [wan-video/wan-2.2-t2v-fast](https://replicate.com/wan-video/wan-2.2-t2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B text-to-video | 1659 |
| [asiryan/juggernaut-xl-v7](https://replicate.com/asiryan/juggernaut-xl-v7) | Juggernaut XL v7 Model (Text2Img, Img2Img and Inpainting) | 1625 |
| [fofr/consistent-character](https://replicate.com/fofr/consistent-character) | Create images of a given character in different poses | 1608 |
| [google/gemini-2.5-flash-image](https://replicate.com/google/gemini-2.5-flash-image) | Google's latest image generation model in Gemini 2.5 | 1588 |
| [resemble-ai/chatterbox](https://replicate.com/resemble-ai/chatterbox) | Generate expressive, natural speech. Features unique emotion control, instant voice cloning from short audio, and built-in watermarking. | 1585 |
| [hexiaochun/pp-ocr-v4](https://replicate.com/hexiaochun/pp-ocr-v4) | ÂõæÊñáËØÜÂà´ | 1514 |
| [prunaai/flux-schnell](https://replicate.com/prunaai/flux-schnell) | This is a 3x faster FLUX.1 [schnell] model from Black Forest Labs, optimised with pruna with minimal quality loss. Contact us for more at pruna.ai | 1486 |
| [colinmcdonnell22/ghiblify-3](https://replicate.com/colinmcdonnell22/ghiblify-3) | null | 1474 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 1472 |
| [leonardoai/lucid-origin](https://replicate.com/leonardoai/lucid-origin) | Artistic and high-quality visuals with improved prompt adherence, diversity, and definition | 1469 |
| [luma/photon](https://replicate.com/luma/photon) | High-quality image generation model optimized for creative professional workflows and ultra-high fidelity outputs | 1462 |
| [bytedance/seededit-3.0](https://replicate.com/bytedance/seededit-3.0) | Text-guided image editing model that preserves original details while making targeted modifications like lighting changes, object removal, and style conversion | 1448 |
| [adirik/realvisxl-v3.0-turbo](https://replicate.com/adirik/realvisxl-v3.0-turbo) | Photorealism with RealVisXL V3.0 Turbo based on SDXL | 1424 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 1405 |
| [tencentarc/vqfr](https://replicate.com/tencentarc/vqfr) | Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder | 1395 |
| [google/veo-3.1-fast](https://replicate.com/google/veo-3.1-fast) | New and improved version of Veo 3 Fast, with higher-fidelity video, context-aware audio and last frame support | 1368 |
| [smoretalk/rembg-enhance](https://replicate.com/smoretalk/rembg-enhance) | A background removal model enhanced with better matting | 1363 |
| [melgor/stabledesign_interiordesign](https://replicate.com/melgor/stabledesign_interiordesign) | Transfer empty room into fabulous interior design | 1345 |
| [ideogram-ai/ideogram-v3-balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced) | Balance speed, quality and cost. Ideogram v3 creates images with stunning realism, creative designs, and consistent styles | 1337 |
| [recraft-ai/recraft-remove-background](https://replicate.com/recraft-ai/recraft-remove-background) | Automated background removal for images. Tuned for AI-generated content, product photos, portraits, and design workflows | 1328 |
| [openai/gpt-4.1](https://replicate.com/openai/gpt-4.1) | OpenAI's Flagship GPT model for complex tasks. | 1304 |
| [google/veo-3-fast](https://replicate.com/google/veo-3-fast) | A faster and cheaper version of Google‚Äôs Veo 3 video model, with audio | 1298 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 1267 |
| [minimax/music-01](https://replicate.com/minimax/music-01) | Quickly generate up to 1 minute of music with lyrics and vocals in the style of a reference track | 1255 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 1207 |
| [black-forest-labs/flux-kontext-dev-lora](https://replicate.com/black-forest-labs/flux-kontext-dev-lora) | FLUX.1 Kontext[dev] image editing model for running lora finetunes | 1186 |
| [fofr/color-matcher](https://replicate.com/fofr/color-matcher) | Color match and white balance fixes for images | 1158 |
| [ibm-granite/granite-3.3-8b-instruct](https://replicate.com/ibm-granite/granite-3.3-8b-instruct) | Granite-3.3-8B-Instruct is a 8-billion parameter 128K context length language model fine-tuned for improved reasoning and instruction-following capabilities. | 1154 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 1138 |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 1111 |
| [fofr/style-transfer](https://replicate.com/fofr/style-transfer) | Transfer the style of one image to another | 1111 |
| [openai/clip](https://replicate.com/openai/clip) | Official CLIP models, generate CLIP (clip-vit-large-patch14) text & image embeddings | 1099 |
| [reve/remix](https://replicate.com/reve/remix) | Image generation model from Reve which handles multiple input reference images | 1091 |
| [runwayml/gen4-aleph](https://replicate.com/runwayml/gen4-aleph) | A new way to edit, transform and generate video | 1080 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 1060 |
| [lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) | FLUX.1-Dev Multi LoRA Explorer | 1015 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 1011 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | üòä Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 1005 |
| [easel/advanced-face-swap](https://replicate.com/easel/advanced-face-swap) | Face swap one or two people into a target image | 994 |
| [simbrams/ri](https://replicate.com/simbrams/ri) | Realistic Inpainting with ControlNET (M-LSD + SEG) | 975 |
| [pixverse/pixverse-v4.5](https://replicate.com/pixverse/pixverse-v4.5) | Quickly make 5s or 8s videos at 540p, 720p or 1080p. It has enhanced motion, prompt coherence and handles complex actions well. | 968 |
| [replicate/train-rvc-model](https://replicate.com/replicate/train-rvc-model) | Train your own custom RVC model | 936 |
| [fpsorg/emoji](https://replicate.com/fpsorg/emoji) | Make Emoji with AI. | 907 |
| [ibm-granite/granite-vision-3.3-2b](https://replicate.com/ibm-granite/granite-vision-3.3-2b) | Granite-vision-3.3-2b is a compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. | 898 |
| [bria/expand-image](https://replicate.com/bria/expand-image) | Bria Expand expands images beyond their borders in high quality. Resizing the image by generating new pixels to expand to the desired aspect ratio. Trained exclusively on licensed data for safe and risk-free commercial use | 890 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 889 |
| [shreejalmaharjan-27/website-screenshot](https://replicate.com/shreejalmaharjan-27/website-screenshot) | Capture a website screenshot | 879 |
| [lightricks/ltx-2-fast](https://replicate.com/lightricks/ltx-2-fast) | Ideal for rapid ideation and mobile workflows. Perfect for creators who need instant feedback, real-time previews, or high-throughput content. | 874 |
| [openai/sora-2-pro](https://replicate.com/openai/sora-2-pro) | OpenAI's Most advanced synced-audio video generation | 870 |
| [anthropic/claude-3.5-sonnet](https://replicate.com/anthropic/claude-3.5-sonnet) | Anthropic's most intelligent language model to date, with a 200K token context window and image understanding (claude-3-5-sonnet-20241022) | 866 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 850 |
| [tommoore515/pix2pix_tf_albedo2pbrmaps](https://replicate.com/tommoore515/pix2pix_tf_albedo2pbrmaps) | pix2pix model for predicting pbr texture maps from an albedo texture | 848 |
| [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) | Base version of Llama 3, an 8 billion parameter language model from Meta. | 847 |
| [rhelsing/basic-pitch](https://replicate.com/rhelsing/basic-pitch) | Spotify's Basic Pitch Model | 823 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | Integral cog of doiwear.it | 818 |
| [codeslake/ifan-defocus-deblur](https://replicate.com/codeslake/ifan-defocus-deblur) | Removes defocus blur in an image | 806 |
| [resemble-ai/resemble-enhance](https://replicate.com/resemble-ai/resemble-enhance) | AI-driven audio enhancement for your audio files, powered by Resemble AI | 798 |
| [recraft-ai/recraft-vectorize](https://replicate.com/recraft-ai/recraft-vectorize) | Convert raster images to high-quality SVG format with precision and clean vector paths, perfect for logos, icons, and scalable graphics. | 794 |
| [lightweight-ai/model1](https://replicate.com/lightweight-ai/model1) | flux_schnell model img2img inference | 789 |
| [bytedance/flux-pulid](https://replicate.com/bytedance/flux-pulid) | ‚ö°Ô∏èFLUX PuLID: FLUX-dev based Pure and Lightning ID Customization via Contrastive Alignmentüé≠ | 789 |
| [devgmstudios/pony-realism-v23](https://replicate.com/devgmstudios/pony-realism-v23) | Latest Pony Realism Model. Try it with WEIGHTS on creatorframes.com | 788 |
| [deepseek-ai/deepseek-r1](https://replicate.com/deepseek-ai/deepseek-r1) | A reasoning model trained with reinforcement learning, on par with OpenAI o1 | 785 |
| [ostris/flux-dev-lora-trainer](https://replicate.com/ostris/flux-dev-lora-trainer) | Fine-tune FLUX.1-dev using ai-toolkit | 779 |
| [sesamo-srl/bge-reranker-v2-m3](https://replicate.com/sesamo-srl/bge-reranker-v2-m3) | Newest reranker model from BAAI (https://huggingface.co/BAAI/bge-reranker-v2-m3). FP16 inference enabled. Normalize param available | 779 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 779 |
| [zust-ai/supir](https://replicate.com/zust-ai/supir) | null | 778 |
| [openai/gpt-4o](https://replicate.com/openai/gpt-4o) | OpenAI's high-intelligence chat model | 763 |
| [pengdaqian2020/image-tagger](https://replicate.com/pengdaqian2020/image-tagger) | image tagger | 763 |
| [delta-lock/noobai-xl](https://replicate.com/delta-lock/noobai-xl) | Models fine-tuned from NoobAI-XL/Illustrious-XL series. | 752 |
| [vyroteam/imagineart-1.0](https://replicate.com/vyroteam/imagineart-1.0) | A state-of-the-art Mixture of Experts (MoE) model for generating hyper-realistic images with unmatched detail, natural lighting, and photographic authenticity. | 746 |
| [kwaivgi/kling-v1.6-pro](https://replicate.com/kwaivgi/kling-v1.6-pro) | Generate 5s and 10s videos in 1080p resolution | 746 |
| [bytedance/dreamina-3.1](https://replicate.com/bytedance/dreamina-3.1) | 4MP text-to-image generation with enhanced cinematic-quality image generation with precise style control, improved text rendering, and commercial design optimization. | 739 |
| [topazlabs/video-upscale](https://replicate.com/topazlabs/video-upscale) | Video Upscaling from Topaz Labs | 734 |
| [bria/generate-background](https://replicate.com/bria/generate-background) | Bria Background Generation allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use | 708 |
| [delta-lock/ponynai3](https://replicate.com/delta-lock/ponynai3) | Models fine-tuned from Pony-XL series. | 700 |
| [recraft-ai/recraft-v3-svg](https://replicate.com/recraft-ai/recraft-v3-svg) | Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles. | 679 |
| [aisha-ai-official/nsfw-flux-dev](https://replicate.com/aisha-ai-official/nsfw-flux-dev) | null | 678 |
| [google/veo-3](https://replicate.com/google/veo-3) | Sound on: Google‚Äôs flagship Veo 3 text to video model, with audio | 652 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 639 |
| [flux-kontext-apps/multi-image-kontext-max](https://replicate.com/flux-kontext-apps/multi-image-kontext-max) | An experimental FLUX Kontext model that can combine two input images | 631 |
| [replicate/fast-flux-trainer](https://replicate.com/replicate/fast-flux-trainer) | Train subjects or styles faster than ever | 617 |
| [sakemin/all-in-one-music-structure-analyzer](https://replicate.com/sakemin/all-in-one-music-structure-analyzer) | Cog implementation of mir-aidj(Taejun Kim)'s 'All-In-One Music Structure Analyzer' | 613 |
| [soykertje/spleeter](https://replicate.com/soykertje/spleeter) | Spleeter is Deezer source separation library with pretrained models written in Python and uses Tensorflow. | 592 |
| [adminconteudosflix/midjourney-allcraft](https://replicate.com/adminconteudosflix/midjourney-allcraft) | null | 589 |
| [ibm-granite/granite-4.0-h-small](https://replicate.com/ibm-granite/granite-4.0-h-small) | Granite-4.0-H-Small is a 32B parameter long-context instruct model finetuned from Granite-4.0-H-Small-Base using a combination of open source instruction datasets with permissive license and internally collected synthetic datasets. | 584 |
| [vectradmin/sdxl-v-transparent](https://replicate.com/vectradmin/sdxl-v-transparent) | null | 578 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 571 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 568 |
| [lucataco/apollo-7b](https://replicate.com/lucataco/apollo-7b) | Apollo 7B - An Exploration of Video Understanding in Large Multimodal Models | 555 |
| [minimax/video-01](https://replicate.com/minimax/video-01) | Generate 6s videos with prompts or images. (Also known as Hailuo). Use a subject reference to make a video with a character and the S2V-01 model. | 554 |
| [runwayml/gen4-image-turbo](https://replicate.com/runwayml/gen4-image-turbo) | Gen-4 Image Turbo is cheaper and 2.5x faster than Gen-4 Image. An image model with references, use up to 3 reference images to create the exact image you need. Capture every angle. | 548 |
| [fofr/sdxl-fresh-ink](https://replicate.com/fofr/sdxl-fresh-ink) | SDXL fine-tuned on photos of freshly inked tattoos | 543 |
| [nateraw/whisper-large-v3](https://replicate.com/nateraw/whisper-large-v3) | Whisper is a general-purpose speech recognition model. | 538 |
| [flux-kontext-apps/cartoonify](https://replicate.com/flux-kontext-apps/cartoonify) | Turn your image into a cartoon with FLUX.1 Kontext [pro] | 523 |
| [easel/ai-avatars](https://replicate.com/easel/ai-avatars) | Use one or two face images to create AI avatars | 519 |
| [lucataco/qwen3-vl-8b-instruct](https://replicate.com/lucataco/qwen3-vl-8b-instruct) | A powerful vision-language model in the Qwen series | 516 |
| [pnyompen/sdxl-controlnet-lora-small](https://replicate.com/pnyompen/sdxl-controlnet-lora-small) | SDXL Canny controlnet with LoRA support. | 506 |
| [tencent/hunyuan-image-3](https://replicate.com/tencent/hunyuan-image-3) | A powerful native multimodal model for image generation (PrunaAI squeezed) | 503 |
| [stability-ai/stable-diffusion-3](https://replicate.com/stability-ai/stable-diffusion-3) | A text-to-image model with greatly improved performance in image quality, typography, complex prompt understanding, and resource-efficiency | 503 |
| [openai/gpt-oss-120b](https://replicate.com/openai/gpt-oss-120b) | 120b open-weight language model from OpenAI | 497 |
| [uglyrobot/sora2-watermark-remover](https://replicate.com/uglyrobot/sora2-watermark-remover) | Removes the watermark from Sora 2 videos using a trained model and IOpaint | 496 |
| [declare-lab/tangoflux](https://replicate.com/declare-lab/tangoflux) | Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization | 492 |
| [pikachupichu25/image-faceswap](https://replicate.com/pikachupichu25/image-faceswap) | null | 490 |
| [recraft-ai/recraft-20b](https://replicate.com/recraft-ai/recraft-20b) | Affordable and fast images | 485 |
| [reve/create](https://replicate.com/reve/create) | Image generation model from Reve | 480 |
| [black-forest-labs/flux-canny-pro](https://replicate.com/black-forest-labs/flux-canny-pro) | Professional edge-guided image generation. Control structure and composition using Canny edge detection | 471 |
| [meta/llama-2-70b-chat](https://replicate.com/meta/llama-2-70b-chat) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 467 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 466 |
| [openai/gpt-image-1-mini](https://replicate.com/openai/gpt-image-1-mini) | A cost-efficient version of GPT Image 1 | 464 |
| [nvidia/sana](https://replicate.com/nvidia/sana) | A fast image model with wide artistic range and resolutions up to 4096x4096 | 462 |
| [openai/o4-mini](https://replicate.com/openai/o4-mini) | OpenAI's fast, lightweight reasoning model | 461 |
| [flux-kontext-apps/multi-image-list](https://replicate.com/flux-kontext-apps/multi-image-list) | FLUX Kontext max with list input for multiple images | 458 |
| [stability-ai/stable-diffusion-3.5-large-turbo](https://replicate.com/stability-ai/stable-diffusion-3.5-large-turbo) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, with a focus on fewer inference steps | 453 |
| [black-forest-labs/flux-depth-pro](https://replicate.com/black-forest-labs/flux-depth-pro) | Professional depth-aware image generation. Edit images while preserving spatial relationships. | 449 |
| [black-forest-labs/flux-1.1-pro-ultra-finetuned](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra-finetuned) | Inference model for FLUX 1.1 [pro] Ultra using custom `finetune_id`. Supports 4MP images and raw mode for realism | 449 |
| [minimax/music-1.5](https://replicate.com/minimax/music-1.5) | Music-1.5: Full-length songs (up to 4 mins) with natural vocals & rich instrumentation | 441 |
| [lucataco/ace-step](https://replicate.com/lucataco/ace-step) | A Step Towards Music Generation Foundation Model text2music | 429 |
| [asiryan/realism-xl](https://replicate.com/asiryan/realism-xl) | Realism XL Model (Text2Img, Img2Img and Inpainting) | 426 |
| [wan-video/wan-2.5-t2v](https://replicate.com/wan-video/wan-2.5-t2v) | Alibaba Wan 2.5 text to video generation model | 421 |
| [xlabs-ai/flux-dev-realism](https://replicate.com/xlabs-ai/flux-dev-realism) | FLUX.1-dev with XLabs-AI‚Äôs realism lora | 420 |
| [google/upscaler](https://replicate.com/google/upscaler) | Upscale images 2x or 4x times | 418 |
| [lucataco/trim-video](https://replicate.com/lucataco/trim-video) | Simple tool to quickly trim a video or audio file | 416 |
| [lucataco/ltx-video-0.9.8-distilled](https://replicate.com/lucataco/ltx-video-0.9.8-distilled) | Generate native long-form video, with controllability | 403 |
| [dashed/whisperx-subtitles-replicate](https://replicate.com/dashed/whisperx-subtitles-replicate) | Generates subtitles from audio using whisperX (faster-whisper-large-v3) | 402 |
| [openai/gpt-oss-20b](https://replicate.com/openai/gpt-oss-20b) | 20b open-weight language model from OpenAI | 401 |
| [ahmdyassr/detect-crop-face](https://replicate.com/ahmdyassr/detect-crop-face) | A simple model to detect and crop face found in image, made for https://outfit.fm | 400 |
| [lucataco/illusion-diffusion-hq](https://replicate.com/lucataco/illusion-diffusion-hq) | Monster Labs QrCode ControlNet on top of SD Realistic Vision v5.1 | 398 |
| [wan-video/wan-2.5-t2v-fast](https://replicate.com/wan-video/wan-2.5-t2v-fast) | Wan 2.5 text-to-video, optimized for speed | 395 |
| [nvidia/canary-qwen-2.5b](https://replicate.com/nvidia/canary-qwen-2.5b) | üé§The best open-source speech-to-text model as of Jul 2025, transcribing audio with record 5.63% WER and enabling AI tasks like summarization directly from speech‚ú® | 393 |
| [declare-lab/tango](https://replicate.com/declare-lab/tango) | Tango 2: Use text prompts to make sound effects | 391 |
| [luma/photon-flash](https://replicate.com/luma/photon-flash) | Accelerated variant of Photon prioritizing speed while maintaining quality | 378 |
| [recraft-ai/recraft-20b-svg](https://replicate.com/recraft-ai/recraft-20b-svg) | Affordable and fast vector images | 374 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 370 |
| [bria/increase-resolution](https://replicate.com/bria/increase-resolution) | Bria Increase resolution upscales the resolution of any image. It increases resolution using a dedicated upscaling method that preserves the original image content without regeneration. | 363 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 361 |
| [black-forest-labs/flux-redux-dev](https://replicate.com/black-forest-labs/flux-redux-dev) | Open-weight image variation model. Create new versions while preserving key elements of your original. | 360 |
| [fermatresearch/sdxl-controlnet-lora](https://replicate.com/fermatresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 353 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 352 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 352 |
| [wan-video/wan-2.5-i2v-fast](https://replicate.com/wan-video/wan-2.5-i2v-fast) | Wan 2.5 image-to-video, optimized for speed | 349 |
| [anthropic/claude-4.5-haiku](https://replicate.com/anthropic/claude-4.5-haiku) | Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed | 346 |
| [minimax/hailuo-02-fast](https://replicate.com/minimax/hailuo-02-fast) | A low cost and fast version of Hailuo 02. Generate 6s and 10s videos in 512p | 336 |
| [qwen/qwen3-235b-a22b-instruct-2507](https://replicate.com/qwen/qwen3-235b-a22b-instruct-2507) | Updated Qwen3 model for instruction following | 327 |
| [deepseek-ai/deepseek-v3.1](https://replicate.com/deepseek-ai/deepseek-v3.1) | Latest hybrid thinking model from Deepseek | 324 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 324 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 320 |
| [lightricks/ltx-2-pro](https://replicate.com/lightricks/ltx-2-pro) | Delivers high visual fidelity with fast turnaround. Great for daily content creation, marketing teams, and iterative creative workflows. | 319 |
| [abiruyt/text-extract-ocr](https://replicate.com/abiruyt/text-extract-ocr) | A simple OCR Model that can easily extract text from an image. | 316 |
| [kwaivgi/kling-v2.1-master](https://replicate.com/kwaivgi/kling-v2.1-master) | A premium version of Kling v2.1 with superb dynamics and prompt adherence. Generate 1080p 5s and 10s videos from text or an image | 315 |
| [aisha-ai-official/wai-nsfw-illustrious-v12](https://replicate.com/aisha-ai-official/wai-nsfw-illustrious-v12) | null | 315 |
| [openai/dall-e-3](https://replicate.com/openai/dall-e-3) | An AI system that can create realistic images and art from a description in natural language. | 310 |
| [danila013/ghibli-easycontrol](https://replicate.com/danila013/ghibli-easycontrol) | Ghiblify your image ‚Äì ChatGPT-level quality, 10√ó faster and cheaper. | 307 |
| [fottoai/remove-bg-2](https://replicate.com/fottoai/remove-bg-2) | Remove image background with custom model to better result. | 305 |
| [openai/gpt-4.1-mini](https://replicate.com/openai/gpt-4.1-mini) | Fast, affordable version of GPT-4.1 | 303 |
| [usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5](https://replicate.com/usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5) | Inpainting || multi-controlnet || single-controlnet || ip-adapter || ip adapter face || ip adapter plus || No ip adapter | 297 |
| [yorickvp/llava-v1.6-vicuna-13b](https://replicate.com/yorickvp/llava-v1.6-vicuna-13b) | LLaVA v1.6: Large Language and Vision Assistant (Vicuna-13B) | 295 |
| [flux-kontext-apps/text-removal](https://replicate.com/flux-kontext-apps/text-removal) | Remove all text from an image with FLUX.1 Kontext | 294 |
| [bytedance/latentsync](https://replicate.com/bytedance/latentsync) | LatentSync: generate high-quality lip sync animations | 293 |
| [shreejalmaharjan-27/tiktok-short-captions](https://replicate.com/shreejalmaharjan-27/tiktok-short-captions) | Generate Tiktok-Style Captions powered by Whisper (GPU) | 291 |
| [minimax/hailuo-2.3](https://replicate.com/minimax/hailuo-2.3) | A high-fidelity video generation model optimized for realistic human motion, cinematic VFX, expressive characters, and strong prompt and style adherence across both text-to-video and image-to-video workflows | 290 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 290 |
| [luma/reframe-image](https://replicate.com/luma/reframe-image) | Change the aspect ratio of any photo using AI (not cropping) | 284 |
| [flux-kontext-apps/face-to-many-kontext](https://replicate.com/flux-kontext-apps/face-to-many-kontext) | Become a character, in style | 282 |
| [zsxkib/jina-clip-v2](https://replicate.com/zsxkib/jina-clip-v2) | Jina-CLIP v2: 0.9B multimodal embedding model with 89-language multilingual support, 512x512 image resolution, and Matryoshka representations | 282 |
| [chenxwh/sdxl-flash](https://replicate.com/chenxwh/sdxl-flash) | Fast sdxl with higher quality | 282 |
| [aisha-ai-official/prefect-pony-xl-v5](https://replicate.com/aisha-ai-official/prefect-pony-xl-v5) | null | 280 |
| [runwayml/upscale-v1](https://replicate.com/runwayml/upscale-v1) | Upscale videos by 4x, up to a maximum of 4k | 279 |
| [xinntao/esrgan](https://replicate.com/xinntao/esrgan) | Image 4x super-resolution | 278 |
| [bria/fibo](https://replicate.com/bria/fibo) | SOTA Open source model trained on licensed data, transforming intent into structured control for precise, high-quality AI image generation in enterprise and agentic workflows. | 275 |
| [flux-kontext-apps/portrait-series](https://replicate.com/flux-kontext-apps/portrait-series) | Create a series of portrait photos from a single image | 264 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 264 |
| [chenxwh/depth-anything-v2](https://replicate.com/chenxwh/depth-anything-v2) | Depth estimation with faster inference speed, fewer parameters, and higher depth accuracy. | 262 |
| [minimax/speech-2.6-hd](https://replicate.com/minimax/speech-2.6-hd) | MiniMax Speech 2.6 HD delivers studio-quality multilingual text-to-audio on Replicate with nuanced prosody, subtitle export, and premium voices | 260 |
| [lqhl/realesrgan](https://replicate.com/lqhl/realesrgan) | Image restoration and face enhancement | 258 |
| [methexis-inc/img2prompt](https://replicate.com/methexis-inc/img2prompt) | Get an approximate text prompt, with style, matching an image.  (Optimized for stable-diffusion (clip ViT-L/14)) | 253 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 252 |
| [lucataco/qwen2-vl-7b-instruct](https://replicate.com/lucataco/qwen2-vl-7b-instruct) | Latest model in the Qwen family for chatting with video and image models | 248 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 248 |
| [google/lyria-2](https://replicate.com/google/lyria-2) | Lyria 2 is a music generation model that produces 48kHz stereo audio through text-based prompts | 246 |
| [lucataco/hermes-2-pro-llama-3-8b](https://replicate.com/lucataco/hermes-2-pro-llama-3-8b) | Hermes 2 Pro is an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house | 243 |
| [littlemonsterzhang/wai90_sdxl](https://replicate.com/littlemonsterzhang/wai90_sdxl) | WAI-NSFW-illustrious-SDXL  v.90 | 238 |
| [luma/reframe-video](https://replicate.com/luma/reframe-video) | Change the aspect ratio of any video up to 30 seconds long, outputs will be 720p | 237 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 236 |
| [wan-video/wan-2.2-i2v-a14b](https://replicate.com/wan-video/wan-2.2-i2v-a14b) | Image-to-video at 720p and 480p with Wan 2.2 A14B | 235 |
| [fofr/realvisxl-v3](https://replicate.com/fofr/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 235 |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | Fast FLUX DEV -> Flux Controlnet Canny, Controlnet Depth , Controlnet Line Art, Controlnet Upscaler - You can use just one controlnet or All - LORAs: HyperFlex LoRA , Add Details LoRA , Realism LoRA | 234 |
| [lucataco/ms-img2vid](https://replicate.com/lucataco/ms-img2vid) | Turn any image into a video | 231 |
| [arielreplicate/deoldify_image](https://replicate.com/arielreplicate/deoldify_image) | Add colours to old images | 231 |
| [pikachupichu25/live-portrait-image](https://replicate.com/pikachupichu25/live-portrait-image) | Match facial expression using a driving image using LivePortrait as a base | 228 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 226 |
| [catacolabs/cartoonify](https://replicate.com/catacolabs/cartoonify) | Turn your image into a cartoon | 224 |
| [lucataco/ssd-1b](https://replicate.com/lucataco/ssd-1b) | Segmind Stable Diffusion Model (SSD-1B) is a distilled 50% smaller version of SDXL, offering a 60% speedup while maintaining high-quality text-to-image generation capabilities | 221 |
| [aaronaftab/mirage-ghibli](https://replicate.com/aaronaftab/mirage-ghibli) | Ghiblify any image, 10x cheaper/faster than GPT 4o | 220 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 220 |
| [flux-kontext-apps/change-haircut](https://replicate.com/flux-kontext-apps/change-haircut) | Quickly change someone's hair style and hair color, powered by FLUX.1 Kontext [pro] | 218 |
| [bytedance/sa2va-8b-image](https://replicate.com/bytedance/sa2va-8b-image) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 218 |
| [ideogram-ai/ideogram-v2a-turbo](https://replicate.com/ideogram-ai/ideogram-v2a-turbo) | Like Ideogram v2 turbo, but now faster and cheaper | 216 |
| [lucataco/nsfw_video_detection](https://replicate.com/lucataco/nsfw_video_detection) | FalconAIs NSFW detection model, extended for videos | 212 |
| [konieshadow/fooocus-api](https://replicate.com/konieshadow/fooocus-api) | Third party Fooocus replicate model | 211 |
| [sync/lipsync-2](https://replicate.com/sync/lipsync-2) | Generate realistic lipsyncs with Sync Labs' 2.0 model | 210 |
| [flux-kontext-apps/professional-headshot](https://replicate.com/flux-kontext-apps/professional-headshot) | Create a professional headshot photo from any single image | 209 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 209 |
| [espressotechie/ai-hst-vg](https://replicate.com/espressotechie/ai-hst-vg) | Hair swap | 204 |
| [pixverse/lipsync](https://replicate.com/pixverse/lipsync) | Generate realistic lipsync animations from audio for high-quality synchronization | 203 |
| [aicapcut/stable-video-diffusion-img2vid-xt-optimized](https://replicate.com/aicapcut/stable-video-diffusion-img2vid-xt-optimized) | Generate video | 201 |
| [tmappdev/change_video_bg](https://replicate.com/tmappdev/change_video_bg) | Change or Replace Video Background with any Image | 199 |
| [ardianfe/demucs-prod](https://replicate.com/ardianfe/demucs-prod) | sound separation with demucs | 196 |
| [zsxkib/whisper-lazyloading](https://replicate.com/zsxkib/whisper-lazyloading) | Convert speech in audio to text w/ `tiny`, `small`, `base`, and `large-v3` models | 194 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 192 |
| [bria/genfill](https://replicate.com/bria/genfill) | Bria GenFill enables high-quality object addition or visual transformation. Trained exclusively on licensed data for safe and risk-free commercial use. | 190 |
| [aisha-ai-official/miaomiao-harem-illustrious-v1](https://replicate.com/aisha-ai-official/miaomiao-harem-illustrious-v1) | null | 189 |
| [fofr/expression-editor](https://replicate.com/fofr/expression-editor) | Quickly edit the expression of a face | 189 |
| [lucataco/video-merge](https://replicate.com/lucataco/video-merge) | Simple tool to merge together separate video snippets | 188 |
| [cjwbw/bigcolor](https://replicate.com/cjwbw/bigcolor) | Colorization using a Generative Color Prior for Natural Images | 188 |
| [idea-research/ram-grounded-sam](https://replicate.com/idea-research/ram-grounded-sam) | A Strong Image Tagging Model with Segment Anything | 187 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 187 |
| [mtg/essentia-bpm](https://replicate.com/mtg/essentia-bpm) | Tempo BPM estimation with Essentia | 186 |
| [reve/edit](https://replicate.com/reve/edit) | Image editing model from Reve | 185 |
| [aisha-ai-official/likereality-pony-v1](https://replicate.com/aisha-ai-official/likereality-pony-v1) | null | 177 |
| [runwayml/gen4-turbo](https://replicate.com/runwayml/gen4-turbo) | Generate 5s and 10s 720p videos fast | 173 |
| [elevenlabs/v3](https://replicate.com/elevenlabs/v3) | The most expressive Text to Speech model | 168 |
| [xlabs-ai/flux-dev-controlnet](https://replicate.com/xlabs-ai/flux-dev-controlnet) | XLabs v3 canny, depth and soft edge controlnets for Flux.1 Dev | 160 |
| [stability-ai/stable-diffusion-3.5-medium](https://replicate.com/stability-ai/stable-diffusion-3.5-medium) | 2.5 billion parameter image model with improved MMDiT-X architecture | 159 |
| [jakedahn/flux-latentpop](https://replicate.com/jakedahn/flux-latentpop) | flux-latentpop features vibrant backgrounds with grungy limited screenprinting color goodness. | 157 |
| [qr2ai/outline](https://replicate.com/qr2ai/outline) | From Sketch to Reality: Transforming Outlines into Lifelike Images | 156 |
| [bytedance/omni-human](https://replicate.com/bytedance/omni-human) | Turns your audio/video/images into professional-quality animated videos | 155 |
| [character-ai/ovi-i2v](https://replicate.com/character-ai/ovi-i2v) | Ovi: generate videos with audio from image and text inputs | 150 |
| [minimax/voice-cloning](https://replicate.com/minimax/voice-cloning) | Clone voices to use with Minimax's speech-02-hd and speech-02-turbo | 150 |
| [kwaivgi/kling-lip-sync](https://replicate.com/kwaivgi/kling-lip-sync) | Add lip-sync to any video with an audio file or text | 149 |
| [wan-video/wan-2.2-animate-replace](https://replicate.com/wan-video/wan-2.2-animate-replace) | Use Wan 2.2 Animate to replace a character in a video scene | 149 |
| [luma/ray](https://replicate.com/luma/ray) | Fast, high quality text-to-video and image-to-video (Also known as Dream Machine) | 148 |
| [cureau/force-align-wordstamps](https://replicate.com/cureau/force-align-wordstamps) | Takes audio (mp3) and a "source-of-truth" audio transcript (string) as input and returns precise timestamps. | 148 |
| [bytedance/bagel](https://replicate.com/bytedance/bagel) | ü•ØByteDance Seed's Bagel Unified multimodal AI that generates images, edits images, and understands images in one 7B parameter modelü•Ø | 144 |
| [adirik/multilingual-e5-large](https://replicate.com/adirik/multilingual-e5-large) | Multilingual E5-large language embedding model | 144 |
| [ahmdyassr/mask-clothing](https://replicate.com/ahmdyassr/mask-clothing) | Super fast clothing (and face) segmentation and masking with erosion and dilation capability, made for https://outfit.fm | 142 |
| [fictions-ai/autocaption](https://replicate.com/fictions-ai/autocaption) | Automatically add captions to a video | 141 |
| [nandycc/sdxl-app-icons](https://replicate.com/nandycc/sdxl-app-icons) | Fine tuned to generate awesome app icons, by aistartupkit.com | 141 |
| [hnesk/whisper-wordtimestamps](https://replicate.com/hnesk/whisper-wordtimestamps) | openai/whisper with exposed settings for word_timestamps | 139 |
| [zsxkib/blip-3](https://replicate.com/zsxkib/blip-3) | Blip 3 / XGen-MM, Answers questions about images ({blip3,xgen-mm}-phi3-mini-base-r-v1) | 138 |
| [lucataco/split-screen-video](https://replicate.com/lucataco/split-screen-video) | Combines two videos into a single split-screen layout | 137 |
| [x-lance/f5-tts](https://replicate.com/x-lance/f5-tts) | F5-TTS, the new state-of-the-art in open source voice cloning | 136 |
| [wavespeedai/qwen-image](https://replicate.com/wavespeedai/qwen-image) | A 20B MMDiT model for next-gen text-to-image generation | 135 |
| [zsxkib/audio-flamingo-3](https://replicate.com/zsxkib/audio-flamingo-3) | üéßAdvanced audio understanding with step-by-step reasoningüì£ | 134 |
| [okaris/live-portrait](https://replicate.com/okaris/live-portrait) | null | 133 |
| [lucataco/animate-diff](https://replicate.com/lucataco/animate-diff) | Animate Your Personalized Text-to-Image Diffusion Models | 132 |
| [meta/sam-2](https://replicate.com/meta/sam-2) | SAM 2: Segment Anything v2 (for Images) | 131 |
| [lucataco/dolphin-2.9-llama3-8b](https://replicate.com/lucataco/dolphin-2.9-llama3-8b) | Dolphin-2.9 has a variety of instruction, conversational, and coding skills. It also has initial agentic abilities and supports function calling | 131 |
| [shanginn/supir](https://replicate.com/shanginn/supir) | null | 131 |
| [kwaivgi/kling-v2.0](https://replicate.com/kwaivgi/kling-v2.0) | Generate 5s and 10s videos in 720p resolution | 130 |
| [stability-ai/stable-audio-2.5](https://replicate.com/stability-ai/stable-audio-2.5) | Generate high-quality music and sound from text prompts | 129 |
| [stability-ai/stable-diffusion-img2img](https://replicate.com/stability-ai/stable-diffusion-img2img) | Generate a new image from an input image with Stable Diffusion | 129 |
| [openai/gpt-4o-transcribe](https://replicate.com/openai/gpt-4o-transcribe) | A speech-to-text model that uses GPT-4o to transcribe audio | 126 |
| [idan054/sarra-video-maker-v1](https://replicate.com/idan054/sarra-video-maker-v1) | Cool | 125 |
| [pixverse/pixverse-v4](https://replicate.com/pixverse/pixverse-v4) | Quickly generate smooth 5s or 8s videos at 540p, 720p or 1080p | 124 |
| [cjwbw/videocrafter](https://replicate.com/cjwbw/videocrafter) | VideoCrafter2: Text-to-Video and Image-to-Video Generation and Editing | 123 |
| [pbarker/gfpgan-video](https://replicate.com/pbarker/gfpgan-video) | GFPGAN for human face video upscaling | 122 |
| [wan-video/wan-2.2-s2v](https://replicate.com/wan-video/wan-2.2-s2v) | Generate a video from an audio clip and a reference image | 121 |
| [turian/insanely-fast-whisper-with-video](https://replicate.com/turian/insanely-fast-whisper-with-video) | whisper-large-v3, incredibly fast, with video transcription | 121 |
| [adirik/flux-cinestill](https://replicate.com/adirik/flux-cinestill) | Flux lora, use "CNSTLL" to trigger | 119 |
| [mejiabrayan/logoai](https://replicate.com/mejiabrayan/logoai) | null | 119 |
| [lucataco/dreamshaper-xl-lightning](https://replicate.com/lucataco/dreamshaper-xl-lightning) | dreamshaper-xl-lightning is a Stable Diffusion model that has been fine-tuned on SDXL | 116 |
| [adirik/t2i-adapter-sdxl-canny](https://replicate.com/adirik/t2i-adapter-sdxl-canny) | Modify images using canny edges | 115 |
| [lucataco/wan-2.2-first-last-frame](https://replicate.com/lucataco/wan-2.2-first-last-frame) | Wan 2.2 First and Last Frame using 8-step inference w/ Lightning LoRA | 114 |
| [asiryan/unlimited-xl](https://replicate.com/asiryan/unlimited-xl) | Unlimited XL Model (Text2Img, Img2Img and Inpainting) | 113 |
| [vufinder/vggt-1b](https://replicate.com/vufinder/vggt-1b) | Feed-forward neural network that directly infers all key 3D attributes of a scene. | 111 |
| [aisha-ai-official/pony-realism-v2.2](https://replicate.com/aisha-ai-official/pony-realism-v2.2) | null | 110 |
| [vetkastar/fooocus](https://replicate.com/vetkastar/fooocus) | Image generation, Added: inpaint_strength loras_custom_urls | 110 |
| [adirik/t2i-adapter-sdxl-depth-midas](https://replicate.com/adirik/t2i-adapter-sdxl-depth-midas) | Modify images using depth maps | 108 |
| [deepseek-ai/deepseek-vl2](https://replicate.com/deepseek-ai/deepseek-vl2) | DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL | 107 |
| [minimax/speech-2.6-turbo](https://replicate.com/minimax/speech-2.6-turbo) | Low‚Äëlatency MiniMax Speech 2.6 Turbo brings multilingual, emotional text-to-speech to Replicate with 300+ voices and real-time friendly pricing | 106 |
| [zetyquickly-org/faceswap-a-gif](https://replicate.com/zetyquickly-org/faceswap-a-gif) | Make Fun by Changing Face on a GIF! | 106 |
| [arielreplicate/robust_video_matting](https://replicate.com/arielreplicate/robust_video_matting) | extract foreground of a video | 106 |
| [aisha-ai-official/illust3relustion](https://replicate.com/aisha-ai-official/illust3relustion) | null | 104 |
| [lucataco/florence-2-base](https://replicate.com/lucataco/florence-2-base) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 103 |
| [tstramer/material-diffusion](https://replicate.com/tstramer/material-diffusion) | Stable diffusion fork for generating tileable outputs using v1.5 model | 102 |
| [wavespeedai/wan-2.1-t2v-480p](https://replicate.com/wavespeedai/wan-2.1-t2v-480p) | Accelerated inference for Wan 2.1 14B text to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation. | 101 |
