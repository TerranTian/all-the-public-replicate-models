# Model Stats
## New Models
No new models today.

## Removed Models
No models were removed today.

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [pixverse/pixverse-v5.6](https://replicate.com/pixverse/pixverse-v5.6) | Latest video model from Pixverse with astonishing physics | 213 | 841 | 25.33% |
| [lightricks/audio-to-video](https://replicate.com/lightricks/audio-to-video) | Use audio input with an image or prompt to generate videos | 51 | 227 | 22.47% |
| [black-forest-labs/flux-2-klein-9b-base-lora](https://replicate.com/black-forest-labs/flux-2-klein-9b-base-lora) | A version of FLUX.2 [klein] 9B-base that supports fast fine-tuned lora inference | 35 | 157 | 22.29% |
| [prunaai/z-image](https://replicate.com/prunaai/z-image) | An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer | 1237 | 6071 | 20.38% |
| [qwen/qwen3-tts](https://replicate.com/qwen/qwen3-tts) | A unified Text-to-Speech demo featuring three powerful modes: Voice, Clone and Design | 2212 | 12383 | 17.86% |
| [moonshotai/kimi-k2.5](https://replicate.com/moonshotai/kimi-k2.5) | Moonshot AI's latest open model. It unifies vision and text, thinking and non-thinking modes, and single-agent and multi-agent execution into one model | 99 | 570 | 17.37% |
| [jyoung105/stable-diffusion-3.5-medium](https://replicate.com/jyoung105/stable-diffusion-3.5-medium) | null | 2 | 13 | 15.38% |
| [elevenlabs/v3](https://replicate.com/elevenlabs/v3) | The most expressive Text to Speech model | 295 | 1978 | 14.91% |
| [tejasunku/qwen3-reranker-8b](https://replicate.com/tejasunku/qwen3-reranker-8b) | Rerank query search results using qwen3 reranker 8b model, with support for instructions | 12 | 88 | 13.64% |
| [black-forest-labs/flux-2-klein-9b](https://replicate.com/black-forest-labs/flux-2-klein-9b) | 4 step distilled version of FLUX.2 [klein]. A foundation model for maximum flexibility and control | 2268 | 18343 | 12.36% |
| [dmtanner/parakeet-tdt-0.6b-v3](https://replicate.com/dmtanner/parakeet-tdt-0.6b-v3) | ASR model, created by Nvidia, with word-level timestamps available.  Supports .wav inputs, or m3u8 urls, with a start and end time (to only process a section of the m3u8). | 165 | 1492 | 11.06% |
| [datalab-to/ocr](https://replicate.com/datalab-to/ocr) | Detect and transcribe text in images with accurate bounding boxes, layout analysis, reding order, and table recognition, in 90 languages | 1228 | 11631 | 10.56% |
| [sundai-club/line_cat](https://replicate.com/sundai-club/line_cat) | A fine-tuned FLUX.1 model | 20 | 200 | 10.00% |
| [grey-hound432/fast-study-sheet](https://replicate.com/grey-hound432/fast-study-sheet) | Generate printable PDF study worksheets with an answer key from any topic. | 1 | 11 | 9.09% |
| [qwen/qwen-image-2512](https://replicate.com/qwen/qwen-image-2512) | Qwen Image 2512 is an improved version of Qwen Image with more realistic human generation, finer textures, and stronger text rendering | 3100 | 37072 | 8.36% |
| [ultralytics/yolov8s-worldv2](https://replicate.com/ultralytics/yolov8s-worldv2) | Ultralytics YOLOv8s worldv2 Real-Time Open-Vocabulary Object Detection model with 12.7M parameters. Achieves 37.7 mAP50-95 on COCO dataset. Optimized for real-time inference | 139 | 1680 | 8.27% |
| [maikocode/ascii-style](https://replicate.com/maikocode/ascii-style) | Turn image into ASCII style. If you like this LoRA visit my app: YourAIPhotographer.com | 6 | 81 | 7.41% |
| [qwen/qwen-image-edit-2511](https://replicate.com/qwen/qwen-image-edit-2511) | An enhanced version over Qwen-Image-Edit-2509, featuring multiple improvements including notably better consistency | 55814 | 756702 | 7.38% |
| [black-forest-labs/flux-2-klein-4b-base-lora](https://replicate.com/black-forest-labs/flux-2-klein-4b-base-lora) | A version of FLUX.2 [klein] 4B-base that supports fast fine-tuned lora inference | 5 | 68 | 7.35% |
| [sourceful/riverflow-v2-fast-preview](https://replicate.com/sourceful/riverflow-v2-fast-preview) | Fast version of Sourceful Riverflow image generation model, ideal for brand assets | 12 | 187 | 6.42% |
| [yuanrui-mdt-info/sd-xl-interior-design](https://replicate.com/yuanrui-mdt-info/sd-xl-interior-design) | Redesign room photos while preserving spatial structure | 3 | 47 | 6.38% |
| [black-forest-labs/flux-2-klein-4b](https://replicate.com/black-forest-labs/flux-2-klein-4b) | Very fast image generation and editing model. 4 steps distilled, sub-second inference for production and near real-time applications. | 111152 | 1798003 | 6.18% |
| [invarrow/carai-offcial](https://replicate.com/invarrow/carai-offcial) | CarAI: Evaluate Car Damages | 44 | 757 | 5.81% |
| [elevenlabs/turbo-v2.5](https://replicate.com/elevenlabs/turbo-v2.5) | High quality, low latency text to speech in 32 languages | 32 | 576 | 5.56% |
| [zsxkib/tool-merge-images](https://replicate.com/zsxkib/tool-merge-images) | Merge multiple images into clean horizontal or vertical strips with precise alignment and sizing controls. | 318 | 5822 | 5.46% |
| [kwaivgi/kling-v2.6](https://replicate.com/kwaivgi/kling-v2.6) | Kling 2.6 Pro: Top-tier image-to-video with cinematic visuals, fluid motion, and native audio generation | 4607 | 85006 | 5.42% |
| [wan-video/wan-2.6-i2v](https://replicate.com/wan-video/wan-2.6-i2v) | Alibaba Wan 2.6 image to video generation model | 945 | 17831 | 5.30% |
| [djangocc/flex-lora-trainer](https://replicate.com/djangocc/flex-lora-trainer) | null | 1 | 20 | 5.00% |
| [daanelson/yolox](https://replicate.com/daanelson/yolox) | High performance and lightweight object detection models | 5458 | 116697 | 4.68% |
| [triadmusic/beat-transformer](https://replicate.com/triadmusic/beat-transformer) | Model to identify Beats in a song and return the beats/second | 1 | 22 | 4.55% |
| [meta/llama-4-maverick-instruct](https://replicate.com/meta/llama-4-maverick-instruct) | A 17 billion parameter model with 128 experts | 133558 | 3071266 | 4.35% |
| [bria/product-shadow](https://replicate.com/bria/product-shadow) | Add consistent, customizable shadows to product cutouts for enhanced visual appeal | 37 | 880 | 4.20% |
| [lightricks/ltx-2-distilled](https://replicate.com/lightricks/ltx-2-distilled) | The first open source audio-video model | 219 | 5282 | 4.15% |
| [erickluis00/all-in-one-audio](https://replicate.com/erickluis00/all-in-one-audio) | AI Music Structure Analyzer + Stem Splitter using Demucs & Mdx-Net with Python-Audio-Separator | 4027 | 99923 | 4.03% |
| [lucataco/r1-1776-70b](https://replicate.com/lucataco/r1-1776-70b) | A version of the DeepSeek-R1 model that has been post trained to provide unbiased, accurate, and factual information by Perplexity | 11 | 273 | 4.03% |
| [capcheck/ai-image-detection](https://replicate.com/capcheck/ai-image-detection) | Detects if an image is real or fake. | 9 | 239 | 3.77% |
| [zhyjiong/sora_watermark_remover](https://replicate.com/zhyjiong/sora_watermark_remover) | Remove 'Sora' watermark on videos generated by sora | 3 | 82 | 3.66% |
| [jasonod888/marigold-normalsv2](https://replicate.com/jasonod888/marigold-normalsv2) | Outputs a normal map for a given input image | 6 | 169 | 3.55% |
| [zeke/sd3-inpainting-with-differential-diffusion](https://replicate.com/zeke/sd3-inpainting-with-differential-diffusion) | Stable Diffusion 3 with Differential Diffusion inpainting (experimental) | 10 | 282 | 3.55% |
| [tencent/hunyuanvideo-foley](https://replicate.com/tencent/hunyuanvideo-foley) | (Research & Non-commercial use only) Text-Video-to-Audio Synthesis: Generate realistic audio from video and text descriptions | 1048 | 30526 | 3.43% |
| [prunaai/flux-2-turbo](https://replicate.com/prunaai/flux-2-turbo) | Image generation and editing with a distilled FLUX.2 [dev] by FAL. | 3985 | 116368 | 3.42% |
| [kwaivgi/kling-v2.6-motion-control](https://replicate.com/kwaivgi/kling-v2.6-motion-control) | Enables precise control of character actions and expressions from a reference image. | 3539 | 104381 | 3.39% |
| [aisha-ai-official/animereal-v2](https://replicate.com/aisha-ai-official/animereal-v2) | null | 28 | 834 | 3.36% |
| [lightricks/ltx-video-0.9.7-distilled](https://replicate.com/lightricks/ltx-video-0.9.7-distilled) | Faster slight quality reduction compared to LTX-Video 13b | 146 | 4409 | 3.31% |
| [prunaai/z-image-turbo-img2img](https://replicate.com/prunaai/z-image-turbo-img2img) | Image 2 Image version of z-image-turbo with lora support. | 1303 | 39825 | 3.27% |
| [meta/cutler](https://replicate.com/meta/cutler) | Cut and Learn for unsupervised object detection and instance segmentation | 120 | 3740 | 3.21% |
| [bytedance/seedance-1.5-pro](https://replicate.com/bytedance/seedance-1.5-pro) | A joint audio-video model that accurately follows complex instructions. | 8244 | 264951 | 3.11% |
| [samim23/internlm-xcomposer2](https://replicate.com/samim23/internlm-xcomposer2) | InternLM-XComposer-2.5: A Versatile Large Vision Language Model Supporting Long-Contextual Input and Output | 3 | 99 | 3.03% |
| [google/gemini-3-flash](https://replicate.com/google/gemini-3-flash) | Google's most intelligent model built for speed with frontier intelligence, superior search, and grounding | 2614 | 87099 | 3.00% |
| [prunaai/p-image](https://replicate.com/prunaai/p-image) | A sub 1 second text-to-image model built for production use cases. | 79289 | 2704020 | 2.93% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [black-forest-labs/flux-schnell](https://replicate.com/black-forest-labs/flux-schnell) | The fastest image generation model tailored for local development and personal use | 605950 |
| [prunaai/z-image-turbo](https://replicate.com/prunaai/z-image-turbo) | Z-Image Turbo is a super fast text-to-image model of 6B parameters developed by Tongyi-MAI. | 477207 |
| [turian/insanely-fast-whisper-with-video](https://replicate.com/turian/insanely-fast-whisper-with-video) | whisper-large-v3, incredibly fast, with video transcription | 443816 |
| [google/nano-banana](https://replicate.com/google/nano-banana) | Google's latest image editing model in Gemini 2.5 | 309204 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 282620 |
| [openai/gpt-4o-mini](https://replicate.com/openai/gpt-4o-mini) | Low latency, low cost version of OpenAI's GPT-4o model | 276004 |
| [prunaai/p-image-edit](https://replicate.com/prunaai/p-image-edit) | A sub 1 second 0.01$ multi-image editing model built for production use cases. For image generation, check out p-image here: https://replicate.com/prunaai/p-image | 215673 |
| [falcons-ai/nsfw_image_detection](https://replicate.com/falcons-ai/nsfw_image_detection) | Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 149834 |
| [bytedance/seedream-4](https://replicate.com/bytedance/seedream-4) | Unified text-to-image generation and precise single-sentence editing at up to 4K resolution | 139657 |
| [google/nano-banana-pro](https://replicate.com/google/nano-banana-pro) | Google's state of the art image generation and editing model üçåüçå | 134157 |
| [jaaari/kokoro-82m](https://replicate.com/jaaari/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 133603 |
| [meta/llama-4-maverick-instruct](https://replicate.com/meta/llama-4-maverick-instruct) | A 17 billion parameter model with 128 experts | 133558 |
| [black-forest-labs/flux-2-klein-4b](https://replicate.com/black-forest-labs/flux-2-klein-4b) | Very fast image generation and editing model. 4 steps distilled, sub-second inference for production and near real-time applications. | 111152 |
| [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct) | An 8 billion parameter language model from Meta, fine tuned for chat completions | 96112 |
| [nicolascoutureau/video-utils](https://replicate.com/nicolascoutureau/video-utils) | null | 80405 |
| [prunaai/p-image](https://replicate.com/prunaai/p-image) | A sub 1 second text-to-image model built for production use cases. | 79289 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 71827 |
| [black-forest-labs/flux-kontext-pro](https://replicate.com/black-forest-labs/flux-kontext-pro) | A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language | 71014 |
| [black-forest-labs/flux-dev](https://replicate.com/black-forest-labs/flux-dev) | A 12 billion parameter rectified flow transformer capable of generating images from text descriptions | 70963 |
| [adirik/grounding-dino](https://replicate.com/adirik/grounding-dino) | Detect everything with language! | 65082 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! ü§ó | 64980 |
| [wan-video/wan-2.2-i2v-fast](https://replicate.com/wan-video/wan-2.2-i2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B image-to-video | 56297 |
| [qwen/qwen-image-edit-2511](https://replicate.com/qwen/qwen-image-edit-2511) | An enhanced version over Qwen-Image-Edit-2509, featuring multiple improvements including notably better consistency | 55814 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 55481 |
| [aisha-ai-official/animagine-xl-v4-opt](https://replicate.com/aisha-ai-official/animagine-xl-v4-opt) | null | 55157 |
| [851-labs/background-remover](https://replicate.com/851-labs/background-remover) | Remove backgrounds from images. | 54151 |
| [bytedance/sdxl-lightning-4step](https://replicate.com/bytedance/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 51671 |
| [openai/gpt-image-1.5](https://replicate.com/openai/gpt-image-1.5) | OpenAI's latest image generation model with better instruction following and adherence to prompts | 51407 |
| [prunaai/flux-fast](https://replicate.com/prunaai/flux-fast) | This is the fastest Flux endpoint in the world. | 50457 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 49410 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 48927 |
| [bytedance/seedream-4.5](https://replicate.com/bytedance/seedream-4.5) | Seedream 4.5: Upgraded Bytedance image model with stronger spatial understanding and world knowledge | 44386 |
| [ideogram-ai/ideogram-v3-turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo) | Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles | 44150 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 43204 |
| [zedge/stable-diffusion](https://replicate.com/zedge/stable-diffusion) | Private instance of stable-diffusion | 41391 |
| [black-forest-labs/flux-2-pro](https://replicate.com/black-forest-labs/flux-2-pro) | High-quality image generation and editing with support for eight reference images | 41119 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ‚ö°Ô∏è Blazing fast audio transcription with speaker diarization | Whisper Large V3 Turbo | word & sentence level timestamps | prompt | 38123 |
| [prunaai/flux-kontext-fast](https://replicate.com/prunaai/flux-kontext-fast) | Ultra fast flux kontext endpoint | 36851 |
| [black-forest-labs/flux-1.1-pro](https://replicate.com/black-forest-labs/flux-1.1-pro) | Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity. | 34331 |
| [bytedance/hyper-flux-8step](https://replicate.com/bytedance/hyper-flux-8step) | Hyper FLUX 8-step by ByteDance | 30871 |
| [openai/gpt-5-nano](https://replicate.com/openai/gpt-5-nano) | Fastest, most cost-effective GPT-5 model from OpenAI | 29951 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x | 28745 |
| [lucataco/moondream2](https://replicate.com/lucataco/moondream2) | moondream2 is a small vision language model designed to run efficiently on edge devices | 27494 |
| [black-forest-labs/flux-kontext-dev](https://replicate.com/black-forest-labs/flux-kontext-dev) | Open-weight version of FLUX.1 Kontext | 24821 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | ü¶ô LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 24339 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 23008 |
| [black-forest-labs/flux-2-dev](https://replicate.com/black-forest-labs/flux-2-dev) | Quality image generation and editing with support for reference images | 22301 |
| [google/imagen-4-fast](https://replicate.com/google/imagen-4-fast) | Use this fast version of Imagen 4 when speed and cost are more important than quality | 20609 |
| [humbleworth/price-predict-v1](https://replicate.com/humbleworth/price-predict-v1) | Predicts the value of a domain name. | 20316 |
| [google/gemini-3-pro](https://replicate.com/google/gemini-3-pro) | Google's most advanced reasoning Gemini model | 18265 |
| [deepseek-ai/deepseek-v3](https://replicate.com/deepseek-ai/deepseek-v3) | DeepSeek-V3-0324 is the leading non-reasoning model, a milestone for open source | 16552 |
| [anthropic/claude-4-sonnet](https://replicate.com/anthropic/claude-4-sonnet) | Claude Sonnet 4 is a significant upgrade to 3.7, delivering superior coding and reasoning while responding more precisely to your instructions | 16050 |
| [qwen/qwen-image-edit-plus](https://replicate.com/qwen/qwen-image-edit-plus) | The latest Qwen-Image‚Äôs iteration with improved multi-image editing, single-image consistency, and native support for ControlNet | 15767 |
| [tmappdev/lang-segment-anything](https://replicate.com/tmappdev/lang-segment-anything) | Segment Anything with prompts | 15485 |
| [minimax/speech-02-turbo](https://replicate.com/minimax/speech-02-turbo) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Designed for real-time applications with low latency | 15193 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 15163 |
| [google/imagen-4](https://replicate.com/google/imagen-4) | Google's Imagen 4 flagship model | 14805 |
| [lucataco/codeformer](https://replicate.com/lucataco/codeformer) | Robust face restoration algorithm for old photos/AI-generated faces | 14341 |
| [minimax/speech-02-hd](https://replicate.com/minimax/speech-02-hd) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Optimized for high-fidelity applications like voiceovers and audiobooks. | 13024 |
| [openai/clip](https://replicate.com/openai/clip) | Official CLIP models, generate CLIP (clip-vit-large-patch14) text & image embeddings | 13006 |
| [comfyui/any-comfyui-workflow](https://replicate.com/comfyui/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/replicate/cog-comfyui | 12955 |
| [google/gemini-2.5-flash](https://replicate.com/google/gemini-2.5-flash) | Google‚Äôs hybrid ‚Äúthinking‚Äù AI model optimized for speed and cost-efficiency | 12593 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Generate image captions | 12111 |
| [alexgenovese/upscaler](https://replicate.com/alexgenovese/upscaler) | GFPGAN aims at developing Practical Algorithms for Real-world Face and Object Restoration | 11913 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 11216 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 10675 |
| [bytedance/hyper-flux-16step](https://replicate.com/bytedance/hyper-flux-16step) | Hyper FLUX 16-step by ByteDance | 10293 |
| [zedge/real-esrgan](https://replicate.com/zedge/real-esrgan) | Private instance of real-esrgan | 9437 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 9336 |
| [black-forest-labs/flux-krea-dev](https://replicate.com/black-forest-labs/flux-krea-dev) | An opinionated text-to-image model from Black Forest Labs in collaboration with Krea that excels in photorealism. Creates images that avoid the oversaturated "AI look". | 8907 |
| [prunaai/hidream-l1-fast](https://replicate.com/prunaai/hidream-l1-fast) | This is an optimised version of the hidream-l1 model using the pruna ai optimisation toolkit! | 8891 |
| [bria/remove-background](https://replicate.com/bria/remove-background) | Bria AI's remove background model | 8762 |
| [bytedance/seedance-1.5-pro](https://replicate.com/bytedance/seedance-1.5-pro) | A joint audio-video model that accurately follows complex instructions. | 8244 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 8212 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 8130 |
| [openai/gpt-5](https://replicate.com/openai/gpt-5) | OpenAI's new model excelling at coding, writing, and reasoning. | 7950 |
| [meta/meta-llama-3-70b-instruct](https://replicate.com/meta/meta-llama-3-70b-instruct) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 7807 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 7745 |
| [bytedance/seedance-1-pro-fast](https://replicate.com/bytedance/seedance-1-pro-fast) | A faster and cheaper version of Seedance 1 Pro | 7739 |
| [openai/gpt-5-mini](https://replicate.com/openai/gpt-5-mini) | Faster version of OpenAI's flagship GPT-5 model | 7704 |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | Advance Face Swap powered by pixalto.app | 7477 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 7393 |
| [bytedance/seedance-1-lite](https://replicate.com/bytedance/seedance-1-lite) | A video generation model that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 720p resolution | 7299 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 7090 |
| [men1scus/birefnet](https://replicate.com/men1scus/birefnet) | Bilateral Reference for High-Resolution Dichotomous Image Segmentation (CAAI AIR 2024) | 7070 |
| [recraft-ai/recraft-crisp-upscale](https://replicate.com/recraft-ai/recraft-crisp-upscale) | Designed to make images sharper and cleaner, Crisp Upscale increases overall quality, making visuals suitable for web use or print-ready materials. | 6836 |
| [zsxkib/mmaudio](https://replicate.com/zsxkib/mmaudio) | Add sound to video using the MMAudio V2 model. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation. | 6724 |
| [soykertje/spleeter](https://replicate.com/soykertje/spleeter) | Spleeter is Deezer source separation library with pretrained models written in Python and uses Tensorflow. | 6718 |
| [victor-upmeet/whisperx-a40-large](https://replicate.com/victor-upmeet/whisperx-a40-large) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 for large audio files | 6625 |
| [kwaivgi/kling-v2.1](https://replicate.com/kwaivgi/kling-v2.1) | Use Kling v2.1 to generate 5s and 10s videos in 720p and 1080p resolution from a starting image (image-to-video) | 6621 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 6564 |
| [datacte/proteus-v0.2](https://replicate.com/datacte/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 6433 |
| [zedge/zoedepth](https://replicate.com/zedge/zoedepth) | null | 6397 |
| [black-forest-labs/flux-2-max](https://replicate.com/black-forest-labs/flux-2-max) | The highest fidelity image model from Black Forest Labs | 6394 |
| [black-forest-labs/flux-1.1-pro-ultra](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra) | FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism. | 6103 |
| [qwen/qwen-image](https://replicate.com/qwen/qwen-image) | An image generation foundation model in the Qwen series that achieves significant advances in complex text rendering. | 6005 |
| [recraft-ai/recraft-remove-background](https://replicate.com/recraft-ai/recraft-remove-background) | Automated background removal for images. Tuned for AI-generated content, product photos, portraits, and design workflows | 5877 |
| [openai/gpt-4.1-nano](https://replicate.com/openai/gpt-4.1-nano) | Fastest, most cost-effective GPT-4.1 model from OpenAI | 5854 |
| [datacte/proteus-v0.3](https://replicate.com/datacte/proteus-v0.3) | ProteusV0.3: The Anime Update | 5833 |
| [recraft-ai/recraft-v3](https://replicate.com/recraft-ai/recraft-v3) | Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis | 5564 |
| [daanelson/yolox](https://replicate.com/daanelson/yolox) | High performance and lightweight object detection models | 5458 |
| [black-forest-labs/flux-dev-lora](https://replicate.com/black-forest-labs/flux-dev-lora) | A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference | 5308 |
| [zsxkib/ic-light](https://replicate.com/zsxkib/ic-light) | ‚úçÔ∏è‚ú®Prompts to auto-magically relights your images | 5263 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 5188 |
| [cdingram/face-swap](https://replicate.com/cdingram/face-swap) | Image to image face swapping | 4852 |
| [bytedance/pulid](https://replicate.com/bytedance/pulid) | üìñ PuLID: Pure and Lightning ID Customization via Contrastive Alignment | 4721 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 4652 |
| [kwaivgi/kling-v2.6](https://replicate.com/kwaivgi/kling-v2.6) | Kling 2.6 Pro: Top-tier image-to-video with cinematic visuals, fluid motion, and native audio generation | 4607 |
| [fofr/flux-black-light](https://replicate.com/fofr/flux-black-light) | A flux lora fine-tuned on black light images | 4312 |
| [kwaivgi/kling-v2.5-turbo-pro](https://replicate.com/kwaivgi/kling-v2.5-turbo-pro) | Kling 2.5 Turbo Pro: Unlock pro-level text-to-video and image-to-video creation with smooth motion, cinematic depth, and remarkable prompt adherence. | 4270 |
| [black-forest-labs/flux-kontext-max](https://replicate.com/black-forest-labs/flux-kontext-max) | A premium text-based image editing model that delivers maximum performance and improved typography generation for transforming images through natural language prompts | 4247 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 4238 |
| [google/gemini-2.5-flash-image](https://replicate.com/google/gemini-2.5-flash-image) | Google's latest image generation model in Gemini 2.5 | 4148 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 4142 |
| [erickluis00/all-in-one-audio](https://replicate.com/erickluis00/all-in-one-audio) | AI Music Structure Analyzer + Stem Splitter using Demucs & Mdx-Net with Python-Audio-Separator | 4027 |
| [prunaai/flux-2-turbo](https://replicate.com/prunaai/flux-2-turbo) | Image generation and editing with a distilled FLUX.2 [dev] by FAL. | 3985 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 3960 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 3951 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 3949 |
| [ryan5453/demucs](https://replicate.com/ryan5453/demucs) | Demucs is an audio source separator created by Facebook Research. | 3901 |
| [qwen/qwen-edit-multiangle](https://replicate.com/qwen/qwen-edit-multiangle) | Camera-aware edits for Qwen/Qwen-Image-Edit-2509 with Lightning + multi-angle LoRA | 3857 |
| [anthropic/claude-4.5-sonnet](https://replicate.com/anthropic/claude-4.5-sonnet) | Claude Sonnet 4.5 is the best coding model to date, with significant improvements across the entire development lifecycle | 3851 |
| [recraft-ai/recraft-vectorize](https://replicate.com/recraft-ai/recraft-vectorize) | Convert raster images to high-quality SVG format with precision and clean vector paths, perfect for logos, icons, and scalable graphics. | 3768 |
| [black-forest-labs/flux-fill-dev](https://replicate.com/black-forest-labs/flux-fill-dev) | Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro]. | 3767 |
| [flux-kontext-apps/restore-image](https://replicate.com/flux-kontext-apps/restore-image) | Use FLUX Kontext to restore, fix scratches and damage, and colorize old photos | 3597 |
| [anthropic/claude-3.7-sonnet](https://replicate.com/anthropic/claude-3.7-sonnet) | The most intelligent Claude model and the first hybrid reasoning model on the market (claude-3-7-sonnet-20250219) | 3566 |
| [qwen/qwen-image-edit](https://replicate.com/qwen/qwen-image-edit) | Edit images using a prompt. This model extends Qwen-Image‚Äôs unique text rendering capabilities to image editing tasks, enabling precise text editing | 3541 |
| [kwaivgi/kling-v2.6-motion-control](https://replicate.com/kwaivgi/kling-v2.6-motion-control) | Enables precise control of character actions and expressions from a reference image. | 3539 |
| [runwayml/gen4-image](https://replicate.com/runwayml/gen4-image) | Runway's Gen-4 Image model with references. Use up to 3 reference images to create the exact image you need. Capture every angle. | 3536 |
| [prunaai/wan-2.2-image](https://replicate.com/prunaai/wan-2.2-image) | This model generates beautiful cinematic 2 megapixel images in 3-4 seconds and is derived from the Wan 2.2 model through optimisation techniques from the pruna package | 3534 |
| [playgroundai/playground-v2.5-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 3448 |
| [google/upscaler](https://replicate.com/google/upscaler) | Upscale images 2x or 4x times | 3445 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting by the HF Diffusers team | 3359 |
| [luma/photon](https://replicate.com/luma/photon) | High-quality image generation model optimized for creative professional workflows and ultra-high fidelity outputs | 3295 |
| [microsoft/omniparser-v2](https://replicate.com/microsoft/omniparser-v2) | OmniParser is a screen parsing tool to convert general GUI screen to structured elements. | 3208 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 3159 |
| [qwen/qwen-image-2512](https://replicate.com/qwen/qwen-image-2512) | Qwen Image 2512 is an improved version of Qwen Image with more realistic human generation, finer textures, and stronger text rendering | 3100 |
| [zedge/emoji-generator](https://replicate.com/zedge/emoji-generator) | null | 3086 |
| [meta/meta-llama-3.1-405b-instruct](https://replicate.com/meta/meta-llama-3.1-405b-instruct) | Meta's flagship 405 billion parameter language model, fine-tuned for chat completions | 3036 |
| [minimax/speech-2.6-turbo](https://replicate.com/minimax/speech-2.6-turbo) | Low‚Äëlatency MiniMax Speech 2.6 Turbo brings multilingual, emotional text-to-speech to Replicate with 300+ voices and real-time friendly pricing | 2982 |
| [topazlabs/image-upscale](https://replicate.com/topazlabs/image-upscale) | Professional-grade image upscaling, from Topaz Labs | 2973 |
| [black-forest-labs/flux-fill-pro](https://replicate.com/black-forest-labs/flux-fill-pro) | Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results. | 2952 |
| [zedge/instantid](https://replicate.com/zedge/instantid) | null | 2908 |
| [zedge/live-portrait](https://replicate.com/zedge/live-portrait) | null | 2906 |
| [zsxkib/qwen2-1.5b-instruct](https://replicate.com/zsxkib/qwen2-1.5b-instruct) | Qwen 2: A 1.5 billion parameter language model from Alibaba Cloud, fine tuned for chat completions | 2874 |
| [black-forest-labs/flux-pro](https://replicate.com/black-forest-labs/flux-pro) | State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. | 2742 |
| [philz1337x/crystal-upscaler](https://replicate.com/philz1337x/crystal-upscaler) | High-precision image upscaler optimized for portraits, faces and products. One of the upscale modes powered by Clarity AI. X:https://x.com/philz1337x | 2706 |
| [charlesmccarthy/addwatermark](https://replicate.com/charlesmccarthy/addwatermark) | Add a watermark to your videos using the power of Replicate brought to you from your friends at FullJourney.AI | 2704 |
| [franz-biz/yolo-world-xl](https://replicate.com/franz-biz/yolo-world-xl) | Real-Time Open-Vocabulary Object Detection using the xl weights | 2703 |
| [openai/gpt-image-1](https://replicate.com/openai/gpt-image-1) | A multimodal image generation model that creates high-quality images. You need to bring your own verified OpenAI key to use this model. Your OpenAI account will be charged for usage. | 2688 |
| [aisha-ai-official/anillustrious-v4](https://replicate.com/aisha-ai-official/anillustrious-v4) | null | 2678 |
| [black-forest-labs/flux-depth-dev](https://replicate.com/black-forest-labs/flux-depth-dev) | Open-weight depth-aware image generation. Edit images while preserving spatial relationships. | 2625 |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 2617 |
| [google/gemini-3-flash](https://replicate.com/google/gemini-3-flash) | Google's most intelligent model built for speed with frontier intelligence, superior search, and grounding | 2614 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 2547 |
| [prunaai/flux.1-dev-lora](https://replicate.com/prunaai/flux.1-dev-lora) | This is a 3x faster FLUX.1 [dev] model from Black Forest Labs, optimised with pruna with minimal quality loss. | 2512 |
| [sesamo-srl/bge-reranker-v2-m3](https://replicate.com/sesamo-srl/bge-reranker-v2-m3) | Newest reranker model from BAAI (https://huggingface.co/BAAI/bge-reranker-v2-m3). FP16 inference enabled. Normalize param available | 2496 |
| [bytedance/seedance-1-pro](https://replicate.com/bytedance/seedance-1-pro) | A pro version of Seedance that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 1080p resolution | 2470 |
| [minimax/image-01](https://replicate.com/minimax/image-01) | Minimax's first image model, with character reference support | 2463 |
| [smoosh-sh/baby-mystic](https://replicate.com/smoosh-sh/baby-mystic) | Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent | 2458 |
| [google/veo-3.1-fast](https://replicate.com/google/veo-3.1-fast) | New and improved version of Veo 3 Fast, with higher-fidelity video, context-aware audio and last frame support | 2413 |
| [openai/gpt-4o](https://replicate.com/openai/gpt-4o) | OpenAI's high-intelligence chat model | 2390 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 2313 |
| [black-forest-labs/flux-2-klein-9b](https://replicate.com/black-forest-labs/flux-2-klein-9b) | 4 step distilled version of FLUX.2 [klein]. A foundation model for maximum flexibility and control | 2268 |
| [wan-video/wan-2.2-5b-fast](https://replicate.com/wan-video/wan-2.2-5b-fast) | The fastest Wan 2.2 text-to-image and image-to-video model | 2247 |
| [qwen/qwen3-tts](https://replicate.com/qwen/qwen3-tts) | A unified Text-to-Speech demo featuring three powerful modes: Voice, Clone and Design | 2212 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 2210 |
| [google/imagen-4-ultra](https://replicate.com/google/imagen-4-ultra) | Use this ultra version of Imagen 4 when quality matters more than speed and cost | 2165 |
| [lucataco/frame-extractor](https://replicate.com/lucataco/frame-extractor) | Extract the first or last frame from any video file as a high-quality image | 2100 |
| [bytedance/seedream-3](https://replicate.com/bytedance/seedream-3) | A text-to-image model with support for native high-resolution (2K) image generation | 2076 |
| [saattrupdan/multilingual-e5-large-instruct](https://replicate.com/saattrupdan/multilingual-e5-large-instruct) | multilingual-e5-large-instruct: A multi-language text embedding model with custom query instructions. | 2069 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 2009 |
| [aisha-ai-official/nsfw-flux-dev](https://replicate.com/aisha-ai-official/nsfw-flux-dev) | null | 2001 |
| [zf-kbot/inpaint-and-guess-prompt](https://replicate.com/zf-kbot/inpaint-and-guess-prompt) | Use a mask to inpaint the image or generate a prompt based on the mask. | 1998 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 1993 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 1923 |
| [prunaai/flux-schnell](https://replicate.com/prunaai/flux-schnell) | This is a 3x faster FLUX.1 [schnell] model from Black Forest Labs, optimised with pruna with minimal quality loss. Contact us for more at pruna.ai | 1899 |
| [bria/eraser](https://replicate.com/bria/eraser) | SOTA Object removal, enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use | 1881 |
| [firtoz/trellis](https://replicate.com/firtoz/trellis) | A powerful 3D asset generation model | 1823 |
| [openai/gpt-4.1-mini](https://replicate.com/openai/gpt-4.1-mini) | Fast, affordable version of GPT-4.1 | 1815 |
| [lucataco/flux-schnell-lora](https://replicate.com/lucataco/flux-schnell-lora) | FLUX.1-Schnell LoRA Explorer | 1814 |
| [alphanumericuser/kokoro-82m](https://replicate.com/alphanumericuser/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 1790 |
| [mrhan1993/fooocus-api](https://replicate.com/mrhan1993/fooocus-api) | null | 1775 |
| [pollinations/modnet](https://replicate.com/pollinations/modnet) | A deep learning approach to remove background & adding new background image | 1762 |
| [lucataco/qwen2-vl-7b-instruct](https://replicate.com/lucataco/qwen2-vl-7b-instruct) | Latest model in the Qwen family for chatting with video and image models | 1757 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 1741 |
| [openai/gpt-image-1-mini](https://replicate.com/openai/gpt-image-1-mini) | A cost-efficient version of GPT Image 1 | 1730 |
| [wan-video/wan-2.5-i2v](https://replicate.com/wan-video/wan-2.5-i2v) | Alibaba Wan 2.5 Image to video generation with background audio | 1640 |
| [qwen/qwen-image-edit-plus-lora](https://replicate.com/qwen/qwen-image-edit-plus-lora) | Qwen Image Edit 2509 LoRA explorer, uses HuggingFace URLs to load any safetensor | 1632 |
| [anthropic/claude-3.5-sonnet](https://replicate.com/anthropic/claude-3.5-sonnet) | Anthropic's most intelligent language model to date, with a 200K token context window and image understanding (claude-3-5-sonnet-20241022) | 1607 |
| [luma/reframe-image](https://replicate.com/luma/reframe-image) | Change the aspect ratio of any photo using AI (not cropping) | 1547 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 1433 |
| [chenxwh/sdxl-flash](https://replicate.com/chenxwh/sdxl-flash) | Fast sdxl with higher quality | 1425 |
| [prunaai/flux-2-fast](https://replicate.com/prunaai/flux-2-fast) | A step-distilled version of flux 2 down to 1s. | 1403 |
| [lucataco/qwen3-embedding-8b](https://replicate.com/lucataco/qwen3-embedding-8b) | The Qwen3 Embedding model series is specifically designed for text embedding and ranking tasks | 1391 |
| [ardianfe/music-gen-fn-200e](https://replicate.com/ardianfe/music-gen-fn-200e) | Create music for your content | 1381 |
| [pixverse/lipsync](https://replicate.com/pixverse/lipsync) | Generate realistic lipsync animations from audio for high-quality synchronization | 1335 |
| [pikachupichu25/image-faceswap](https://replicate.com/pikachupichu25/image-faceswap) | null | 1331 |
| [prunaai/z-image-turbo-img2img](https://replicate.com/prunaai/z-image-turbo-img2img) | Image 2 Image version of z-image-turbo with lora support. | 1303 |
| [replicate/train-rvc-model](https://replicate.com/replicate/train-rvc-model) | Train your own custom RVC model | 1271 |
| [cuuupid/idm-vton](https://replicate.com/cuuupid/idm-vton) | Best-in-class clothing virtual try on in the wild (non-commercial use only) | 1265 |
| [stability-ai/stable-diffusion-3.5-large](https://replicate.com/stability-ai/stable-diffusion-3.5-large) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, thanks to Query-Key Normalization. | 1258 |
| [simbrams/segformer-b5-finetuned-ade-640-640](https://replicate.com/simbrams/segformer-b5-finetuned-ade-640-640) | Semantic Segmentation | 1258 |
| [prunaai/z-image](https://replicate.com/prunaai/z-image) | An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer | 1237 |
| [aisha-ai-official/miaomiao-harem-illustrious-v1](https://replicate.com/aisha-ai-official/miaomiao-harem-illustrious-v1) | null | 1229 |
| [deepseek-ai/deepseek-v3.1](https://replicate.com/deepseek-ai/deepseek-v3.1) | Latest hybrid thinking model from Deepseek | 1228 |
| [datalab-to/ocr](https://replicate.com/datalab-to/ocr) | Detect and transcribe text in images with accurate bounding boxes, layout analysis, reding order, and table recognition, in 90 languages | 1228 |
| [qwen/qwen3-235b-a22b-instruct-2507](https://replicate.com/qwen/qwen3-235b-a22b-instruct-2507) | Updated Qwen3 model for instruction following | 1207 |
| [adirik/interior-design](https://replicate.com/adirik/interior-design) | Realistic interior design with text and image inputs | 1197 |
| [ideogram-ai/ideogram-v2](https://replicate.com/ideogram-ai/ideogram-v2) | An excellent image model with state of the art inpainting, prompt comprehension and text rendering | 1194 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 1184 |
| [aisha-ai-official/wai-nsfw-illustrious-v11](https://replicate.com/aisha-ai-official/wai-nsfw-illustrious-v11) | null | 1171 |
| [luma/photon-flash](https://replicate.com/luma/photon-flash) | Accelerated variant of Photon prioritizing speed while maintaining quality | 1151 |
| [fofr/expression-editor](https://replicate.com/fofr/expression-editor) | Quickly edit the expression of a face | 1086 |
| [adirik/realvisxl-v3.0-turbo](https://replicate.com/adirik/realvisxl-v3.0-turbo) | Photorealism with RealVisXL V3.0 Turbo based on SDXL | 1074 |
| [kwaivgi/kling-v1.6-standard](https://replicate.com/kwaivgi/kling-v1.6-standard) | Generate 5s and 10s videos in 720p resolution at 30fps | 1054 |
| [tencent/hunyuanvideo-foley](https://replicate.com/tencent/hunyuanvideo-foley) | (Research & Non-commercial use only) Text-Video-to-Audio Synthesis: Generate realistic audio from video and text descriptions | 1048 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 1047 |
| [smoretalk/rembg-enhance](https://replicate.com/smoretalk/rembg-enhance) | A background removal model enhanced with better matting | 1014 |
| [wan-video/wan-2.2-t2v-fast](https://replicate.com/wan-video/wan-2.2-t2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B text-to-video | 999 |
| [openai/sora-2](https://replicate.com/openai/sora-2) | OpenAI's Flagship video generation with synced audio | 997 |
| [codeslake/ifan-defocus-deblur](https://replicate.com/codeslake/ifan-defocus-deblur) | Removes defocus blur in an image | 993 |
| [delta-lock/ponynai3](https://replicate.com/delta-lock/ponynai3) | Models fine-tuned from Pony-XL series. | 964 |
| [wan-video/wan-2.6-i2v](https://replicate.com/wan-video/wan-2.6-i2v) | Alibaba Wan 2.6 image to video generation model | 945 |
| [resemble-ai/chatterbox-turbo](https://replicate.com/resemble-ai/chatterbox-turbo) | The fastest open source TTS model without sacrificing quality. | 938 |
| [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) | Base version of Llama 3, an 8 billion parameter language model from Meta. | 906 |
| [google/veo-3.1](https://replicate.com/google/veo-3.1) | New and improved version of Veo 3, with higher-fidelity video, context-aware audio, reference image and last frame support | 901 |
| [reve/create](https://replicate.com/reve/create) | Image generation model from Reve | 900 |
| [sdxl-based/consistent-character](https://replicate.com/sdxl-based/consistent-character) | Create images of a given character in different poses | 879 |
| [anthropic/claude-3.5-haiku](https://replicate.com/anthropic/claude-3.5-haiku) | Anthropic's fastest, most cost-effective model, with a 200K token context window (claude-3-5-haiku-20241022) | 872 |
| [black-forest-labs/flux-schnell-lora](https://replicate.com/black-forest-labs/flux-schnell-lora) | The fastest image generation model tailored for fine-tuned use | 846 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 842 |
| [simbrams/ri](https://replicate.com/simbrams/ri) | Realistic Inpainting with ControlNET (M-LSD + SEG) | 837 |
| [openai/gpt-oss-20b](https://replicate.com/openai/gpt-oss-20b) | 20b open-weight language model from OpenAI | 835 |
| [ideogram-ai/ideogram-character](https://replicate.com/ideogram-ai/ideogram-character) | Generate consistent characters from a single reference image. Outputs can be in many styles. You can also use inpainting to add your character to an existing image. | 816 |
| [minimax/hailuo-02](https://replicate.com/minimax/hailuo-02) | Hailuo 2 is a text-to-video and image-to-video model that can make 6s or 10s videos at 768p (standard) or 1080p (pro). It excels at real world physics. | 809 |
| [google/imagen-3](https://replicate.com/google/imagen-3) | Google's highest quality text-to-image model, capable of generating images with detail, rich lighting and beauty | 798 |
| [black-forest-labs/flux-2-flex](https://replicate.com/black-forest-labs/flux-2-flex) | Max-quality image generation and editing with support for ten reference images | 788 |
| [fofr/style-transfer](https://replicate.com/fofr/style-transfer) | Transfer the style of one image to another | 783 |
| [charlesmccarthy/pony-sdxl](https://replicate.com/charlesmccarthy/pony-sdxl) | The best Pony-SDXL models! Current one is based on Pony Realism. | 781 |
| [lucataco/trim-video](https://replicate.com/lucataco/trim-video) | Simple tool to quickly trim a video or audio file | 764 |
| [ibm-granite/granite-4.0-h-small](https://replicate.com/ibm-granite/granite-4.0-h-small) | Granite-4.0-H-Small is a 32B parameter long-context instruct model finetuned from Granite-4.0-H-Small-Base using a combination of open source instruction datasets with permissive license and internally collected synthetic datasets. | 761 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 737 |
| [openai/gpt-5.2](https://replicate.com/openai/gpt-5.2) | The best model for coding and agentic tasks across industries | 734 |
| [bria/expand-image](https://replicate.com/bria/expand-image) | Bria Expand expands images beyond their borders in high quality. Resizing the image by generating new pixels to expand to the desired aspect ratio. Trained exclusively on licensed data for safe and risk-free commercial use | 733 |
| [wan-video/wan-2.2-s2v](https://replicate.com/wan-video/wan-2.2-s2v) | Generate a video from an audio clip and a reference image | 709 |
| [runwayml/gen4-aleph](https://replicate.com/runwayml/gen4-aleph) | A new way to edit, transform and generate video | 708 |
| [pixverse/pixverse-v5](https://replicate.com/pixverse/pixverse-v5) | Create 5s-8s videos with enhanced character movement, visual effects, and exclusive 1080p-8s support. Optimized for anime characters and complex actions | 706 |
| [lightricks/ltx-2-fast](https://replicate.com/lightricks/ltx-2-fast) | Ideal for rapid ideation and mobile workflows. Perfect for creators who need instant feedback, real-time previews, or high-throughput content. | 692 |
| [deepseek-ai/deepseek-r1](https://replicate.com/deepseek-ai/deepseek-r1) | A reasoning model trained with reinforcement learning, on par with OpenAI o1 | 687 |
| [minimax/video-01](https://replicate.com/minimax/video-01) | Generate 6s videos with prompts or images. (Also known as Hailuo). Use a subject reference to make a video with a character and the S2V-01 model. | 678 |
| [sepal/audiogen](https://replicate.com/sepal/audiogen) | Generate sounds from a text prompt | 677 |
| [stability-ai/stable-diffusion-3.5-large-turbo](https://replicate.com/stability-ai/stable-diffusion-3.5-large-turbo) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, with a focus on fewer inference steps | 669 |
| [resemble-ai/resemble-enhance](https://replicate.com/resemble-ai/resemble-enhance) | AI-driven audio enhancement for your audio files, powered by Resemble AI | 662 |
| [ideogram-ai/ideogram-v3-balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced) | Balance speed, quality and cost. Ideogram v3 creates images with stunning realism, creative designs, and consistent styles | 652 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 647 |
| [bytedance/flux-pulid](https://replicate.com/bytedance/flux-pulid) | ‚ö°Ô∏èFLUX PuLID: FLUX-dev based Pure and Lightning ID Customization via Contrastive Alignmentüé≠ | 646 |
| [sdxl-based/realvisxl-v3-multi-controlnet-lora](https://replicate.com/sdxl-based/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 635 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | Integral cog of doiwear.it | 634 |
| [melgor/stabledesign_interiordesign](https://replicate.com/melgor/stabledesign_interiordesign) | Transfer empty room into fabulous interior design | 630 |
| [stability-ai/stable-diffusion-3](https://replicate.com/stability-ai/stable-diffusion-3) | A text-to-image model with greatly improved performance in image quality, typography, complex prompt understanding, and resource-efficiency | 620 |
| [minimax/music-01](https://replicate.com/minimax/music-01) | Quickly generate up to 1 minute of music with lyrics and vocals in the style of a reference track | 615 |
| [lqhl/realesrgan](https://replicate.com/lqhl/realesrgan) | Image restoration and face enhancement | 615 |
| [cureau/force-align-wordstamps](https://replicate.com/cureau/force-align-wordstamps) | Takes audio (mp3) and a "source-of-truth" audio transcript (string) as input and returns precise timestamps. | 608 |
| [black-forest-labs/flux-redux-dev](https://replicate.com/black-forest-labs/flux-redux-dev) | Open-weight image variation model. Create new versions while preserving key elements of your original. | 607 |
| [arielreplicate/tres_iqa](https://replicate.com/arielreplicate/tres_iqa) | Assess the quality of an image | 604 |
| [sakemin/all-in-one-music-structure-analyzer](https://replicate.com/sakemin/all-in-one-music-structure-analyzer) | Cog implementation of mir-aidj(Taejun Kim)'s 'All-In-One Music Structure Analyzer' | 600 |
| [appmeloncreator/platmoji-beta](https://replicate.com/appmeloncreator/platmoji-beta) | This is an emoji generator fine tuned with Flux. (btw thx so much for the support on this) | 585 |
| [tencentarc/vqfr](https://replicate.com/tencentarc/vqfr) | Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder | 583 |
| [ideogram-ai/ideogram-v2-turbo](https://replicate.com/ideogram-ai/ideogram-v2-turbo) | A fast image model with state of the art inpainting, prompt comprehension and text rendering. | 577 |
| [meta/llama-4-scout-instruct](https://replicate.com/meta/llama-4-scout-instruct) | A 17 billion parameter model with 16 experts | 572 |
| [lucataco/wan-2.2-first-last-frame](https://replicate.com/lucataco/wan-2.2-first-last-frame) | Wan 2.2 First and Last Frame using 8-step inference w/ Lightning LoRA | 568 |
| [openai/gpt-5.1](https://replicate.com/openai/gpt-5.1) | The best model for coding and agentic tasks with configurable reasoning effort. | 562 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 559 |
| [shreejalmaharjan-27/tiktok-short-captions](https://replicate.com/shreejalmaharjan-27/tiktok-short-captions) | Generate Tiktok-Style Captions powered by Whisper (GPU) | 557 |
| [fpsorg/emoji](https://replicate.com/fpsorg/emoji) | Make Emoji with AI. | 554 |
| [bria/image-3.2](https://replicate.com/bria/image-3.2) | Commercial-ready, trained entirely on licensed data, text-to-image model. With only 4B parameters provides exceptional aesthetics and text rendering. Evaluated to be on par to other leading models in the market | 547 |
| [meronym/speaker-diarization](https://replicate.com/meronym/speaker-diarization) | Segments an audio recording based on who is speaking | 541 |
| [topazlabs/video-upscale](https://replicate.com/topazlabs/video-upscale) | Video Upscaling from Topaz Labs | 524 |
| [flux-kontext-apps/change-haircut](https://replicate.com/flux-kontext-apps/change-haircut) | Quickly change someone's hair style and hair color, powered by FLUX.1 Kontext [pro] | 516 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 516 |
| [xinntao/esrgan](https://replicate.com/xinntao/esrgan) | Image 4x super-resolution | 511 |
| [pnyompen/sdxl-controlnet-lora-small](https://replicate.com/pnyompen/sdxl-controlnet-lora-small) | SDXL Canny controlnet with LoRA support. | 499 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 487 |
| [vectradmin/sdxl-v-transparent](https://replicate.com/vectradmin/sdxl-v-transparent) | null | 485 |
| [shreejalmaharjan-27/website-screenshot](https://replicate.com/shreejalmaharjan-27/website-screenshot) | Capture a website screenshot | 484 |
| [recraft-ai/recraft-v3-svg](https://replicate.com/recraft-ai/recraft-v3-svg) | Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles. | 480 |
| [minimax/speech-2.6-hd](https://replicate.com/minimax/speech-2.6-hd) | MiniMax Speech 2.6 HD delivers studio-quality multilingual text-to-audio on Replicate with nuanced prosody, subtitle export, and premium voices | 478 |
| [ideogram-ai/ideogram-v3-quality](https://replicate.com/ideogram-ai/ideogram-v3-quality) | The highest quality Ideogram v3 model. v3 creates images with stunning realism, creative designs, and consistent styles | 477 |
| [devgmstudios/pony-realism-v23](https://replicate.com/devgmstudios/pony-realism-v23) | Latest Pony Realism Model. Try it with WEIGHTS on creatorframes.com | 477 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 477 |
| [fottoai/remove-bg-2](https://replicate.com/fottoai/remove-bg-2) | Remove image background with custom model to better result. | 476 |
| [zf-kbot/photo-to-anime](https://replicate.com/zf-kbot/photo-to-anime) | Convert images to anime style | 476 |
| [lucataco/ltx-video-0.9.8-distilled](https://replicate.com/lucataco/ltx-video-0.9.8-distilled) | Generate native long-form video, with controllability | 470 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | üòä Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 466 |
| [nvidia/sana-sprint-1.6b](https://replicate.com/nvidia/sana-sprint-1.6b) | SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation | 463 |
| [idan054/better-video-merge](https://replicate.com/idan054/better-video-merge) | Fix Diffrent Sizes for each clip. Fork of lucataco/cog-video-merge.git | 460 |
| [declare-lab/tangoflux](https://replicate.com/declare-lab/tangoflux) | Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization | 460 |
| [lucataco/flux-dev-lora](https://replicate.com/lucataco/flux-dev-lora) | FLUX.1-Dev LoRA Explorer (DEPRECATED Please use: black-forest-labs/flux-dev-lora) | 456 |
| [ostris/flux-dev-lora-trainer](https://replicate.com/ostris/flux-dev-lora-trainer) | Fine-tune FLUX.1-dev using ai-toolkit | 449 |
| [google/imagen-3-fast](https://replicate.com/google/imagen-3-fast) | A faster and cheaper Imagen 3 model, for when price or speed are more important than final image quality | 440 |
| [ibm-granite/granite-vision-3.3-2b](https://replicate.com/ibm-granite/granite-vision-3.3-2b) | Granite-vision-3.3-2b is a compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. | 440 |
| [fofr/sdxl-fresh-ink](https://replicate.com/fofr/sdxl-fresh-ink) | SDXL fine-tuned on photos of freshly inked tattoos | 436 |
| [lucataco/ace-step](https://replicate.com/lucataco/ace-step) | A Step Towards Music Generation Foundation Model text2music | 425 |
| [prunaai/z-image-turbo-lora](https://replicate.com/prunaai/z-image-turbo-lora) | Lora version of Z-Image Turbo, which is a super fast text-to-image model of 6B parameters developed by Tongyi-MAI. | 417 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 414 |
| [meta/sam-2](https://replicate.com/meta/sam-2) | SAM 2: Segment Anything v2 (for Images) | 407 |
| [black-forest-labs/flux-canny-dev](https://replicate.com/black-forest-labs/flux-canny-dev) | Open-weight edge-guided image generation. Control structure and composition using Canny edge detection. | 403 |
| [pixverse/pixverse-v4.5](https://replicate.com/pixverse/pixverse-v4.5) | Quickly make 5s or 8s videos at 540p, 720p or 1080p. It has enhanced motion, prompt coherence and handles complex actions well. | 392 |
| [flux-kontext-apps/cartoonify](https://replicate.com/flux-kontext-apps/cartoonify) | Turn your image into a cartoon with FLUX.1 Kontext [pro] | 392 |
| [astelvida/genmoji-gen](https://replicate.com/astelvida/genmoji-gen) | null | 392 |
| [yorickvp/llava-v1.6-mistral-7b](https://replicate.com/yorickvp/llava-v1.6-mistral-7b) | LLaVA v1.6: Large Language and Vision Assistant (Mistral-7B) | 390 |
| [lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) | FLUX.1-Dev Multi LoRA Explorer | 389 |
| [codeplugtech/background_remover](https://replicate.com/codeplugtech/background_remover) | Remove background from image | 389 |
| [black-forest-labs/flux-2-klein-9b-base](https://replicate.com/black-forest-labs/flux-2-klein-9b-base) | Un-distilled version of FLUX.2 [klein]. A foundation model for maximum flexibility and control | 377 |
| [lucataco/flux-content-filter](https://replicate.com/lucataco/flux-content-filter) | Flux Content Filter - Check for public figures and copyright concerns | 377 |
| [openai/gpt-5-structured](https://replicate.com/openai/gpt-5-structured) | GPT-5 with support for structured outputs, web search and custom tools | 374 |
| [resemble-ai/chatterbox](https://replicate.com/resemble-ai/chatterbox) | Generate expressive, natural speech. Features unique emotion control, instant voice cloning from short audio, and built-in watermarking. | 373 |
| [black-forest-labs/flux-kontext-dev-lora](https://replicate.com/black-forest-labs/flux-kontext-dev-lora) | FLUX.1 Kontext[dev] image editing model for running lora finetunes | 361 |
| [kwaivgi/kling-v1.6-pro](https://replicate.com/kwaivgi/kling-v1.6-pro) | Generate 5s and 10s videos in 1080p resolution | 360 |
| [fofr/color-matcher](https://replicate.com/fofr/color-matcher) | Color match and white balance fixes for images | 360 |
| [aisha-ai-official/prefect-pony-xl-v5](https://replicate.com/aisha-ai-official/prefect-pony-xl-v5) | null | 360 |
| [flux-kontext-apps/multi-image-list](https://replicate.com/flux-kontext-apps/multi-image-list) | FLUX Kontext max with list input for multiple images | 359 |
| [black-forest-labs/flux-canny-pro](https://replicate.com/black-forest-labs/flux-canny-pro) | Professional edge-guided image generation. Control structure and composition using Canny edge detection | 358 |
| [idea-research/ram-grounded-sam](https://replicate.com/idea-research/ram-grounded-sam) | A Strong Image Tagging Model with Segment Anything | 358 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 357 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 352 |
| [sdxl-based/realvisxl-v3](https://replicate.com/sdxl-based/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 350 |
| [asiryan/realism-xl](https://replicate.com/asiryan/realism-xl) | Realism XL Model (Text2Img, Img2Img and Inpainting) | 348 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 348 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 340 |
| [cjwbw/videocrafter](https://replicate.com/cjwbw/videocrafter) | VideoCrafter2: Text-to-Video and Image-to-Video Generation and Editing | 337 |
| [wan-video/wan-2.5-t2v-fast](https://replicate.com/wan-video/wan-2.5-t2v-fast) | Wan 2.5 text-to-video, optimized for speed | 330 |
| [gewoonjaap/flux-emoji](https://replicate.com/gewoonjaap/flux-emoji) | Easily create emojis using Flux Dev | 330 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 330 |
| [fictions-ai/autocaption](https://replicate.com/fictions-ai/autocaption) | Automatically add captions to a video | 329 |
| [leonardoai/lucid-origin](https://replicate.com/leonardoai/lucid-origin) | Artistic and high-quality visuals with improved prompt adherence, diversity, and definition | 321 |
| [zsxkib/tool-merge-images](https://replicate.com/zsxkib/tool-merge-images) | Merge multiple images into clean horizontal or vertical strips with precise alignment and sizing controls. | 318 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 318 |
| [bytedance/latentsync](https://replicate.com/bytedance/latentsync) | LatentSync: generate high-quality lip sync animations | 317 |
| [google/veo-3-fast](https://replicate.com/google/veo-3-fast) | A faster and cheaper version of Google‚Äôs Veo 3 video model, with audio | 315 |
| [flux-kontext-apps/multi-image-kontext-pro](https://replicate.com/flux-kontext-apps/multi-image-kontext-pro) | An experimental model with FLUX Kontext Pro that can combine two input images | 315 |
| [okaris/omni-zero](https://replicate.com/okaris/omni-zero) | Omni-Zero: A diffusion pipeline for zero-shot stylized portrait creation. | 307 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 305 |
| [black-forest-labs/flux-depth-pro](https://replicate.com/black-forest-labs/flux-depth-pro) | Professional depth-aware image generation. Edit images while preserving spatial relationships. | 298 |
| [elevenlabs/v3](https://replicate.com/elevenlabs/v3) | The most expressive Text to Speech model | 295 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 294 |
| [replicate/fast-flux-trainer](https://replicate.com/replicate/fast-flux-trainer) | Train subjects or styles faster than ever | 293 |
| [minimax/music-1.5](https://replicate.com/minimax/music-1.5) | Music-1.5: Full-length songs (up to 4 mins) with natural vocals & rich instrumentation | 285 |
| [pseudoram/rvc-v2](https://replicate.com/pseudoram/rvc-v2) | Speech to speech with any RVC v2 trained AI voice | 279 |
| [ibm-granite/granite-3.3-8b-instruct](https://replicate.com/ibm-granite/granite-3.3-8b-instruct) | Granite-3.3-8B-Instruct is a 8-billion parameter 128K context length language model fine-tuned for improved reasoning and instruction-following capabilities. | 278 |
| [colinmcdonnell22/ghiblify-3](https://replicate.com/colinmcdonnell22/ghiblify-3) | null | 278 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 264 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 263 |
| [anthropic/claude-4.5-haiku](https://replicate.com/anthropic/claude-4.5-haiku) | Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed | 261 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 261 |
| [recraft-ai/recraft-20b-svg](https://replicate.com/recraft-ai/recraft-20b-svg) | Affordable and fast vector images | 258 |
| [datalab-to/marker](https://replicate.com/datalab-to/marker) | Convert PDF to markdown + JSON quickly with high accuracy | 252 |
| [fermatresearch/bisenet-faces](https://replicate.com/fermatresearch/bisenet-faces) | A Cog implementation of BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation [Face Parsing] (https://github.com/yakhyo/face-parsing). | 250 |
| [runwayml/gen4-image-turbo](https://replicate.com/runwayml/gen4-image-turbo) | Gen-4 Image Turbo is cheaper and 2.5x faster than Gen-4 Image. An image model with references, use up to 3 reference images to create the exact image you need. Capture every angle. | 247 |
| [openai/sora-2-pro](https://replicate.com/openai/sora-2-pro) | OpenAI's Most advanced synced-audio video generation | 246 |
| [ahmdyassr/detect-crop-face](https://replicate.com/ahmdyassr/detect-crop-face) | A simple model to detect and crop face found in image, made for https://outfit.fm | 246 |
| [fermatresearch/sdxl-controlnet-lora](https://replicate.com/fermatresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 244 |
| [bria/generate-background](https://replicate.com/bria/generate-background) | Bria Background Generation allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use | 236 |
| [cjwbw/sadtalker](https://replicate.com/cjwbw/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 232 |
| [minimax/hailuo-2.3](https://replicate.com/minimax/hailuo-2.3) | A high-fidelity video generation model optimized for realistic human motion, cinematic VFX, expressive characters, and strong prompt and style adherence across both text-to-video and image-to-video workflows | 229 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 227 |
| [zsxkib/dia](https://replicate.com/zsxkib/dia) | Dia 1.6B by Nari Labs, Generates realistic dialogue audio from text, including non-verbal cues and voice cloning | 225 |
| [nvidia/sana](https://replicate.com/nvidia/sana) | A fast image model with wide artistic range and resolutions up to 4096x4096 | 221 |
| [lightricks/ltx-2-distilled](https://replicate.com/lightricks/ltx-2-distilled) | The first open source audio-video model | 219 |
| [kwaivgi/kling-lip-sync](https://replicate.com/kwaivgi/kling-lip-sync) | Add lip-sync to any video with an audio file or text | 219 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 217 |
| [pixverse/pixverse-v5.6](https://replicate.com/pixverse/pixverse-v5.6) | Latest video model from Pixverse with astonishing physics | 213 |
| [chenxwh/depth-anything-v2](https://replicate.com/chenxwh/depth-anything-v2) | Depth estimation with faster inference speed, fewer parameters, and higher depth accuracy. | 212 |
| [ndreca/hunyuan3d-2](https://replicate.com/ndreca/hunyuan3d-2) | [Turbo Mode] Scaling Diffusion Models for High Resolution Textured 3D Assets Generation | 209 |
| [littlemonsterzhang/wai90_sdxl](https://replicate.com/littlemonsterzhang/wai90_sdxl) | WAI-NSFW-illustrious-SDXL  v.90 | 207 |
| [dashed/whisperx-subtitles-replicate](https://replicate.com/dashed/whisperx-subtitles-replicate) | Generates subtitles from audio using whisperX (faster-whisper-large-v3) | 206 |
| [stability-ai/stable-diffusion-3.5-medium](https://replicate.com/stability-ai/stable-diffusion-3.5-medium) | 2.5 billion parameter image model with improved MMDiT-X architecture | 204 |
| [logerzhu/ad-inpaint](https://replicate.com/logerzhu/ad-inpaint) | Product advertising image generator | 198 |
| [minimax/hailuo-2.3-fast](https://replicate.com/minimax/hailuo-2.3-fast) | A lower-latency image-to-video version of Hailuo 2.3 that preserves core motion quality, visual consistency, and stylization performance while enabling faster iteration cycles. | 197 |
| [aisha-ai-official/realism-il-v3](https://replicate.com/aisha-ai-official/realism-il-v3) | null | 197 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 196 |
| [openai/o4-mini](https://replicate.com/openai/o4-mini) | OpenAI's fast, lightweight reasoning model | 194 |
| [tencent/hunyuan-image-3](https://replicate.com/tencent/hunyuan-image-3) | A powerful native multimodal model for image generation (PrunaAI squeezed) | 194 |
| [lucataco/nsfw_video_detection](https://replicate.com/lucataco/nsfw_video_detection) | FalconAIs NSFW detection model, extended for videos | 190 |
| [wan-video/wan-2.2-animate-replace](https://replicate.com/wan-video/wan-2.2-animate-replace) | Use Wan 2.2 Animate to replace a character in a video scene | 189 |
| [black-forest-labs/flux-2-klein-4b-base](https://replicate.com/black-forest-labs/flux-2-klein-4b-base) | Un-distilled version of FLUX.2 [klein]. Optimized for fine-tuning, customization, and post-training workflows | 188 |
| [aaronaftab/mirage-ghibli](https://replicate.com/aaronaftab/mirage-ghibli) | Ghiblify any image, 10x cheaper/faster than GPT 4o | 188 |
| [tmappdev/change_video_bg](https://replicate.com/tmappdev/change_video_bg) | Change or Replace Video Background with any Image | 188 |
| [stability-ai/stable-audio-2.5](https://replicate.com/stability-ai/stable-audio-2.5) | Generate high-quality music and sound from text prompts | 184 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 183 |
| [prompthero/openjourney](https://replicate.com/prompthero/openjourney) | Stable Diffusion fine tuned on Midjourney v4 images. | 183 |
| [ardianfe/demucs-prod](https://replicate.com/ardianfe/demucs-prod) | sound separation with demucs | 179 |
| [aisha-ai-official/likereality-pony-v1](https://replicate.com/aisha-ai-official/likereality-pony-v1) | null | 175 |
| [recraft-ai/recraft-20b](https://replicate.com/recraft-ai/recraft-20b) | Affordable and fast images | 173 |
| [meta/llama-guard-4-12b](https://replicate.com/meta/llama-guard-4-12b) | null | 172 |
| [uglyrobot/sora2-watermark-remover](https://replicate.com/uglyrobot/sora2-watermark-remover) | Removes the watermark from Sora 2 videos using a trained model and IOpaint | 170 |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | Fast FLUX DEV -> Flux Controlnet Canny, Controlnet Depth , Controlnet Line Art, Controlnet Upscaler - You can use just one controlnet or All - LORAs: HyperFlex LoRA , Add Details LoRA , Realism LoRA | 167 |
| [aisha-ai-official/pony-realism-v2.2](https://replicate.com/aisha-ai-official/pony-realism-v2.2) | null | 167 |
| [runwayml/gen4-turbo](https://replicate.com/runwayml/gen4-turbo) | Generate 5s and 10s 720p videos fast | 165 |
| [dmtanner/parakeet-tdt-0.6b-v3](https://replicate.com/dmtanner/parakeet-tdt-0.6b-v3) | ASR model, created by Nvidia, with word-level timestamps available.  Supports .wav inputs, or m3u8 urls, with a start and end time (to only process a section of the m3u8). | 165 |
| [xlabs-ai/flux-dev-controlnet](https://replicate.com/xlabs-ai/flux-dev-controlnet) | XLabs v3 canny, depth and soft edge controlnets for Flux.1 Dev | 165 |
| [havocy28/ai-detector](https://replicate.com/havocy28/ai-detector) | Detect AI Generated Text with Fast-DetectGPT | 165 |
| [lightweight-ai/model1](https://replicate.com/lightweight-ai/model1) | flux_schnell model img2img inference | 163 |
| [arielreplicate/robust_video_matting](https://replicate.com/arielreplicate/robust_video_matting) | extract foreground of a video | 162 |
| [miike-ai/flux-sprites](https://replicate.com/miike-ai/flux-sprites) | Sprite sheets made easy.  Give it a whirl! | 157 |
| [abiruyt/text-extract-ocr](https://replicate.com/abiruyt/text-extract-ocr) | A simple OCR Model that can easily extract text from an image. | 157 |
| [flux-kontext-apps/face-to-many-kontext](https://replicate.com/flux-kontext-apps/face-to-many-kontext) | Become a character, in style | 155 |
| [usamaehsan/qwen-image-edit-fastest-2](https://replicate.com/usamaehsan/qwen-image-edit-fastest-2) | 400+ images in 1$ 1024 resolution// 2s /img on L40S GPU, check description and examples | 154 |
| [jd7h/propainter](https://replicate.com/jd7h/propainter) | Object removal, video completion and video outpainting | 151 |
| [google/lyria-2](https://replicate.com/google/lyria-2) | Lyria 2 is a music generation model that produces 48kHz stereo audio through text-based prompts | 150 |
| [lightricks/ltx-video-0.9.7-distilled](https://replicate.com/lightricks/ltx-video-0.9.7-distilled) | Faster slight quality reduction compared to LTX-Video 13b | 146 |
| [resemble-ai/chatterbox-multilingual](https://replicate.com/resemble-ai/chatterbox-multilingual) | Generate expressive, natural speech in 23 languages. Features instant voice cloning from short audio, emotion control, and seamless cross-language voice transfer. | 145 |
| [wavespeedai/wan-2.1-i2v-480p](https://replicate.com/wavespeedai/wan-2.1-i2v-480p) | Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation. | 143 |
| [flux-kontext-apps/text-removal](https://replicate.com/flux-kontext-apps/text-removal) | Remove all text from an image with FLUX.1 Kontext | 143 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 143 |
| [rhelsing/basic-pitch](https://replicate.com/rhelsing/basic-pitch) | Spotify's Basic Pitch Model | 142 |
| [google/veo-3](https://replicate.com/google/veo-3) | Sound on: Google‚Äôs flagship Veo 3 text to video model, with audio | 140 |
| [perceptron-ai-inc/isaac-0.1](https://replicate.com/perceptron-ai-inc/isaac-0.1) | an open-source, 2B-parameter model built for real-world applications | 139 |
| [minimax/voice-cloning](https://replicate.com/minimax/voice-cloning) | Clone voices to use with Minimax's speech-02-hd and speech-02-turbo | 139 |
| [ultralytics/yolov8s-worldv2](https://replicate.com/ultralytics/yolov8s-worldv2) | Ultralytics YOLOv8s worldv2 Real-Time Open-Vocabulary Object Detection model with 12.7M parameters. Achieves 37.7 mAP50-95 on COCO dataset. Optimized for real-time inference | 139 |
| [lucataco/video-merge](https://replicate.com/lucataco/video-merge) | Simple tool to merge together separate video snippets | 139 |
| [black-forest-labs/flux-redux-schnell](https://replicate.com/black-forest-labs/flux-redux-schnell) | Fast, efficient image variation model for rapid iteration and experimentation. | 138 |
| [okaris/live-portrait](https://replicate.com/okaris/live-portrait) | null | 138 |
| [wan-video/wan-2.5-i2v-fast](https://replicate.com/wan-video/wan-2.5-i2v-fast) | Wan 2.5 image-to-video, optimized for speed | 135 |
| [sync/lipsync-2-pro](https://replicate.com/sync/lipsync-2-pro) | Studio-grade lipsync in minutes, not weeks | 133 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 133 |
| [xlabs-ai/flux-dev-realism](https://replicate.com/xlabs-ai/flux-dev-realism) | FLUX.1-dev with XLabs-AI‚Äôs realism lora | 132 |
| [leonardoai/phoenix-1.0](https://replicate.com/leonardoai/phoenix-1.0) | Leonardo AI‚Äôs first foundational model produces images up to 5 megapixels (fast, quality and ultra modes) | 129 |
| [fofr/sdxl-multi-controlnet-lora](https://replicate.com/fofr/sdxl-multi-controlnet-lora) | Multi-controlnet, lora loading, img2img, inpainting | 129 |
| [openai/dall-e-3](https://replicate.com/openai/dall-e-3) | An AI system that can create realistic images and art from a description in natural language. | 127 |
| [runwayml/upscale-v1](https://replicate.com/runwayml/upscale-v1) | Upscale videos by 4x, up to a maximum of 4k | 127 |
| [arielreplicate/deoldify_image](https://replicate.com/arielreplicate/deoldify_image) | Add colours to old images | 127 |
| [fofr/toolkit](https://replicate.com/fofr/toolkit) | Video toolkit ‚Äì convert, make GIFs, extract audio | 125 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 123 |
| [reve/edit](https://replicate.com/reve/edit) | Image editing model from Reve | 120 |
| [lucataco/hermes-2-pro-llama-3-8b](https://replicate.com/lucataco/hermes-2-pro-llama-3-8b) | Hermes 2 Pro is an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house | 120 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 120 |
| [meta/cutler](https://replicate.com/meta/cutler) | Cut and Learn for unsupervised object detection and instance segmentation | 120 |
| [bytedance/dreamina-3.1](https://replicate.com/bytedance/dreamina-3.1) | 4MP text-to-image generation with enhanced cinematic-quality image generation with precise style control, improved text rendering, and commercial design optimization. | 115 |
| [flux-kontext-apps/professional-headshot](https://replicate.com/flux-kontext-apps/professional-headshot) | Create a professional headshot photo from any single image | 115 |
| [flux-kontext-apps/multi-image-kontext-max](https://replicate.com/flux-kontext-apps/multi-image-kontext-max) | An experimental FLUX Kontext model that can combine two input images | 114 |
| [bytedance/bagel](https://replicate.com/bytedance/bagel) | ü•ØByteDance Seed's Bagel Unified multimodal AI that generates images, edits images, and understands images in one 7B parameter modelü•Ø | 110 |
| [lucataco/animate-diff](https://replicate.com/lucataco/animate-diff) | Animate Your Personalized Text-to-Image Diffusion Models | 110 |
| [reve/remix](https://replicate.com/reve/remix) | Image generation model from Reve which handles multiple input reference images | 109 |
| [bytedance/sa2va-8b-image](https://replicate.com/bytedance/sa2va-8b-image) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 107 |
| [ideogram-ai/ideogram-v2a](https://replicate.com/ideogram-ai/ideogram-v2a) | Like Ideogram v2, but faster and cheaper | 105 |
| [fofr/latent-consistency-model](https://replicate.com/fofr/latent-consistency-model) | Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet | 104 |
| [luma/reframe-video](https://replicate.com/luma/reframe-video) | Change the aspect ratio of any video up to 30 seconds long, outputs will be 720p | 101 |
