# Model Stats
## New Models
- https://replicate.com/marfnxd/sks_verse_style

## Removed Models
- https://replicate.com/black-forest-labs/flux-krea-dev

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [marfnxd/sks_verse_style](https://replicate.com/marfnxd/sks_verse_style) | null | 746 | 746 | 100.00% |
| [hanglics/dse-qwen2-2b-mrl-v1](https://replicate.com/hanglics/dse-qwen2-2b-mrl-v1) | The screenshot retriever model base on DSE. | 1891 | 1914 | 98.80% |
| [zsxkib/kimi-vl-a3b-thinking](https://replicate.com/zsxkib/kimi-vl-a3b-thinking) | Kimi-VL-A3B-Thinking is a multi-modal LLM that can understand text and images, and generate text with thinking processes | 375 | 524 | 71.56% |
| [microsoft/vibevoice](https://replicate.com/microsoft/vibevoice) | Microsoft's VibeVoice text-to-speech model that can generate long-form speech from text with sample voices. | 28 | 60 | 46.67% |
| [humbleworth/price-predict-v1](https://replicate.com/humbleworth/price-predict-v1) | Predicts the value of a domain name. | 6 | 15 | 40.00% |
| [chenxwh/cogvlm2](https://replicate.com/chenxwh/cogvlm2) | CogVLM2: Visual Language Models for Image and Video Understanding | 388 | 1050 | 36.95% |
| [aakashapoorv/synthwave](https://replicate.com/aakashapoorv/synthwave) | neon-soaked, synth-powered aesthetics of 1980s retro-futurism. | 11 | 30 | 36.67% |
| [zsxkib/wd-image-tagger](https://replicate.com/zsxkib/wd-image-tagger) | Image tagger fine-tuned on WaifuDiffusion w/ (SwinV2, SwinV2, ConvNext, and ViT) | 1935 | 6221 | 31.10% |
| [digitalmagicmom/alyssmodel](https://replicate.com/digitalmagicmom/alyssmodel) | null | 5 | 17 | 29.41% |
| [zhooshify/benjieaitwin](https://replicate.com/zhooshify/benjieaitwin) | null | 6 | 22 | 27.27% |
| [deepseek-ai/deepseek-v3.1](https://replicate.com/deepseek-ai/deepseek-v3.1) | Latest hybrid thinking model from Deepseek | 317 | 1281 | 24.75% |
| [marcelarocerie/criador-de-celas](https://replicate.com/marcelarocerie/criador-de-celas) | Generates photorealistic images of mah2025 while preserving identity and style. | 20 | 83 | 24.10% |
| [google/nano-banana](https://replicate.com/google/nano-banana) | Google's latest image editing model in Gemini 2.5 | 299803 | 1258406 | 23.82% |
| [lucataco/stable-avatar](https://replicate.com/lucataco/stable-avatar) | End-to-end video diffusion transformer, which synthesizes infinite-length high-quality audio-driven avatar videos without any post-processing | 30 | 151 | 19.87% |
| [recraft-ai/recraft-remove-background](https://replicate.com/recraft-ai/recraft-remove-background) | Automated background removal for images. Tuned for AI-generated content, product photos, portraits, and design workflows | 210 | 1090 | 19.27% |
| [theblindeman/twha](https://replicate.com/theblindeman/twha) | null | 7 | 39 | 17.95% |
| [recraft-ai/recraft-vectorize](https://replicate.com/recraft-ai/recraft-vectorize) | Convert raster images to high-quality SVG format with precision and clean vector paths, perfect for logos, icons, and scalable graphics. | 282 | 1794 | 15.72% |
| [google/gemini-2.5-flash-image](https://replicate.com/google/gemini-2.5-flash-image) | Google's latest image generation model in Gemini 2.5 | 2032 | 13121 | 15.49% |
| [ddvinh1/video-faceswap-gpu](https://replicate.com/ddvinh1/video-faceswap-gpu) | null | 3 | 20 | 15.00% |
| [paragekbote/smollm3-3b-smashed](https://replicate.com/paragekbote/smollm3-3b-smashed) | SmolLM3-3B with Pruna for lightning-fast, memory-efficient AI inference. | 1 | 7 | 14.29% |
| [pixverse/pixverse-v5](https://replicate.com/pixverse/pixverse-v5) | Create 5s-8s videos with enhanced character movement, visual effects, and exclusive 1080p-8s support. Optimized for anime characters and complex actions | 785 | 5821 | 13.49% |
| [justmalhar/flux-thumbnails](https://replicate.com/justmalhar/flux-thumbnails) | Generate 16:9 Thumbnails. Use prefix - `Thumbnail in the style of TOK` | 705 | 5266 | 13.39% |
| [govirtualuk/pegasus](https://replicate.com/govirtualuk/pegasus) | Creates fully 360 panoramas for VR and backdrop media | 16 | 137 | 11.68% |
| [alphanumericuser/kokoro-82m](https://replicate.com/alphanumericuser/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 56593 | 489653 | 11.56% |
| [jhonp4/jhonpiedrahita_ai01](https://replicate.com/jhonp4/jhonpiedrahita_ai01) | null | 11 | 109 | 10.09% |
| [paragekbote/flux-fast-lora-hotswap](https://replicate.com/paragekbote/flux-fast-lora-hotswap) | A blazing-fast inference setup for Flux.1-dev with dynamic LoRA hotswapping. | 3 | 30 | 10.00% |
| [bfirsh/concatenate-videos](https://replicate.com/bfirsh/concatenate-videos) | Stitches videos together | 40 | 417 | 9.59% |
| [marivfreire/tatitayra](https://replicate.com/marivfreire/tatitayra) | null | 2 | 21 | 9.52% |
| [onemadgeek/video-to-frames-extractor](https://replicate.com/onemadgeek/video-to-frames-extractor) | Extract frames from videos at custom frame rates | 2 | 21 | 9.52% |
| [runwayml/upscale-v1](https://replicate.com/runwayml/upscale-v1) | Upscale videos by 4x, up to a maximum of 4k | 249 | 2704 | 9.21% |
| [deepseek-ai/deepseek-vl-7b-base](https://replicate.com/deepseek-ai/deepseek-vl-7b-base) | DeepSeek-VL: An open-source Vision-Language Model designed for real-world vision and language understanding applications | 385 | 4193 | 9.18% |
| [krisdoan/gb2045g](https://replicate.com/krisdoan/gb2045g) | null | 16 | 179 | 8.94% |
| [openai/gpt-5-nano](https://replicate.com/openai/gpt-5-nano) | Fastest, most cost-effective GPT-5 model from OpenAI | 1661 | 18612 | 8.92% |
| [bytedance/omni-human](https://replicate.com/bytedance/omni-human) | Turns your audio/video/images into professional-quality animated videos | 753 | 8483 | 8.88% |
| [ddvinh1/face-swap-gpu](https://replicate.com/ddvinh1/face-swap-gpu) | null | 13 | 164 | 7.93% |
| [swk23/obiwan-live-three](https://replicate.com/swk23/obiwan-live-three) | null | 1 | 13 | 7.69% |
| [sljeff/dots.ocr](https://replicate.com/sljeff/dots.ocr) | https://github.com/sljeff/dots-ocr-client | 169 | 2269 | 7.45% |
| [openai/gpt-5-mini](https://replicate.com/openai/gpt-5-mini) | Faster version of OpenAI's flagship GPT-5 model | 1799 | 24376 | 7.38% |
| [google/upscaler](https://replicate.com/google/upscaler) | Upscale images 2x or 4x times | 1684 | 22901 | 7.35% |
| [remodela-ai/virtual_staging_i](https://replicate.com/remodela-ai/virtual_staging_i) | null | 5 | 68 | 7.35% |
| [bytedance/sa2va-8b-image](https://replicate.com/bytedance/sa2va-8b-image) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 435 | 5974 | 7.28% |
| [lucataco/minicpm-v-4](https://replicate.com/lucataco/minicpm-v-4) | MiniCPM-V 4.0 has strong image and video understanding performance | 6 | 85 | 7.06% |
| [fofr/kontext-old-and-damaged](https://replicate.com/fofr/kontext-old-and-damaged) | Use this kontext fine-tune to turn any photo into an old and damaged photo | 39 | 569 | 6.85% |
| [ddvinh1/tool-faceswap](https://replicate.com/ddvinh1/tool-faceswap) | null | 4 | 60 | 6.67% |
| [dmtanner/parakeet-tdt-0.6b-v3](https://replicate.com/dmtanner/parakeet-tdt-0.6b-v3) | ASR model, created by Nvidia, with word-level timestamps available.  Supports .wav inputs, or m3u8 urls, with a start and end time (to only process a section of the m3u8). | 2 | 30 | 6.67% |
| [luma/reframe-image](https://replicate.com/luma/reframe-image) | Change the aspect ratio of any photo using AI (not cropping) | 900 | 13995 | 6.43% |
| [bytedance/sa2va-26b-image](https://replicate.com/bytedance/sa2va-26b-image) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 331 | 5167 | 6.41% |
| [krunalmangroliya/lbm](https://replicate.com/krunalmangroliya/lbm) | LBM: Latent Bridge Matching for Fast Image-to-Image Translation | 4 | 64 | 6.25% |
| [remodela-ai/virtual_staging_ii](https://replicate.com/remodela-ai/virtual_staging_ii) | null | 1 | 16 | 6.25% |
| [fishwowater/ram-grounded-sam-maskfixed](https://replicate.com/fishwowater/ram-grounded-sam-maskfixed) | A fork of https://replicate.com/idea-research/ram-grounded-sam that outputs usable(grayscale) mask values | 2 | 33 | 6.06% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [black-forest-labs/flux-schnell](https://replicate.com/black-forest-labs/flux-schnell) | The fastest image generation model tailored for local development and personal use | 1244544 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 426913 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 388254 |
| [google/nano-banana](https://replicate.com/google/nano-banana) | Google's latest image editing model in Gemini 2.5 | 299803 |
| [black-forest-labs/flux-kontext-pro](https://replicate.com/black-forest-labs/flux-kontext-pro) | A state-of-the-art text-based image editing model that delivers high-quality outputs with excellent prompt following and consistent results for transforming images through natural language | 242438 |
| [black-forest-labs/flux-1.1-pro](https://replicate.com/black-forest-labs/flux-1.1-pro) | Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity. | 229352 |
| [jaaari/kokoro-82m](https://replicate.com/jaaari/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 183217 |
| [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct) | An 8 billion parameter language model from Meta, fine tuned for chat completions | 182504 |
| [prunaai/flux.1-dev](https://replicate.com/prunaai/flux.1-dev) | This is the fastest Flux Dev endpoint in the world, contact us for more at pruna.ai | 176108 |
| [turian/insanely-fast-whisper-with-video](https://replicate.com/turian/insanely-fast-whisper-with-video) | whisper-large-v3, incredibly fast, with video transcription | 167838 |
| [minimax/speech-02-turbo](https://replicate.com/minimax/speech-02-turbo) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Designed for real-time applications with low latency | 93401 |
| [adirik/grounding-dino](https://replicate.com/adirik/grounding-dino) | Detect everything with language! | 91692 |
| [black-forest-labs/flux-dev](https://replicate.com/black-forest-labs/flux-dev) | A 12 billion parameter rectified flow transformer capable of generating images from text descriptions | 91032 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 90931 |
| [zsxkib/mmaudio](https://replicate.com/zsxkib/mmaudio) | Add sound to video using the MMAudio V2 model. An advanced AI model that synthesizes high-quality audio from video content, enabling seamless video-to-audio transformation. | 90228 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! 🤗 | 86119 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 62848 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 60291 |
| [google/imagen-4](https://replicate.com/google/imagen-4) | Google's Imagen 4 flagship model | 59730 |
| [alphanumericuser/kokoro-82m](https://replicate.com/alphanumericuser/kokoro-82m) | Kokoro v1.0 - text-to-speech (82M params, based on StyleTTS2) | 56593 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 55628 |
| [bytedance/sdxl-lightning-4step](https://replicate.com/bytedance/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 54556 |
| [prunaai/flux-kontext-dev](https://replicate.com/prunaai/flux-kontext-dev) | Fast endpoint for Flux Kontext, optimized with pruna framework | 52879 |
| [ideogram-ai/ideogram-v3-quality](https://replicate.com/ideogram-ai/ideogram-v3-quality) | The highest quality Ideogram v3 model. v3 creates images with stunning realism, creative designs, and consistent styles | 52361 |
| [meta/meta-llama-3-70b-instruct](https://replicate.com/meta/meta-llama-3-70b-instruct) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 52286 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x | 50771 |
| [black-forest-labs/flux-1.1-pro-ultra](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra) | FLUX1.1 [pro] in ultra and raw modes. Images are up to 4 megapixels. Use raw mode for realism. | 50004 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 46439 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 45653 |
| [bytedance/seedream-3](https://replicate.com/bytedance/seedream-3) | A text-to-image model with support for native high-resolution (2K) image generation | 45359 |
| [recraft-ai/recraft-v3](https://replicate.com/recraft-ai/recraft-v3) | Recraft V3 (code-named red_panda) is a text-to-image model with the ability to generate long texts, and images in a wide list of styles. As of today, it is SOTA in image generation, proven by the Text-to-Image Benchmark by Artificial Analysis | 44559 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 43292 |
| [851-labs/background-remover](https://replicate.com/851-labs/background-remover) | Remove backgrounds from images. | 43096 |
| [nicolascoutureau/video-utils](https://replicate.com/nicolascoutureau/video-utils) | null | 40641 |
| [ibm-granite/granite-3.3-8b-instruct](https://replicate.com/ibm-granite/granite-3.3-8b-instruct) | Granite-3.3-8B-Instruct is a 8-billion parameter 128K context length language model fine-tuned for improved reasoning and instruction-following capabilities. | 40101 |
| [ideogram-ai/ideogram-v3-turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo) | Turbo is the fastest and cheapest Ideogram v3. v3 creates images with stunning realism, creative designs, and consistent styles | 36125 |
| [black-forest-labs/flux-kontext-max](https://replicate.com/black-forest-labs/flux-kontext-max) | A premium text-based image editing model that delivers maximum performance and improved typography generation for transforming images through natural language prompts | 35824 |
| [kwaivgi/kling-v2.1](https://replicate.com/kwaivgi/kling-v2.1) | Use Kling v2.1 to generate 5s and 10s videos in 720p and 1080p resolution from a starting image (image-to-video) | 34147 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | 🦙 LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 32155 |
| [wan-video/wan-2.2-i2v-fast](https://replicate.com/wan-video/wan-2.2-i2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B image-to-video | 29555 |
| [lucataco/moondream2](https://replicate.com/lucataco/moondream2) | moondream2 is a small vision language model designed to run efficiently on edge devices | 28240 |
| [prunaai/hidream-l1-fast](https://replicate.com/prunaai/hidream-l1-fast) | This is an optimised version of the hidream-l1 model using the pruna ai optimisation toolkit! | 28177 |
| [bytedance/hyper-flux-8step](https://replicate.com/bytedance/hyper-flux-8step) | Hyper FLUX 8-step by ByteDance | 27526 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 26973 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 25803 |
| [falcons-ai/nsfw_image_detection](https://replicate.com/falcons-ai/nsfw_image_detection) | Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 24957 |
| [openai/gpt-4o-mini](https://replicate.com/openai/gpt-4o-mini) | Low latency, low cost version of OpenAI's GPT-4o model | 24759 |
| [black-forest-labs/flux-kontext-dev](https://replicate.com/black-forest-labs/flux-kontext-dev) | Open-weight version of FLUX.1 Kontext | 23821 |
| [lucataco/codeformer](https://replicate.com/lucataco/codeformer) | Robust face restoration algorithm for old photos/AI-generated faces | 20732 |
| [bytedance/hyper-flux-16step](https://replicate.com/bytedance/hyper-flux-16step) | Hyper FLUX 16-step by ByteDance | 20176 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 20139 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ⚡️ Blazing fast audio transcription with speaker diarization | Whisper Large V3 Turbo | word & sentence level timestamps | prompt | 20004 |
| [black-forest-labs/flux-dev-lora](https://replicate.com/black-forest-labs/flux-dev-lora) | A version of flux-dev, a text to image model, that supports fast fine-tuned lora inference | 18269 |
| [alexgenovese/upscaler](https://replicate.com/alexgenovese/upscaler) | GFPGAN aims at developing Practical Algorithms for Real-world Face and Object Restoration | 18076 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 17561 |
| [google/imagen-4-fast](https://replicate.com/google/imagen-4-fast) | Use this fast version of Imagen 4 when speed and cost are more important than quality | 17469 |
| [bytedance/seedance-1-lite](https://replicate.com/bytedance/seedance-1-lite) | A video generation model that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 720p resolution | 17174 |
| [luma/photon](https://replicate.com/luma/photon) | High-quality image generation model optimized for creative professional workflows and ultra-high fidelity outputs | 16824 |
| [yorickvp/llava-v1.6-vicuna-13b](https://replicate.com/yorickvp/llava-v1.6-vicuna-13b) | LLaVA v1.6: Large Language and Vision Assistant (Vicuna-13B) | 16644 |
| [topazlabs/video-upscale](https://replicate.com/topazlabs/video-upscale) | Video Upscaling from Topaz Labs | 15788 |
| [black-forest-labs/flux-fill-pro](https://replicate.com/black-forest-labs/flux-fill-pro) | Professional inpainting and outpainting model with state-of-the-art performance. Edit or extend images with natural, seamless results. | 14989 |
| [qwen/qwen-image](https://replicate.com/qwen/qwen-image) | An image generation foundation model in the Qwen series that achieves significant advances in complex text rendering. | 13722 |
| [asiryan/meina-mix-v11](https://replicate.com/asiryan/meina-mix-v11) | Meina Mix V11 Model (Text2Img, Img2Img and Inpainting) | 13681 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 12917 |
| [deepseek-ai/deepseek-v3](https://replicate.com/deepseek-ai/deepseek-v3) | DeepSeek-V3-0324 is the leading non-reasoning model, a milestone for open source | 12328 |
| [minimax/image-01](https://replicate.com/minimax/image-01) | Minimax's first image model, with character reference support | 10812 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 10029 |
| [prunaai/wan-2.2-image](https://replicate.com/prunaai/wan-2.2-image) | This model generates beautiful cinematic 2 megapixel images in 3-4 seconds and is derived from the Wan 2.2 model through optimisation techniques from the pruna package | 9823 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Generate image captions | 9786 |
| [openai/gpt-4.1-mini](https://replicate.com/openai/gpt-4.1-mini) | Fast, affordable version of GPT-4.1 | 9375 |
| [meta/meta-llama-3.1-405b-instruct](https://replicate.com/meta/meta-llama-3.1-405b-instruct) | Meta's flagship 405 billion parameter language model, fine-tuned for chat completions | 9314 |
| [bytedance/seedance-1-pro](https://replicate.com/bytedance/seedance-1-pro) | A pro version of Seedance that offers text-to-video and image-to-video support for 5s or 10s videos, at 480p and 1080p resolution | 9307 |
| [google/imagen-4-ultra](https://replicate.com/google/imagen-4-ultra) | Use this ultra version of Imagen 4 when quality matters more than speed and cost | 9221 |
| [minimax/speech-02-hd](https://replicate.com/minimax/speech-02-hd) | Text-to-Audio (T2A) that offers voice synthesis, emotional expression, and multilingual capabilities. Optimized for high-fidelity applications like voiceovers and audiobooks. | 8992 |
| [qwen/qwen-image-edit](https://replicate.com/qwen/qwen-image-edit) | Edit images using a prompt. This model extends Qwen-Image’s unique text rendering capabilities to image editing tasks, enabling precise text editing | 8694 |
| [black-forest-labs/flux-pro](https://replicate.com/black-forest-labs/flux-pro) | State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. | 8587 |
| [ideogram-ai/ideogram-v2](https://replicate.com/ideogram-ai/ideogram-v2) | An excellent image model with state of the art inpainting, prompt comprehension and text rendering | 8434 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 8055 |
| [pharmapsychotic/clip-interrogator](https://replicate.com/pharmapsychotic/clip-interrogator) | The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art! | 8053 |
| [smoretalk/clip-interrogator-turbo](https://replicate.com/smoretalk/clip-interrogator-turbo) | @pharmapsychotic 's CLIP-Interrogator, but 3x faster and more accurate. Specialized on SDXL. | 7903 |
| [anthropic/claude-3.5-haiku](https://replicate.com/anthropic/claude-3.5-haiku) | Anthropic's fastest, most cost-effective model, with a 200K token context window (claude-3-5-haiku-20241022) | 7818 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 7720 |
| [anthropic/claude-4-sonnet](https://replicate.com/anthropic/claude-4-sonnet) | Claude Sonnet 4 is a significant upgrade to 3.7, delivering superior coding and reasoning while responding more precisely to your instructions | 7657 |
| [topazlabs/image-upscale](https://replicate.com/topazlabs/image-upscale) | Professional-grade image upscaling, from Topaz Labs | 7381 |
| [playgroundai/playground-v2.5-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 7175 |
| [men1scus/birefnet](https://replicate.com/men1scus/birefnet) | Bilateral Reference for High-Resolution Dichotomous Image Segmentation (CAAI AIR 2024) | 7171 |
| [anthropic/claude-3.7-sonnet](https://replicate.com/anthropic/claude-3.7-sonnet) | The most intelligent Claude model and the first hybrid reasoning model on the market (claude-3-7-sonnet-20250219) | 7105 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 7009 |
| [victor-upmeet/whisperx-a40-large](https://replicate.com/victor-upmeet/whisperx-a40-large) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 for large audio files | 6898 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 6620 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 6613 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 6605 |
| [datacte/proteus-v0.2](https://replicate.com/datacte/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 6209 |
| [lucataco/flux-schnell-lora](https://replicate.com/lucataco/flux-schnell-lora) | FLUX.1-Schnell LoRA Explorer | 6006 |
| [datacte/proteus-v0.3](https://replicate.com/datacte/proteus-v0.3) | ProteusV0.3: The Anime Update | 5990 |
| [aisha-ai-official/anillustrious-v4](https://replicate.com/aisha-ai-official/anillustrious-v4) | null | 5887 |
| [fofr/flux-black-light](https://replicate.com/fofr/flux-black-light) | A flux lora fine-tuned on black light images | 5810 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 5617 |
| [zsxkib/ic-light](https://replicate.com/zsxkib/ic-light) | ✍️✨Prompts to auto-magically relights your images | 5549 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 5428 |
| [google/imagen-3](https://replicate.com/google/imagen-3) | Google's highest quality text-to-image model, capable of generating images with detail, rich lighting and beauty | 5327 |
| [adirik/interior-design](https://replicate.com/adirik/interior-design) | Realistic interior design with text and image inputs | 5314 |
| [openai/gpt-image-1](https://replicate.com/openai/gpt-image-1) | A multimodal image generation model that creates high-quality images. You need to bring your own verified OpenAI key to use this model. Your OpenAI account will be charged for usage. | 5191 |
| [kwaivgi/kling-v1.6-standard](https://replicate.com/kwaivgi/kling-v1.6-standard) | Generate 5s and 10s videos in 720p resolution at 30fps | 5076 |
| [meta/llama-4-scout-instruct](https://replicate.com/meta/llama-4-scout-instruct) | A 17 billion parameter model with 16 experts | 5021 |
| [stability-ai/stable-diffusion-3.5-large](https://replicate.com/stability-ai/stable-diffusion-3.5-large) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, thanks to Query-Key Normalization. | 4996 |
| [cdingram/face-swap](https://replicate.com/cdingram/face-swap) | Image to image face swapping | 4911 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 4816 |
| [cuuupid/idm-vton](https://replicate.com/cuuupid/idm-vton) | Best-in-class clothing virtual try on in the wild (non-commercial use only) | 4569 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 4494 |
| [black-forest-labs/flux-fill-dev](https://replicate.com/black-forest-labs/flux-fill-dev) | Open-weight inpainting model for editing and extending images. Guidance-distilled from FLUX.1 Fill [pro]. | 4256 |
| [pollinations/modnet](https://replicate.com/pollinations/modnet) | A deep learning approach to remove background & adding new background image | 4253 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 4236 |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | null | 4225 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 4209 |
| [ideogram-ai/ideogram-v2a](https://replicate.com/ideogram-ai/ideogram-v2a) | Like Ideogram v2, but faster and cheaper | 3951 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 3938 |
| [meronym/speaker-diarization](https://replicate.com/meronym/speaker-diarization) | Segments an audio recording based on who is speaking | 3887 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 3877 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 3872 |
| [ideogram-ai/ideogram-v2-turbo](https://replicate.com/ideogram-ai/ideogram-v2-turbo) | A fast image model with state of the art inpainting, prompt comprehension and text rendering. | 3730 |
| [black-forest-labs/flux-depth-dev](https://replicate.com/black-forest-labs/flux-depth-dev) | Open-weight depth-aware image generation. Edit images while preserving spatial relationships. | 3699 |
| [meta/llama-4-maverick-instruct](https://replicate.com/meta/llama-4-maverick-instruct) | A 17 billion parameter model with 128 experts | 3690 |
| [fofr/any-comfyui-workflow](https://replicate.com/fofr/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/replicate/cog-comfyui | 3679 |
| [franz-biz/yolo-world-xl](https://replicate.com/franz-biz/yolo-world-xl) | Real-Time Open-Vocabulary Object Detection using the xl weights | 3640 |
| [smoosh-sh/baby-mystic](https://replicate.com/smoosh-sh/baby-mystic) | Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent | 3602 |
| [charlesmccarthy/addwatermark](https://replicate.com/charlesmccarthy/addwatermark) | Add a watermark to your videos using the power of Replicate brought to you from your friends at FullJourney.AI | 3573 |
| [bytedance/flux-pulid](https://replicate.com/bytedance/flux-pulid) | ⚡️FLUX PuLID: FLUX-dev based Pure and Lightning ID Customization via Contrastive Alignment🎭 | 3566 |
| [black-forest-labs/flux-schnell-lora](https://replicate.com/black-forest-labs/flux-schnell-lora) | The fastest image generation model tailored for fine-tuned use | 3394 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting by the HF Diffusers team | 3298 |
| [flux-kontext-apps/restore-image](https://replicate.com/flux-kontext-apps/restore-image) | Use FLUX Kontext to restore, fix scratches and damage, and colorize old photos | 3294 |
| [prunaai/flux.1-dev-lora](https://replicate.com/prunaai/flux.1-dev-lora) | This is a 3x faster FLUX.1 [dev] model from Black Forest Labs, optimised with pruna with minimal quality loss. | 3232 |
| [runwayml/gen4-image](https://replicate.com/runwayml/gen4-image) | Runway's Gen-4 Image model with references. Use up to 3 reference images to create the exact image you need. Capture every angle. | 3174 |
| [ardianfe/music-gen-fn-200e](https://replicate.com/ardianfe/music-gen-fn-200e) | Create music for your content | 3128 |
| [recraft-ai/recraft-crisp-upscale](https://replicate.com/recraft-ai/recraft-crisp-upscale) | Designed to make images sharper and cleaner, Crisp Upscale increases overall quality, making visuals suitable for web use or print-ready materials. | 3079 |
| [lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) | FLUX.1-Dev Multi LoRA Explorer | 2991 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 2983 |
| [openai/gpt-oss-120b](https://replicate.com/openai/gpt-oss-120b) | 120b open-weight language model from OpenAI | 2921 |
| [mrhan1993/fooocus-api](https://replicate.com/mrhan1993/fooocus-api) | null | 2898 |
| [pseudoram/rvc-v2](https://replicate.com/pseudoram/rvc-v2) | Speech to speech with any RVC v2 trained AI voice | 2786 |
| [ideogram-ai/ideogram-character](https://replicate.com/ideogram-ai/ideogram-character) | Generate consistent characters from a single reference image. Outputs can be in many styles. You can also use inpainting to add your character to an existing image. | 2750 |
| [openai/gpt-5](https://replicate.com/openai/gpt-5) | OpenAI's new model excelling at coding, writing, and reasoning. | 2573 |
| [bytedance/seededit-3.0](https://replicate.com/bytedance/seededit-3.0) | Text-guided image editing model that preserves original details while making targeted modifications like lighting changes, object removal, and style conversion | 2563 |
| [fofr/consistent-character](https://replicate.com/fofr/consistent-character) | Create images of a given character in different poses | 2503 |
| [melgor/stabledesign_interiordesign](https://replicate.com/melgor/stabledesign_interiordesign) | Transfer empty room into fabulous interior design | 2446 |
| [openai/o4-mini](https://replicate.com/openai/o4-mini) | OpenAI's fast, lightweight reasoning model | 2329 |
| [bytedance/pulid](https://replicate.com/bytedance/pulid) | 📖 PuLID: Pure and Lightning ID Customization via Contrastive Alignment | 2298 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 2288 |
| [asiryan/juggernaut-xl-v7](https://replicate.com/asiryan/juggernaut-xl-v7) | Juggernaut XL v7 Model (Text2Img, Img2Img and Inpainting) | 2285 |
| [lucataco/flux-dev-lora](https://replicate.com/lucataco/flux-dev-lora) | FLUX.1-Dev LoRA Explorer (DEPRECATED Please use: black-forest-labs/flux-dev-lora) | 2188 |
| [minimax/hailuo-02](https://replicate.com/minimax/hailuo-02) | Hailuo 2 is a text-to-video and image-to-video model that can make 6s or 10s videos at 768p (standard) or 1080p (pro). It excels at real world physics. | 2135 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 2123 |
| [firtoz/trellis](https://replicate.com/firtoz/trellis) | A powerful 3D asset generation model | 2090 |
| [google/gemini-2.5-flash-image](https://replicate.com/google/gemini-2.5-flash-image) | Google's latest image generation model in Gemini 2.5 | 2032 |
| [shreejalmaharjan-27/website-screenshot](https://replicate.com/shreejalmaharjan-27/website-screenshot) | Capture a website screenshot | 2018 |
| [adirik/realvisxl-v3.0-turbo](https://replicate.com/adirik/realvisxl-v3.0-turbo) | Photorealism with RealVisXL V3.0 Turbo based on SDXL | 1979 |
| [declare-lab/tango](https://replicate.com/declare-lab/tango) | Tango 2: Use text prompts to make sound effects | 1968 |
| [fofr/style-transfer](https://replicate.com/fofr/style-transfer) | Transfer the style of one image to another | 1966 |
| [ryan5453/demucs](https://replicate.com/ryan5453/demucs) | Demucs is an audio source separator created by Facebook Research. | 1959 |
| [chenxwh/depth-anything-v2](https://replicate.com/chenxwh/depth-anything-v2) | Depth estimation with faster inference speed, fewer parameters, and higher depth accuracy. | 1952 |
| [meta/llama-2-70b-chat](https://replicate.com/meta/llama-2-70b-chat) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 1950 |
| [zsxkib/wd-image-tagger](https://replicate.com/zsxkib/wd-image-tagger) | Image tagger fine-tuned on WaifuDiffusion w/ (SwinV2, SwinV2, ConvNext, and ViT) | 1935 |
| [hanglics/dse-qwen2-2b-mrl-v1](https://replicate.com/hanglics/dse-qwen2-2b-mrl-v1) | The screenshot retriever model base on DSE. | 1891 |
| [simbrams/segformer-b5-finetuned-ade-640-640](https://replicate.com/simbrams/segformer-b5-finetuned-ade-640-640) | Semantic Segmentation | 1888 |
| [zf-kbot/inpaint-and-guess-prompt](https://replicate.com/zf-kbot/inpaint-and-guess-prompt) | Use a mask to inpaint the image or generate a prompt based on the mask. | 1867 |
| [fofr/realvisxl-v3-multi-controlnet-lora](https://replicate.com/fofr/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 1843 |
| [ideogram-ai/ideogram-v3-balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced) | Balance speed, quality and cost. Ideogram v3 creates images with stunning realism, creative designs, and consistent styles | 1838 |
| [openai/gpt-5-mini](https://replicate.com/openai/gpt-5-mini) | Faster version of OpenAI's flagship GPT-5 model | 1799 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 1780 |
| [openai/gpt-4.1-nano](https://replicate.com/openai/gpt-4.1-nano) | Fastest, most cost-effective GPT-4.1 model from OpenAI | 1714 |
| [fofr/pulid-base](https://replicate.com/fofr/pulid-base) | Use a face to make images. Uses SDXL fine-tuned checkpoints. | 1713 |
| [soykertje/spleeter](https://replicate.com/soykertje/spleeter) | Spleeter is Deezer source separation library with pretrained models written in Python and uses Tensorflow. | 1702 |
| [openai/gpt-4.1](https://replicate.com/openai/gpt-4.1) | OpenAI's Flagship GPT model for complex tasks. | 1694 |
| [google/upscaler](https://replicate.com/google/upscaler) | Upscale images 2x or 4x times | 1684 |
| [openai/gpt-5-nano](https://replicate.com/openai/gpt-5-nano) | Fastest, most cost-effective GPT-5 model from OpenAI | 1661 |
| [openai/clip](https://replicate.com/openai/clip) | Official CLIP models, generate CLIP (clip-vit-large-patch14) text & image embeddings | 1641 |
| [stability-ai/stable-diffusion-3.5-large-turbo](https://replicate.com/stability-ai/stable-diffusion-3.5-large-turbo) | A text-to-image model that generates high-resolution images with fine details. It supports various artistic styles and produces diverse outputs from the same prompt, with a focus on fewer inference steps | 1566 |
| [lucataco/frame-extractor](https://replicate.com/lucataco/frame-extractor) | Extract the first or last frame from any video file as a high-quality image | 1540 |
| [kwaivgi/kling-v1.6-pro](https://replicate.com/kwaivgi/kling-v1.6-pro) | Generate 5s and 10s videos in 1080p resolution | 1523 |
| [wan-video/wan-2.2-5b-fast](https://replicate.com/wan-video/wan-2.2-5b-fast) | The fastest Wan 2.2 text-to-image and image-to-video model | 1518 |
| [aisha-ai-official/illust3relustion](https://replicate.com/aisha-ai-official/illust3relustion) | null | 1506 |
| [smoretalk/rembg-enhance](https://replicate.com/smoretalk/rembg-enhance) | A background removal model enhanced with better matting | 1462 |
| [lucataco/flux-content-filter](https://replicate.com/lucataco/flux-content-filter) | Flux Content Filter - Check for public figures and copyright concerns | 1425 |
| [zsxkib/molmo-7b](https://replicate.com/zsxkib/molmo-7b) | allenai/Molmo-7B-D-0924, Answers questions and caption about images | 1425 |
| [simbrams/ri](https://replicate.com/simbrams/ri) | Realistic Inpainting with ControlNET (M-LSD + SEG) | 1417 |
| [deepseek-ai/deepseek-r1](https://replicate.com/deepseek-ai/deepseek-r1) | A reasoning model trained with reinforcement learning, on par with OpenAI o1 | 1374 |
| [runwayml/gen4-image-turbo](https://replicate.com/runwayml/gen4-image-turbo) | Gen-4 Image Turbo is cheaper and 2.5x faster than Gen-4 Image. An image model with references, use up to 3 reference images to create the exact image you need. Capture every angle. | 1372 |
| [codeplugtech/background_remover](https://replicate.com/codeplugtech/background_remover) | Remove background from image | 1366 |
| [konieshadow/fooocus-api](https://replicate.com/konieshadow/fooocus-api) | Third party Fooocus replicate model | 1362 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 1351 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 1345 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 1335 |
| [aisha-ai-official/miaomiao-harem-illustrious-v1](https://replicate.com/aisha-ai-official/miaomiao-harem-illustrious-v1) | null | 1282 |
| [juergengunz/real-esrgan-v2](https://replicate.com/juergengunz/real-esrgan-v2) | Real-ESRGAN Upscale with AI Face Correction | 1267 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 1265 |
| [replicate/all-mpnet-base-v2](https://replicate.com/replicate/all-mpnet-base-v2) | This is a language model that can be used to obtain document embeddings suitable for downstream tasks like semantic search and clustering. | 1258 |
| [flux-kontext-apps/multi-image-kontext-max](https://replicate.com/flux-kontext-apps/multi-image-kontext-max) | An experimental FLUX Kontext model that can combine two input images | 1204 |
| [flux-kontext-apps/multi-image-kontext-pro](https://replicate.com/flux-kontext-apps/multi-image-kontext-pro) | An experimental model with FLUX Kontext Pro that can combine two input images | 1200 |
| [hexiaochun/pp-ocr-v4](https://replicate.com/hexiaochun/pp-ocr-v4) | 图文识别 | 1188 |
| [minimax/music-01](https://replicate.com/minimax/music-01) | Quickly generate up to 1 minute of music with lyrics and vocals in the style of a reference track | 1155 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 1153 |
| [openai/dall-e-3](https://replicate.com/openai/dall-e-3) | An AI system that can create realistic images and art from a description in natural language. | 1133 |
| [openai/gpt-4o](https://replicate.com/openai/gpt-4o) | OpenAI's high-intelligence chat model | 1127 |
| [aisha-ai-official/wai-nsfw-illustrious-v11](https://replicate.com/aisha-ai-official/wai-nsfw-illustrious-v11) | null | 1121 |
| [tencentarc/vqfr](https://replicate.com/tencentarc/vqfr) | Blind Face Restoration with Vector-Quantized Dictionary and Parallel Decoder | 1119 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 1100 |
| [lucataco/florence-2-base](https://replicate.com/lucataco/florence-2-base) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 1087 |
| [prunaai/flux-schnell](https://replicate.com/prunaai/flux-schnell) | This is a 3x faster FLUX.1 [schnell] model from Black Forest Labs, optimised with pruna with minimal quality loss. Contact us for more at pruna.ai | 1075 |
| [ahmdyassr/detect-crop-face](https://replicate.com/ahmdyassr/detect-crop-face) | A simple model to detect and crop face found in image, made for https://outfit.fm | 1070 |
| [lucataco/realistic-vision-v5.1](https://replicate.com/lucataco/realistic-vision-v5.1) | Implementation of Realistic Vision v5.1 with VAE | 1061 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 1056 |
| [cuuupid/markitdown](https://replicate.com/cuuupid/markitdown) | Microsoft's tool to convert Office documents, PDFs, images, audio, and more to LLM-ready markdown. | 1055 |
| [fpsorg/emoji](https://replicate.com/fpsorg/emoji) | Make Emoji with AI. | 1038 |
| [daanelson/minigpt-4](https://replicate.com/daanelson/minigpt-4) | A model which generates text in response to an input image and prompt. | 997 |
| [pengdaqian2020/image-tagger](https://replicate.com/pengdaqian2020/image-tagger) | image tagger | 996 |
| [bytedance/dreamina-3.1](https://replicate.com/bytedance/dreamina-3.1) | 4MP text-to-image generation with enhanced cinematic-quality image generation with precise style control, improved text rendering, and commercial design optimization. | 988 |
| [microsoft/omniparser-v2](https://replicate.com/microsoft/omniparser-v2) | OmniParser is a screen parsing tool to convert general GUI screen to structured elements. | 964 |
| [delta-lock/ponynai3](https://replicate.com/delta-lock/ponynai3) | Models fine-tuned from Pony-XL series. | 958 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 954 |
| [cjwbw/videocrafter](https://replicate.com/cjwbw/videocrafter) | VideoCrafter2: Text-to-Video and Image-to-Video Generation and Editing | 934 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | 😊 Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 933 |
| [ostris/flux-dev-lora-trainer](https://replicate.com/ostris/flux-dev-lora-trainer) | Fine-tune FLUX.1-dev using ai-toolkit | 932 |
| [fermatresearch/magic-image-refiner](https://replicate.com/fermatresearch/magic-image-refiner) | A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling. | 911 |
| [luma/reframe-image](https://replicate.com/luma/reframe-image) | Change the aspect ratio of any photo using AI (not cropping) | 900 |
| [mtg/effnet-discogs](https://replicate.com/mtg/effnet-discogs) | An EfficientNet for music style classification by 400 styles from the Discogs taxonomy | 852 |
| [bria/eraser](https://replicate.com/bria/eraser) | SOTA Object removal, enables precise removal of unwanted objects from images while maintaining high-quality outputs. Trained exclusively on licensed data for safe and risk-free commercial use | 850 |
| [google/imagen-3-fast](https://replicate.com/google/imagen-3-fast) | A faster and cheaper Imagen 3 model, for when price or speed are more important than final image quality | 848 |
| [zust-ai/supir](https://replicate.com/zust-ai/supir) | null | 838 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 835 |
| [vetkastar/fooocus](https://replicate.com/vetkastar/fooocus) | Image generation, Added: inpaint_strength loras_custom_urls | 826 |
| [stability-ai/stable-diffusion-3](https://replicate.com/stability-ai/stable-diffusion-3) | A text-to-image model with greatly improved performance in image quality, typography, complex prompt understanding, and resource-efficiency | 822 |
| [pixverse/pixverse-v4.5](https://replicate.com/pixverse/pixverse-v4.5) | Quickly make 5s or 8s videos at 540p, 720p or 1080p. It has enhanced motion, prompt coherence and handles complex actions well. | 814 |
| [black-forest-labs/flux-depth-pro](https://replicate.com/black-forest-labs/flux-depth-pro) | Professional depth-aware image generation. Edit images while preserving spatial relationships. | 812 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 809 |
| [flux-kontext-apps/cartoonify](https://replicate.com/flux-kontext-apps/cartoonify) | Turn your image into a cartoon with FLUX.1 Kontext [pro] | 795 |
| [pixverse/pixverse-v5](https://replicate.com/pixverse/pixverse-v5) | Create 5s-8s videos with enhanced character movement, visual effects, and exclusive 1080p-8s support. Optimized for anime characters and complex actions | 785 |
| [fofr/latent-consistency-model](https://replicate.com/fofr/latent-consistency-model) | Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet | 778 |
| [luma/photon-flash](https://replicate.com/luma/photon-flash) | Accelerated variant of Photon prioritizing speed while maintaining quality | 777 |
| [flux-kontext-apps/change-haircut](https://replicate.com/flux-kontext-apps/change-haircut) | Quickly change someone's hair style and hair color, powered by FLUX.1 Kontext [pro] | 770 |
| [lucataco/qwen2-vl-7b-instruct](https://replicate.com/lucataco/qwen2-vl-7b-instruct) | Latest model in the Qwen family for chatting with video and image models | 768 |
| [google/veo-3-fast](https://replicate.com/google/veo-3-fast) | A faster and cheaper version of Google’s Veo 3 video model, with audio | 767 |
| [black-forest-labs/flux-1.1-pro-ultra-finetuned](https://replicate.com/black-forest-labs/flux-1.1-pro-ultra-finetuned) | Inference model for FLUX 1.1 [pro] Ultra using custom `finetune_id`. Supports 4MP images and raw mode for realism | 758 |
| [bytedance/omni-human](https://replicate.com/bytedance/omni-human) | Turns your audio/video/images into professional-quality animated videos | 753 |
| [marfnxd/sks_verse_style](https://replicate.com/marfnxd/sks_verse_style) | null | 746 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | Integral cog of doiwear.it | 746 |
| [tmappdev/lang-segment-anything](https://replicate.com/tmappdev/lang-segment-anything) | Segment Anything with prompts | 742 |
| [google/veo-3](https://replicate.com/google/veo-3) | Sound on: Google’s flagship Veo 3 text to video model, with audio | 740 |
| [resemble-ai/chatterbox](https://replicate.com/resemble-ai/chatterbox) | Generate expressive, natural speech. Features unique emotion control, instant voice cloning from short audio, and built-in watermarking. | 722 |
| [flux-kontext-apps/multi-image-list](https://replicate.com/flux-kontext-apps/multi-image-list) | FLUX Kontext max with list input for multiple images | 720 |
| [asiryan/realism-xl](https://replicate.com/asiryan/realism-xl) | Realism XL Model (Text2Img, Img2Img and Inpainting) | 713 |
| [justmalhar/flux-thumbnails](https://replicate.com/justmalhar/flux-thumbnails) | Generate 16:9 Thumbnails. Use prefix - `Thumbnail in the style of TOK` | 705 |
| [wan-video/wan-2.2-t2v-fast](https://replicate.com/wan-video/wan-2.2-t2v-fast) | A very fast and cheap PrunaAI optimized version of Wan 2.2 A14B text-to-video | 693 |
| [resemble-ai/resemble-enhance](https://replicate.com/resemble-ai/resemble-enhance) | AI-driven audio enhancement for your audio files, powered by Resemble AI | 681 |
| [zsxkib/jina-clip-v2](https://replicate.com/zsxkib/jina-clip-v2) | Jina-CLIP v2: 0.9B multimodal embedding model with 89-language multilingual support, 512x512 image resolution, and Matryoshka representations | 676 |
| [moonshotai/kimi-k2-instruct](https://replicate.com/moonshotai/kimi-k2-instruct) | Kimi K2 achieves exceptional performance across frontier knowledge, reasoning, and coding tasks while being meticulously optimized for agentic capabilities | 673 |
| [pikachupichu25/live-portrait-image](https://replicate.com/pikachupichu25/live-portrait-image) | Match facial expression using a driving image using LivePortrait as a base | 659 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 658 |
| [colinmcdonnell22/ghiblify-3](https://replicate.com/colinmcdonnell22/ghiblify-3) | null | 644 |
| [codeslake/ifan-defocus-deblur](https://replicate.com/codeslake/ifan-defocus-deblur) | Removes defocus blur in an image | 634 |
| [zsxkib/sonic](https://replicate.com/zsxkib/sonic) | Generates realistic talking face animations from a portrait image and audio using the CVPR 2025 Sonic model | 628 |
| [kwaivgi/kling-v2.1-master](https://replicate.com/kwaivgi/kling-v2.1-master) | A premium version of Kling v2.1 with superb dynamics and prompt adherence. Generate 1080p 5s and 10s videos from text or an image | 623 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 615 |
| [vectradmin/sdxl-v-transparent](https://replicate.com/vectradmin/sdxl-v-transparent) | null | 614 |
| [lightweight-ai/model1](https://replicate.com/lightweight-ai/model1) | flux_schnell model img2img inference | 602 |
| [deepseek-ai/deepseek-vl2](https://replicate.com/deepseek-ai/deepseek-vl2) | DeepSeek-VL2, an advanced series of large Mixture-of-Experts (MoE) Vision-Language Models that significantly improves upon its predecessor, DeepSeek-VL | 601 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 593 |
| [replicate/train-rvc-model](https://replicate.com/replicate/train-rvc-model) | Train your own custom RVC model | 592 |
| [fofr/sdxl-fresh-ink](https://replicate.com/fofr/sdxl-fresh-ink) | SDXL fine-tuned on photos of freshly inked tattoos | 586 |
| [minimax/video-01](https://replicate.com/minimax/video-01) | Generate 6s videos with prompts or images. (Also known as Hailuo). Use a subject reference to make a video with a character and the S2V-01 model. | 571 |
| [recraft-ai/recraft-v3-svg](https://replicate.com/recraft-ai/recraft-v3-svg) | Recraft V3 SVG (code-named red_panda) is a text-to-image model with the ability to generate high quality SVG images including logotypes, and icons. The model supports a wide list of styles. | 571 |
| [bria/remove-background](https://replicate.com/bria/remove-background) | Bria AI's remove background model | 566 |
| [devgmstudios/pony-realism-v23](https://replicate.com/devgmstudios/pony-realism-v23) | Latest Pony Realism Model. Try it with WEIGHTS on creatorframes.com | 561 |
| [zetyquickly-org/faceswap-a-gif](https://replicate.com/zetyquickly-org/faceswap-a-gif) | Make Fun by Changing Face on a GIF! | 560 |
| [cjwbw/stable-diffusion-v2-inpainting](https://replicate.com/cjwbw/stable-diffusion-v2-inpainting) | stable-diffusion-v2-inpainting | 557 |
| [konieshadow/fooocus-api-realistic](https://replicate.com/konieshadow/fooocus-api-realistic) | Third party Fooocus replicate model with preset 'realistic' | 534 |
| [aisha-ai-official/nsfw-flux-dev](https://replicate.com/aisha-ai-official/nsfw-flux-dev) | null | 525 |
| [xlabs-ai/flux-dev-realism](https://replicate.com/xlabs-ai/flux-dev-realism) | FLUX.1-dev with XLabs-AI’s realism lora | 504 |
| [danila013/ghibli-easycontrol](https://replicate.com/danila013/ghibli-easycontrol) | Ghiblify your image – ChatGPT-level quality, 10× faster and cheaper. | 501 |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | Fast FLUX DEV -> Flux Controlnet Canny, Controlnet Depth , Controlnet Line Art, Controlnet Upscaler - You can use just one controlnet or All - LORAs: HyperFlex LoRA , Add Details LoRA , Realism LoRA | 486 |
| [pnyompen/sdxl-controlnet-lora-small](https://replicate.com/pnyompen/sdxl-controlnet-lora-small) | SDXL Canny controlnet with LoRA support. | 485 |
| [black-forest-labs/flux-canny-pro](https://replicate.com/black-forest-labs/flux-canny-pro) | Professional edge-guided image generation. Control structure and composition using Canny edge detection | 476 |
| [black-forest-labs/flux-kontext-dev-lora](https://replicate.com/black-forest-labs/flux-kontext-dev-lora) | FLUX.1 Kontext[dev] image editing model for running lora finetunes | 474 |
| [sakemin/all-in-one-music-structure-analyzer](https://replicate.com/sakemin/all-in-one-music-structure-analyzer) | Cog implementation of mir-aidj(Taejun Kim)'s 'All-In-One Music Structure Analyzer' | 473 |
| [nvidia/sana](https://replicate.com/nvidia/sana) | A fast image model with wide artistic range and resolutions up to 4096x4096 | 471 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 470 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 469 |
| [nvidia/sana-sprint-1.6b](https://replicate.com/nvidia/sana-sprint-1.6b) | SANA-Sprint: One-Step Diffusion with Continuous-Time Consistency Distillation | 466 |
| [lucataco/ace-step](https://replicate.com/lucataco/ace-step) | A Step Towards Music Generation Foundation Model text2music | 465 |
| [fermatresearch/sdxl-controlnet-lora](https://replicate.com/fermatresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 440 |
| [fofr/color-matcher](https://replicate.com/fofr/color-matcher) | Color match and white balance fixes for images | 438 |
| [chenxwh/sdxl-flash](https://replicate.com/chenxwh/sdxl-flash) | Fast sdxl with higher quality | 437 |
| [bytedance/sa2va-8b-image](https://replicate.com/bytedance/sa2va-8b-image) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 435 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 434 |
| [easel/advanced-face-swap](https://replicate.com/easel/advanced-face-swap) | Face swap one or two people into a target image | 423 |
| [replicate/fast-flux-trainer](https://replicate.com/replicate/fast-flux-trainer) | Train subjects or styles faster than ever | 422 |
| [flux-kontext-apps/portrait-series](https://replicate.com/flux-kontext-apps/portrait-series) | Create a series of portrait photos from a single image | 416 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 410 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 408 |
| [meta/codellama-7b](https://replicate.com/meta/codellama-7b) | A 7 billion parameter Llama tuned for coding and conversation | 408 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 404 |
| [flux-kontext-apps/face-to-many-kontext](https://replicate.com/flux-kontext-apps/face-to-many-kontext) | Become a character, in style | 397 |
| [adminconteudosflix/midjourney-allcraft](https://replicate.com/adminconteudosflix/midjourney-allcraft) | null | 395 |
| [declare-lab/tangoflux](https://replicate.com/declare-lab/tangoflux) | Super Fast and Faithful Text to Audio Generation with Flow Matching and Clap-Ranked Preference Optimization | 390 |
| [chenxwh/cogvlm2](https://replicate.com/chenxwh/cogvlm2) | CogVLM2: Visual Language Models for Image and Video Understanding | 388 |
| [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) | Base version of Llama 3, an 8 billion parameter language model from Meta. | 385 |
| [deepseek-ai/deepseek-vl-7b-base](https://replicate.com/deepseek-ai/deepseek-vl-7b-base) | DeepSeek-VL: An open-source Vision-Language Model designed for real-world vision and language understanding applications | 385 |
| [zsxkib/kimi-vl-a3b-thinking](https://replicate.com/zsxkib/kimi-vl-a3b-thinking) | Kimi-VL-A3B-Thinking is a multi-modal LLM that can understand text and images, and generate text with thinking processes | 375 |
| [google/lyria-2](https://replicate.com/google/lyria-2) | Lyria 2 is a music generation model that produces 48kHz stereo audio through text-based prompts | 368 |
| [luma/reframe-video](https://replicate.com/luma/reframe-video) | Change the aspect ratio of any video up to 30 seconds long, outputs will be 720p | 360 |
| [abiruyt/text-extract-ocr](https://replicate.com/abiruyt/text-extract-ocr) | A simple OCR Model that can easily extract text from an image. | 360 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 352 |
| [wavespeedai/wan-2.1-i2v-480p](https://replicate.com/wavespeedai/wan-2.1-i2v-480p) | Accelerated inference for Wan 2.1 14B image to video, a comprehensive and open suite of video foundation models that pushes the boundaries of video generation. | 344 |
| [wan-video/wan-2.2-i2v-a14b](https://replicate.com/wan-video/wan-2.2-i2v-a14b) | Image-to-video at 720p and 480p with Wan 2.2 A14B | 340 |
| [catacolabs/sdxl-ad-inpaint](https://replicate.com/catacolabs/sdxl-ad-inpaint) | Product advertising image generator using SDXL | 335 |
| [bytedance/sa2va-26b-image](https://replicate.com/bytedance/sa2va-26b-image) | Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of Images and Videos | 331 |
| [soykertje/whisper](https://replicate.com/soykertje/whisper) | Convert speech in audio to text | 331 |
| [minimax/hailuo-02-fast](https://replicate.com/minimax/hailuo-02-fast) | A low cost and fast version of Hailuo 02. Generate 6s and 10s videos in 512p | 322 |
| [deepseek-ai/deepseek-v3.1](https://replicate.com/deepseek-ai/deepseek-v3.1) | Latest hybrid thinking model from Deepseek | 317 |
| [bytedance/latentsync](https://replicate.com/bytedance/latentsync) | LatentSync: generate high-quality lip sync animations | 317 |
| [meta/llama-guard-4-12b](https://replicate.com/meta/llama-guard-4-12b) | null | 313 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 312 |
| [ibm-granite/granite-vision-3.3-2b](https://replicate.com/ibm-granite/granite-vision-3.3-2b) | Granite-vision-3.3-2b is a compact and efficient vision-language model, specifically designed for visual document understanding, enabling automated content extraction from tables, charts, infographics, plots, diagrams, and more. | 311 |
| [playgroundai/playground-v2-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2-1024px-aesthetic) | Playground v2 is a diffusion-based text-to-image generative model trained from scratch by the research team at Playground | 298 |
| [catacolabs/cartoonify](https://replicate.com/catacolabs/cartoonify) | Turn your image into a cartoon | 294 |
| [leonardoai/phoenix-1.0](https://replicate.com/leonardoai/phoenix-1.0) | Leonardo AI’s first foundational model produces images up to 5 megapixels (fast, quality and ultra modes) | 286 |
| [usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5](https://replicate.com/usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5) | Inpainting || multi-controlnet || single-controlnet || ip-adapter || ip adapter face || ip adapter plus || No ip adapter | 286 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 285 |
| [ideogram-ai/ideogram-v2a-turbo](https://replicate.com/ideogram-ai/ideogram-v2a-turbo) | Like Ideogram v2 turbo, but now faster and cheaper | 284 |
| [recraft-ai/recraft-vectorize](https://replicate.com/recraft-ai/recraft-vectorize) | Convert raster images to high-quality SVG format with precision and clean vector paths, perfect for logos, icons, and scalable graphics. | 282 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 282 |
| [minimax/video-01-director](https://replicate.com/minimax/video-01-director) | Generate videos with specific camera movements | 279 |
| [recraft-ai/recraft-20b](https://replicate.com/recraft-ai/recraft-20b) | Affordable and fast images | 279 |
| [runwayml/upscale-v1](https://replicate.com/runwayml/upscale-v1) | Upscale videos by 4x, up to a maximum of 4k | 249 |
| [black-forest-labs/flux-canny-dev](https://replicate.com/black-forest-labs/flux-canny-dev) | Open-weight edge-guided image generation. Control structure and composition using Canny edge detection. | 245 |
| [tmappdev/change_video_bg](https://replicate.com/tmappdev/change_video_bg) | Change or Replace Video Background with any Image | 245 |
| [nvidia/parakeet-rnnt-1.1b](https://replicate.com/nvidia/parakeet-rnnt-1.1b) | 🗣️ Nvidia + Suno.ai's speech-to-text conversion with high accuracy and efficiency 📝 | 243 |
| [openai/gpt-oss-20b](https://replicate.com/openai/gpt-oss-20b) | 20b open-weight language model from OpenAI | 240 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 240 |
| [xlabs-ai/flux-dev-controlnet](https://replicate.com/xlabs-ai/flux-dev-controlnet) | XLabs v3 canny, depth and soft edge controlnets for Flux.1 Dev | 235 |
| [lightricks/ltx-video](https://replicate.com/lightricks/ltx-video) | LTX-Video is the first DiT-based video generation model capable of generating high-quality videos in real-time. It produces 24 FPS videos at a 768x512 resolution faster than they can be watched. | 228 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 226 |
| [runwayml/gen4-aleph](https://replicate.com/runwayml/gen4-aleph) | A new way to edit, transform and generate video | 225 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 220 |
| [luma/ray-flash-2-720p](https://replicate.com/luma/ray-flash-2-720p) | Generate 5s and 9s 720p videos, faster and cheaper than Ray 2 | 212 |
| [zeke/ziki-flux](https://replicate.com/zeke/ziki-flux) | A Flux fine-tune of https://replicate.com/zeke the real-life human. Use "ZIKI" in the prompt to activate the trained style. | 211 |
| [recraft-ai/recraft-remove-background](https://replicate.com/recraft-ai/recraft-remove-background) | Automated background removal for images. Tuned for AI-generated content, product photos, portraits, and design workflows | 210 |
| [lucataco/ssd-1b](https://replicate.com/lucataco/ssd-1b) | Segmind Stable Diffusion Model (SSD-1B) is a distilled 50% smaller version of SDXL, offering a 60% speedup while maintaining high-quality text-to-image generation capabilities | 208 |
| [shreejalmaharjan-27/tiktok-short-captions](https://replicate.com/shreejalmaharjan-27/tiktok-short-captions) | Generate Tiktok-Style Captions powered by Whisper (GPU) | 207 |
| [cswry/seesr](https://replicate.com/cswry/seesr) | SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution | 205 |
| [recraft-ai/recraft-20b-svg](https://replicate.com/recraft-ai/recraft-20b-svg) | Affordable and fast vector images | 201 |
| [idea-research/ram-grounded-sam](https://replicate.com/idea-research/ram-grounded-sam) | A Strong Image Tagging Model with Segment Anything | 199 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 197 |
| [casia-iva-lab/fastsam](https://replicate.com/casia-iva-lab/fastsam) | Fast Segment Anything | 196 |
| [fermatresearch/flux-controlnet-inpaint](https://replicate.com/fermatresearch/flux-controlnet-inpaint) | Run inpainting with Flux, compatible with Canny ControlNet, LoRAs and HyperFlux_8step | 195 |
| [fofr/realvisxl-v3](https://replicate.com/fofr/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 195 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 195 |
| [kwaivgi/kling-lip-sync](https://replicate.com/kwaivgi/kling-lip-sync) | Add lip-sync to any video with an audio file or text | 188 |
| [delta-lock/noobai-xl](https://replicate.com/delta-lock/noobai-xl) | Models fine-tuned from NoobAI-XL/Illustrious-XL series. | 188 |
| [twn39/lama](https://replicate.com/twn39/lama) | 🦙 LaMa Image Inpainting, Resolution-robust Large Mask Inpainting with Fourier Convolutions, WACV 2022 | 188 |
| [lucataco/ltx-video-0.9.8-distilled](https://replicate.com/lucataco/ltx-video-0.9.8-distilled) | Generate native long-form video, with controllability | 187 |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 186 |
| [runwayml/gen4-turbo](https://replicate.com/runwayml/gen4-turbo) | Generate 5s and 10s 720p videos fast | 182 |
| [xinntao/esrgan](https://replicate.com/xinntao/esrgan) | Image 4x super-resolution | 182 |
| [ndreca/hunyuan3d-2.1](https://replicate.com/ndreca/hunyuan3d-2.1) | [Quality Mode] Scaling Diffusion Models for High Resolution Textured 3D Assets Generation | 179 |
| [aaronaftab/mirage-ghibli](https://replicate.com/aaronaftab/mirage-ghibli) | Ghiblify any image, 10x cheaper/faster than GPT 4o | 177 |
| [anthropic/claude-3.5-sonnet](https://replicate.com/anthropic/claude-3.5-sonnet) | Anthropic's most intelligent language model to date, with a 200K token context window and image understanding (claude-3-5-sonnet-20241022) | 174 |
| [bria/expand-image](https://replicate.com/bria/expand-image) | Bria Expand expands images beyond their borders in high quality. Resizing the image by generating new pixels to expand to the desired aspect ratio. Trained exclusively on licensed data for safe and risk-free commercial use | 170 |
| [rhelsing/basic-pitch](https://replicate.com/rhelsing/basic-pitch) | Spotify's Basic Pitch Model | 170 |
| [sljeff/dots.ocr](https://replicate.com/sljeff/dots.ocr) | https://github.com/sljeff/dots-ocr-client | 169 |
| [cszn/scunet](https://replicate.com/cszn/scunet) | Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis | 169 |
| [flux-kontext-apps/text-removal](https://replicate.com/flux-kontext-apps/text-removal) | Remove all text from an image with FLUX.1 Kontext | 167 |
| [mtg/essentia-bpm](https://replicate.com/mtg/essentia-bpm) | Tempo BPM estimation with Essentia | 165 |
| [bria/increase-resolution](https://replicate.com/bria/increase-resolution) | Bria Increase resolution upscales the resolution of any image. It increases resolution using a dedicated upscaling method that preserves the original image content without regeneration. | 160 |
| [aisha-ai-official/pony-realism-v2.2](https://replicate.com/aisha-ai-official/pony-realism-v2.2) | null | 157 |
| [qwen/qwen3-235b-a22b-instruct-2507](https://replicate.com/qwen/qwen3-235b-a22b-instruct-2507) | Updated Qwen3 model for instruction following | 156 |
| [littlemonsterzhang/wai90_sdxl](https://replicate.com/littlemonsterzhang/wai90_sdxl) | WAI-NSFW-illustrious-SDXL  v.90 | 155 |
| [adirik/t2i-adapter-sdxl-canny](https://replicate.com/adirik/t2i-adapter-sdxl-canny) | Modify images using canny edges | 155 |
| [prunaai/vace-14b](https://replicate.com/prunaai/vace-14b) | This is a faster VACE-14B model, optimised with pruna, contact us for more at pruna.ai | 153 |
| [okaris/live-portrait](https://replicate.com/okaris/live-portrait) | null | 150 |
| [microsoft/phi-3-mini-4k-instruct](https://replicate.com/microsoft/phi-3-mini-4k-instruct) | Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets | 150 |
| [easel/ai-avatars](https://replicate.com/easel/ai-avatars) | Use one or two face images to create AI avatars | 148 |
| [lucataco/nsfw_video_detection](https://replicate.com/lucataco/nsfw_video_detection) | FalconAIs NSFW detection model, extended for videos | 148 |
| [datacte/flux-aesthetic-anime](https://replicate.com/datacte/flux-aesthetic-anime) | Flux lora, trained on the unique style and aesthetic of ghibli retro anime | 145 |
| [bytedance/bagel](https://replicate.com/bytedance/bagel) | 🥯ByteDance Seed's Bagel Unified multimodal AI that generates images, edits images, and understands images in one 7B parameter model🥯 | 144 |
| [stability-ai/stable-diffusion-3.5-medium](https://replicate.com/stability-ai/stable-diffusion-3.5-medium) | 2.5 billion parameter image model with improved MMDiT-X architecture | 140 |
| [asiryan/unlimited-xl](https://replicate.com/asiryan/unlimited-xl) | Unlimited XL Model (Text2Img, Img2Img and Inpainting) | 138 |
| [cjwbw/sadtalker](https://replicate.com/cjwbw/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 137 |
| [tencent/hunyuan3d-2mv](https://replicate.com/tencent/hunyuan3d-2mv) | Hunyuan3D-2mv is finetuned from Hunyuan3D-2 to support multiview controlled shape generation. | 135 |
| [minimax/video-01-live](https://replicate.com/minimax/video-01-live) | An image-to-video (I2V) model specifically trained for Live2D and general animation use cases | 134 |
| [bria/generate-background](https://replicate.com/bria/generate-background) | Bria Background Generation allows for efficient swapping of backgrounds in images via text prompts or reference image, delivering realistic and polished results. Trained exclusively on licensed data for safe and risk-free commercial use | 133 |
| [snowflake/snowflake-arctic-instruct](https://replicate.com/snowflake/snowflake-arctic-instruct) | An efficient, intelligent, and truly open-source language model | 133 |
| [lucataco/realistic-vision-v5](https://replicate.com/lucataco/realistic-vision-v5) | Realistic Vision v5.0 with VAE | 132 |
| [lucataco/hermes-2-pro-llama-3-8b](https://replicate.com/lucataco/hermes-2-pro-llama-3-8b) | Hermes 2 Pro is an updated and cleaned version of the OpenHermes 2.5 Dataset, as well as a newly introduced Function Calling and JSON Mode dataset developed in-house | 131 |
| [fofr/kontext-make-person-real](https://replicate.com/fofr/kontext-make-person-real) | A FLUX Kontext fine-tune to fix plastic AI skin textures | 130 |
| [meta/llama-2-13b-chat](https://replicate.com/meta/llama-2-13b-chat) | A 13 billion parameter language model from Meta, fine tuned for chat completions | 129 |
| [tstramer/material-diffusion](https://replicate.com/tstramer/material-diffusion) | Stable diffusion fork for generating tileable outputs using v1.5 model | 129 |
| [cjwbw/bigcolor](https://replicate.com/cjwbw/bigcolor) | Colorization using a Generative Color Prior for Natural Images | 128 |
| [lucataco/animate-diff](https://replicate.com/lucataco/animate-diff) | Animate Your Personalized Text-to-Image Diffusion Models | 127 |
| [pixverse/pixverse-v4](https://replicate.com/pixverse/pixverse-v4) | Quickly generate smooth 5s or 8s videos at 540p, 720p or 1080p | 126 |
| [fofr/wan2.1-with-lora](https://replicate.com/fofr/wan2.1-with-lora) | Run Wan2.1 14b or 1.3b with a lora | 125 |
| [miike-ai/flux-ico](https://replicate.com/miike-ai/flux-ico) | Create beautiful icons & emojis | 125 |
| [black-forest-labs/flux-redux-dev](https://replicate.com/black-forest-labs/flux-redux-dev) | Open-weight image variation model. Create new versions while preserving key elements of your original. | 123 |
| [lucataco/dreamshaper-xl-lightning](https://replicate.com/lucataco/dreamshaper-xl-lightning) | dreamshaper-xl-lightning is a Stable Diffusion model that has been fine-tuned on SDXL | 123 |
| [okaris/omni-zero-couples](https://replicate.com/okaris/omni-zero-couples) | Omni-Zero Couples: A diffusion pipeline for zero-shot stylized couples portrait creation. | 120 |
| [ndreca/hunyuan3d-2](https://replicate.com/ndreca/hunyuan3d-2) | [Turbo Mode] Scaling Diffusion Models for High Resolution Textured 3D Assets Generation | 119 |
| [shanginn/supir](https://replicate.com/shanginn/supir) | null | 117 |
| [fermatresearch/high-resolution-controlnet-tile](https://replicate.com/fermatresearch/high-resolution-controlnet-tile) | UPDATE: new upscaling algorithm for a much improved image quality. Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination. | 116 |
| [google-deepmind/gemma-3-27b-it](https://replicate.com/google-deepmind/gemma-3-27b-it) | Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models. | 110 |
| [lucataco/video-merge](https://replicate.com/lucataco/video-merge) | Simple tool to merge together separate video snippets | 107 |
| [black-forest-labs/flux-pro-finetuned](https://replicate.com/black-forest-labs/flux-pro-finetuned) | Inference model for FLUX.1 [pro] using custom `finetune_id` | 107 |
| [jschoormans/comfyui-interior-remodel](https://replicate.com/jschoormans/comfyui-interior-remodel) | Interior remodelling, keeps windows, ceilings, and doors. Uses a depth controlnet weighted to ignore existing furniture. | 107 |
| [fottoai/remove-bg-2](https://replicate.com/fottoai/remove-bg-2) | Remove image background with custom model to better result. | 106 |
| [fofr/tooncrafter](https://replicate.com/fofr/tooncrafter) | Create videos from illustrated input images | 106 |
| [codehappynice/codemusic](https://replicate.com/codehappynice/codemusic) | The current model is used for graphics replacement processing | 105 |
| [fictions-ai/autocaption](https://replicate.com/fictions-ai/autocaption) | Automatically add captions to a video | 105 |
| [nandycc/sdxl-app-icons](https://replicate.com/nandycc/sdxl-app-icons) | Fine tuned to generate awesome app icons, by aistartupkit.com | 105 |
| [zsxkib/blip-3](https://replicate.com/zsxkib/blip-3) | Blip 3 / XGen-MM, Answers questions about images ({blip3,xgen-mm}-phi3-mini-base-r-v1) | 104 |
| [adirik/t2i-adapter-sdxl-depth-midas](https://replicate.com/adirik/t2i-adapter-sdxl-depth-midas) | Modify images using depth maps | 103 |
