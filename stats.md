# Model Stats
## New Models
- https://replicate.com/fofr/flux-black-sclera
- https://replicate.com/tiziisa93/ai-yellowdress
- https://replicate.com/mchamoudadev/james_31_1000k
- https://replicate.com/tiziisa93/ai-lilyblossom
- https://replicate.com/diyomatalo/diyo
- https://replicate.com/tiziisa93/ai-pinkdress
- https://replicate.com/0xdeadd/kamala
- https://replicate.com/hartmamt/randall
- https://replicate.com/dcamsdev/childify-nestle-flux
- https://replicate.com/marloes90/fiersmarloes2
- https://replicate.com/zf-kbot/sd-inpaint
- https://replicate.com/programmerarpoolen/gentia

## Removed Models
- https://replicate.com/nicknaskida/whisper-diarization
- https://replicate.com/zerlowin/air_france_posters
- https://replicate.com/zerlowin/air_france
- https://replicate.com/jd7h/xmem-propainter-inpainting

## Rising Stars
| Model | Description | Runs Today | Runs Total | % of Total |
|-------|-------------|------------|------------|------------|
| [fofr/flux-black-sclera](https://replicate.com/fofr/flux-black-sclera) | null | 36 | 36 | 100.00% |
| [tiziisa93/ai-yellowdress](https://replicate.com/tiziisa93/ai-yellowdress) | null | 30 | 30 | 100.00% |
| [mchamoudadev/james_31_1000k](https://replicate.com/mchamoudadev/james_31_1000k) | null | 37 | 37 | 100.00% |
| [tiziisa93/ai-lilyblossom](https://replicate.com/tiziisa93/ai-lilyblossom) | null | 38 | 38 | 100.00% |
| [diyomatalo/diyo](https://replicate.com/diyomatalo/diyo) | null | 90 | 90 | 100.00% |
| [tiziisa93/ai-pinkdress](https://replicate.com/tiziisa93/ai-pinkdress) | null | 34 | 34 | 100.00% |
| [0xdeadd/kamala](https://replicate.com/0xdeadd/kamala) | A fine-tuned FLUX.1 model | 16 | 16 | 100.00% |
| [hartmamt/randall](https://replicate.com/hartmamt/randall) | null | 36 | 36 | 100.00% |
| [dcamsdev/childify-nestle-flux](https://replicate.com/dcamsdev/childify-nestle-flux) | Creates child version of you | 35 | 35 | 100.00% |
| [marloes90/fiersmarloes2](https://replicate.com/marloes90/fiersmarloes2) | null | 46 | 46 | 100.00% |
| [zf-kbot/sd-inpaint](https://replicate.com/zf-kbot/sd-inpaint) | Fill in masked parts of images with Stable Diffusion | 791206 | 791206 | 100.00% |
| [programmerarpoolen/gentia](https://replicate.com/programmerarpoolen/gentia) | Produces images of Tia | 62 | 62 | 100.00% |
| [hexiaochun/img2video](https://replicate.com/hexiaochun/img2video) | ËæìÂÖ•ÂõæÁâáÂíåÈü≥È¢ëÂêàÂπ∂ÂÖ≥ÈîÆÂ∏ßËßÜÈ¢ë | 118 | 126 | 93.65% |
| [omarprama/xot-batch-8](https://replicate.com/omarprama/xot-batch-8) | null | 13 | 17 | 76.47% |
| [imjishan/jishanv2](https://replicate.com/imjishan/jishanv2) | null | 22 | 35 | 62.86% |
| [treebridge83/luke-lora](https://replicate.com/treebridge83/luke-lora) | null | 23 | 38 | 60.53% |
| [crivera/sketch-lora](https://replicate.com/crivera/sketch-lora) | Create pencil sketches of anything | 28 | 47 | 59.57% |
| [hexiaochun/video_merge](https://replicate.com/hexiaochun/video_merge) | ËßÜÈ¢ëÂêàÂπ∂ | 15 | 29 | 51.72% |
| [kazdatahelp/azhrq](https://replicate.com/kazdatahelp/azhrq) | null | 12 | 26 | 46.15% |
| [samsa-ai/flux-grainy-retro](https://replicate.com/samsa-ai/flux-grainy-retro) | Flux lora, use "grainyr3tro style illustration" as trigger | 12 | 27 | 44.44% |
| [bsandmg/coachp](https://replicate.com/bsandmg/coachp) | Model for the creation of Coach P | 18 | 41 | 43.90% |
| [0xtuba/archillect-lora](https://replicate.com/0xtuba/archillect-lora) | Generates images in the style of Archillect | 841 | 1935 | 43.46% |
| [fofr/flux-fruit-head](https://replicate.com/fofr/flux-fruit-head) | null | 5 | 12 | 41.67% |
| [juliananev/frutiger-aero](https://replicate.com/juliananev/frutiger-aero) | null | 123 | 308 | 39.94% |
| [lucataco/gemma2-9b-it](https://replicate.com/lucataco/gemma2-9b-it) | Google's Gemma2 9b instruct model | 302 | 850 | 35.53% |
| [treebridge83/luke-lora-2](https://replicate.com/treebridge83/luke-lora-2) | A model trained on images of Luke.  Use the word LucasM to ask for a photo of Luke. | 16 | 47 | 34.04% |
| [vipersona20002/malek](https://replicate.com/vipersona20002/malek) | null | 3 | 9 | 33.33% |
| [levelsio/neon-tokyo](https://replicate.com/levelsio/neon-tokyo) | Take photos in the style of rainy Tokyo nights with neon lights | 631 | 1923 | 32.81% |
| [zsxkib/aura-sr-v2](https://replicate.com/zsxkib/aura-sr-v2) | AuraSR v2: Second-gen GAN-based Super-Resolution for real-world applications | 290 | 913 | 31.76% |
| [simonheese/flux-thefinger](https://replicate.com/simonheese/flux-thefinger) | For my AI punk band The Buttredettes I wanted the option to generate images where they show the finger. This gesture is either censored in all major models or not trained. This lora should fix it. It's not working all the time, but more often than not. | 39 | 127 | 30.71% |
| [lucataco/flux-vlta](https://replicate.com/lucataco/flux-vlta) | A Flux finetune of an AI character named: Violeta | 111 | 365 | 30.41% |
| [mandelavybe/jungkook](https://replicate.com/mandelavybe/jungkook) | null | 76 | 253 | 30.04% |
| [dunaevai135/tst_agt](https://replicate.com/dunaevai135/tst_agt) | null | 38 | 127 | 29.92% |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 1184 | 4008 | 29.54% |
| [0xdeadd/bijay](https://replicate.com/0xdeadd/bijay) | A fine-tuned FLUX.1 model | 5 | 18 | 27.78% |
| [buovier94/flux_stevenespinoza](https://replicate.com/buovier94/flux_stevenespinoza) | null | 27 | 98 | 27.55% |
| [myaiteam2/website-scrapper](https://replicate.com/myaiteam2/website-scrapper) | Just some good ole beautifulsoup scrapping URL magic. (some sites don't work as they block scrapping, but still useful) | 3431 | 14435 | 23.77% |
| [roelfrenkema/flux1.lora.elonmusk](https://replicate.com/roelfrenkema/flux1.lora.elonmusk) | Dope brain malfunction. | 3 | 14 | 21.43% |
| [roberthein/modelname-new](https://replicate.com/roberthein/modelname-new) | null | 19 | 95 | 20.00% |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | 8-step-lora-and-canny-controlnet > more are coming soon | 388 | 1981 | 19.59% |
| [lucataco/flux-time100](https://replicate.com/lucataco/flux-time100) | Flux finetune of the style: TIMES 100 Most Influential People in AI | 47 | 247 | 19.03% |
| [apolinario/flux-tarot-v1](https://replicate.com/apolinario/flux-tarot-v1) | Flux lora, use "in the style of TOK a trtcrd tarot style" to trigger image generation | 437 | 2298 | 19.02% |
| [datacte/flux-aesthetic-anime](https://replicate.com/datacte/flux-aesthetic-anime) | Flux lora, trained on the unique style and aesthetic of ghibli retro anime | 44 | 235 | 18.72% |
| [jfobrien29/flux-us-national-parks](https://replicate.com/jfobrien29/flux-us-national-parks) | Generate photos like old school US National Park Posters | 7 | 42 | 16.67% |
| [hexiaochun/video2mp3](https://replicate.com/hexiaochun/video2mp3) | ÊèêÂèñËßÜÈ¢ë‰∏≠ÁöÑÈü≥È¢ë | 2 | 12 | 16.67% |
| [therendercafe/therendercafegmailcom-sarahi-2595](https://replicate.com/therendercafe/therendercafegmailcom-sarahi-2595) | A fine-tuned FLUX.1 model | 11 | 72 | 15.28% |
| [afterpeak/flux-slowed](https://replicate.com/afterpeak/flux-slowed) | Flux LORA to generate images in the style of the arworks used for sowed versions of a song | 31 | 209 | 14.83% |
| [hexiaochun/minicpm_v26](https://replicate.com/hexiaochun/minicpm_v26) | minicpm ËßÜÈ¢ëÁêÜËß£ | 8 | 56 | 14.29% |
| [bingbangboom-lab/flux-mix-reality](https://replicate.com/bingbangboom-lab/flux-mix-reality) | Flux lora, use "HIHP style" to trigger generation | 13 | 91 | 14.29% |
| [zsxkib/whisper-lazyloading](https://replicate.com/zsxkib/whisper-lazyloading) | Convert speech in audio to text w/ `tiny`, `small`, `base`, and `large-v3` models | 5 | 35 | 14.29% |

## Active Models
| Model | Description | Runs in the last day |
|-------|-------------|---------------------|
| [bytedance/sdxl-lightning-4step](https://replicate.com/bytedance/sdxl-lightning-4step) | SDXL-Lightning by ByteDance: a fast text-to-image model that makes high-quality images in 4 steps | 2455037 |
| [black-forest-labs/flux-schnell](https://replicate.com/black-forest-labs/flux-schnell) | The fastest image generation model tailored for local development and personal use | 1142410 |
| [zf-kbot/sd-inpaint](https://replicate.com/zf-kbot/sd-inpaint) | Fill in masked parts of images with Stable Diffusion | 791206 |
| [falcons-ai/nsfw_image_detection](https://replicate.com/falcons-ai/nsfw_image_detection) | Fine-Tuned Vision Transformer (ViT) for NSFW Image Classification | 259051 |
| [openai/whisper](https://replicate.com/openai/whisper) | Convert speech in audio to text | 156707 |
| [meta/meta-llama-3-70b-instruct](https://replicate.com/meta/meta-llama-3-70b-instruct) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 153635 |
| [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct) | An 8 billion parameter language model from Meta, fine tuned for chat completions | 125492 |
| [stability-ai/sdxl](https://replicate.com/stability-ai/sdxl) | A text-to-image generative AI model that creates beautiful images | 124189 |
| [salesforce/blip](https://replicate.com/salesforce/blip) | Generate image captions | 112473 |
| [black-forest-labs/flux-pro](https://replicate.com/black-forest-labs/flux-pro) | State-of-the-art image generation with top of the line prompt following, visual quality, image detail and output diversity. | 98787 |
| [andreasjansson/clip-features](https://replicate.com/andreasjansson/clip-features) | Return CLIP features for the clip-vit-large-patch14 model | 52446 |
| [tencentarc/gfpgan](https://replicate.com/tencentarc/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 42513 |
| [andreasjansson/blip-2](https://replicate.com/andreasjansson/blip-2) | Answers questions about images | 39353 |
| [meta/llama-2-7b-chat](https://replicate.com/meta/llama-2-7b-chat) | A 7 billion parameter language model from Meta, fine tuned for chat completions | 35520 |
| [nightmareai/real-esrgan](https://replicate.com/nightmareai/real-esrgan) | Real-ESRGAN with optional face correction and adjustable upscale | 35518 |
| [lucataco/hyper-flux-8step](https://replicate.com/lucataco/hyper-flux-8step) | Hyper FLUX 8-step by ByteDance | 33801 |
| [yorickvp/llava-13b](https://replicate.com/yorickvp/llava-13b) | Visual instruction tuning towards large language and vision models with GPT-4 level capabilities | 32650 |
| [datacte/proteus-v0.2](https://replicate.com/datacte/proteus-v0.2) | Proteus v0.2 shows subtle yet significant improvements over Version 0.1. It demonstrates enhanced prompt understanding that surpasses MJ6, while also approaching its stylistic capabilities. | 32250 |
| [black-forest-labs/flux-dev](https://replicate.com/black-forest-labs/flux-dev) | A 12 billion parameter rectified flow transformer capable of generating images from text descriptions | 27962 |
| [xinntao/gfpgan](https://replicate.com/xinntao/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* | 26690 |
| [meta/meta-llama-3.1-405b-instruct](https://replicate.com/meta/meta-llama-3.1-405b-instruct) | Meta's flagship 405 billion parameter language model, fine-tuned for chat completions | 25110 |
| [lucataco/realistic-vision-v5.1](https://replicate.com/lucataco/realistic-vision-v5.1) | Implementation of Realistic Vision v5.1 with VAE | 23411 |
| [philz1337x/clarity-upscaler](https://replicate.com/philz1337x/clarity-upscaler) | High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x | 21874 |
| [datacte/proteus-v0.3](https://replicate.com/datacte/proteus-v0.3) | ProteusV0.3: The Anime Update | 20633 |
| [lucataco/flux-dev-lora](https://replicate.com/lucataco/flux-dev-lora) | FLUX.1-Dev LoRA explorer | 18671 |
| [sczhou/codeformer](https://replicate.com/sczhou/codeformer) | Robust face restoration algorithm for old photos / AI-generated faces | 18310 |
| [daanelson/real-esrgan-a100](https://replicate.com/daanelson/real-esrgan-a100) | Real-ESRGAN for image upscaling on an A100 | 16325 |
| [vaibhavs10/incredibly-fast-whisper](https://replicate.com/vaibhavs10/incredibly-fast-whisper) | whisper-large-v3, incredibly fast, powered by Hugging Face Transformers! ü§ó | 16169 |
| [shefa/turbo-enigma](https://replicate.com/shefa/turbo-enigma) | SDXL based text-to-image model applying Distribution Matching Distillation, supporting zero-shot identity generation in 2-5s. https://ai-visionboard.com | 14642 |
| [lucataco/remove-bg](https://replicate.com/lucataco/remove-bg) | Remove background from an image | 14605 |
| [mejiabrayan/logoai](https://replicate.com/mejiabrayan/logoai) | null | 12879 |
| [playgroundai/playground-v2.5-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2.5-1024px-aesthetic) | Playground v2.5 is the state-of-the-art open-source model in aesthetic quality | 11926 |
| [cjwbw/rembg](https://replicate.com/cjwbw/rembg) | Remove images background | 11742 |
| [lucataco/juggernaut-xl-v9](https://replicate.com/lucataco/juggernaut-xl-v9) | Juggernaut XL v9 | 11716 |
| [stability-ai/stable-diffusion-inpainting](https://replicate.com/stability-ai/stable-diffusion-inpainting) | Fill in masked parts of images with Stable Diffusion | 11566 |
| [mistralai/mixtral-8x7b-instruct-v0.1](https://replicate.com/mistralai/mixtral-8x7b-instruct-v0.1) | The Mixtral-8x7B-instruct-v0.1 Large Language Model (LLM) is a pretrained generative Sparse Mixture of Experts tuned to be a helpful assistant. | 11392 |
| [smoretalk/clip-interrogator-turbo](https://replicate.com/smoretalk/clip-interrogator-turbo) | @pharmapsychotic 's CLIP-Interrogator, but 3x faster and more accurate. Specialized on SDXL. | 10280 |
| [fofr/sdxl-emoji](https://replicate.com/fofr/sdxl-emoji) | An SDXL fine-tune based on Apple Emojis | 9204 |
| [smoretalk/rembg-enhance](https://replicate.com/smoretalk/rembg-enhance) | A background removal model enhanced with ViTMatte. | 9140 |
| [omniedgeio/face-swap](https://replicate.com/omniedgeio/face-swap) | Face Swap | 8591 |
| [beautyyuyanli/multilingual-e5-large](https://replicate.com/beautyyuyanli/multilingual-e5-large) | multilingual-e5-large: A multi-language text embedding model | 8536 |
| [allenhooo/lama](https://replicate.com/allenhooo/lama) | ü¶ô LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions | 7697 |
| [cjwbw/animagine-xl-3.1](https://replicate.com/cjwbw/animagine-xl-3.1) | Anime-themed text-to-image stable diffusion model | 7342 |
| [fofr/consistent-character](https://replicate.com/fofr/consistent-character) | Create images of a given character in different poses | 6846 |
| [zsxkib/pulid](https://replicate.com/zsxkib/pulid) | üìñ PuLID: Pure and Lightning ID Customization via Contrastive Alignment | 6525 |
| [cjwbw/clip-vit-large-patch14](https://replicate.com/cjwbw/clip-vit-large-patch14) | openai/clip-vit-large-patch14 with Transformers | 6523 |
| [pharmapsychotic/clip-interrogator](https://replicate.com/pharmapsychotic/clip-interrogator) | The CLIP Interrogator is a prompt engineering tool that combines OpenAI's CLIP and Salesforce's BLIP to optimize text prompts to match a given image. Use the resulting prompts with text-to-image models like Stable Diffusion to create cool art! | 6398 |
| [snowflake/snowflake-arctic-instruct](https://replicate.com/snowflake/snowflake-arctic-instruct) | An efficient, intelligent, and truly open-source language model | 6187 |
| [xiankgx/face-swap](https://replicate.com/xiankgx/face-swap) | null | 5526 |
| [lucataco/flux-dev-multi-lora](https://replicate.com/lucataco/flux-dev-multi-lora) | FLUX.1-Dev Multi LoRA Explorer | 5482 |
| [lucataco/sdxl-inpainting](https://replicate.com/lucataco/sdxl-inpainting) | SDXL Inpainting developed by the HF Diffusers team | 5454 |
| [stability-ai/stable-diffusion-3](https://replicate.com/stability-ai/stable-diffusion-3) | A text-to-image model with greatly improved performance in image quality, typography, complex prompt understanding, and resource-efficiency | 5394 |
| [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b) | Base version of Llama 3, an 8 billion parameter language model from Meta. | 5011 |
| [m1guelpf/nsfw-filter](https://replicate.com/m1guelpf/nsfw-filter) | Run any image through the Stable Diffusion content filter | 4650 |
| [replicate/all-mpnet-base-v2](https://replicate.com/replicate/all-mpnet-base-v2) | This is a language model that can be used to obtain document embeddings suitable for downstream tasks like semantic search and clustering. | 4604 |
| [fofr/realvisxl-v3-multi-controlnet-lora](https://replicate.com/fofr/realvisxl-v3-multi-controlnet-lora) | RealVisXl V3 with multi-controlnet, lora loading, img2img, inpainting | 4587 |
| [tencentarc/photomaker](https://replicate.com/tencentarc/photomaker) | Create photos, paintings and avatars for anyone in any style within seconds. | 4505 |
| [shreejalmaharjan-27/website-screenshot](https://replicate.com/shreejalmaharjan-27/website-screenshot) | Capture a website screenshot | 4471 |
| [asiryan/reliberate-v3](https://replicate.com/asiryan/reliberate-v3) | Reliberate v3 Model (Text2Img, Img2Img and Inpainting) | 4348 |
| [tencentarc/photomaker-style](https://replicate.com/tencentarc/photomaker-style) | Create photos, paintings and avatars for anyone in any style within seconds.  (Stylization version) | 4283 |
| [meta/llama-2-70b-chat](https://replicate.com/meta/llama-2-70b-chat) | A 70 billion parameter language model from Meta, fine tuned for chat completions | 4127 |
| [smoosh-sh/baby-mystic](https://replicate.com/smoosh-sh/baby-mystic) | Implementation of Realistic Vision v5.1 to conjure up images of the potential baby using a single photo from each parent | 4119 |
| [mchong6/jojogan](https://replicate.com/mchong6/jojogan) | JoJoGAN: One Shot Face Stylization | 4081 |
| [thomasmol/whisper-diarization](https://replicate.com/thomasmol/whisper-diarization) | ‚ö°Ô∏è Fast audio transcription | whisper large-v3 | speaker diarization | word & sentence level timestamps | prompt | hotwords | 3797 |
| [cjwbw/zoedepth](https://replicate.com/cjwbw/zoedepth) | ZoeDepth: Combining relative and metric depth | 3667 |
| [fofr/face-to-many](https://replicate.com/fofr/face-to-many) | Turn a face into 3D, emoji, pixel art, video game, claymation or toy | 3634 |
| [vetkastar/fooocus](https://replicate.com/vetkastar/fooocus) | Image generation, Added: inpaint_strength loras_custom_urls | 3593 |
| [xlabs-ai/flux-dev-realism](https://replicate.com/xlabs-ai/flux-dev-realism) | FLUX.1-dev with XLabs-AI‚Äôs realism lora | 3586 |
| [myaiteam2/website-scrapper](https://replicate.com/myaiteam2/website-scrapper) | Just some good ole beautifulsoup scrapping URL magic. (some sites don't work as they block scrapping, but still useful) | 3431 |
| [swook/inspyrenet](https://replicate.com/swook/inspyrenet) | Segment foreground objects with high resolution and matting, using InSPyReNet | 3408 |
| [victor-upmeet/whisperx](https://replicate.com/victor-upmeet/whisperx) | Accelerated transcription, word-level timestamps and diarization with whisperX large-v3 | 3365 |
| [stability-ai/stable-diffusion](https://replicate.com/stability-ai/stable-diffusion) | A latent text-to-image diffusion model capable of generating photo-realistic images given any text input | 3341 |
| [asiryan/blue-pencil-xl-v2](https://replicate.com/asiryan/blue-pencil-xl-v2) | Blue Pencil XL v2 Model (Text2Img, Img2Img and Inpainting) | 3140 |
| [pnyompen/sd-controlnet-lora](https://replicate.com/pnyompen/sd-controlnet-lora) | SD1.5 Canny controlnet with LoRA support. | 3077 |
| [asiryan/counterfeit-xl-v2](https://replicate.com/asiryan/counterfeit-xl-v2) | Counterfeit XL v2 Model (Text2Img, Img2Img and Inpainting) | 3055 |
| [asiryan/meina-mix-v11](https://replicate.com/asiryan/meina-mix-v11) | Meina Mix V11 Model (Text2Img, Img2Img and Inpainting) | 3046 |
| [asiryan/anything-v4.5](https://replicate.com/asiryan/anything-v4.5) | Anything V4.5 Model (Text2Img, Img2Img and Inpainting) | 3046 |
| [lucataco/sdxl-controlnet](https://replicate.com/lucataco/sdxl-controlnet) | SDXL ControlNet - Canny | 2820 |
| [daanelson/imagebind](https://replicate.com/daanelson/imagebind) | A model for text, audio, and image embeddings in one space | 2747 |
| [chenxwh/depth-anything-v2](https://replicate.com/chenxwh/depth-anything-v2) | Depth estimation with faster inference speed, fewer parameters, and higher depth accuracy. | 2664 |
| [bfirsh/segformer-b0-finetuned-ade-512-512](https://replicate.com/bfirsh/segformer-b0-finetuned-ade-512-512) | null | 2651 |
| [xinntao/realesrgan](https://replicate.com/xinntao/realesrgan) | Practical Image Restoration Algorithms for General/Anime Images | 2470 |
| [okaris/omni-zero](https://replicate.com/okaris/omni-zero) | Omni-Zero: A diffusion pipeline for zero-shot stylized portrait creation. | 2436 |
| [meta/musicgen](https://replicate.com/meta/musicgen) | Generate music from a prompt or melody | 2425 |
| [lucataco/flux-schnell-lora](https://replicate.com/lucataco/flux-schnell-lora) | FLUX.1-Schnell LoRA explorer | 2413 |
| [meta/meta-llama-3-70b](https://replicate.com/meta/meta-llama-3-70b) | Base version of Llama 3, a 70 billion parameter language model from Meta. | 2376 |
| [usamaehsan/controlnet-1.1-x-realistic-vision-v2.0](https://replicate.com/usamaehsan/controlnet-1.1-x-realistic-vision-v2.0) | controlnet 1.1 lineart x realistic-vision-v2.0 (updated to v5) | 2360 |
| [mistralai/mistral-7b-instruct-v0.2](https://replicate.com/mistralai/mistral-7b-instruct-v0.2) | The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of Mistral-7B-Instruct-v0.1. | 2354 |
| [fofr/sticker-maker](https://replicate.com/fofr/sticker-maker) | Make stickers with AI. Generates graphics with transparent backgrounds. | 2336 |
| [135arvin/my_comfyui](https://replicate.com/135arvin/my_comfyui) | Run comfyui with api | 2330 |
| [tomasmcm/llamaguard-7b](https://replicate.com/tomasmcm/llamaguard-7b) | Source: llamas-community/LlamaGuard-7b ‚ú¶ Quant: TheBloke/LlamaGuard-7B-AWQ ‚ú¶ Llama-Guard is a 7B parameter Llama 2-based input-output safeguard model | 2308 |
| [chenxwh/sdxl-flash](https://replicate.com/chenxwh/sdxl-flash) | Fast sdxl with higher quality | 2225 |
| [fofr/style-transfer](https://replicate.com/fofr/style-transfer) | Transfer the style of one image to another | 2117 |
| [xrunda/hello](https://replicate.com/xrunda/hello) | Take a video and replace the face in it with a face of your choice. You only need one image of the desired face. No dataset, no training. | 2047 |
| [cjwbw/real-esrgan](https://replicate.com/cjwbw/real-esrgan) | Real-ESRGAN: Real-World Blind Super-Resolution | 2038 |
| [simbrams/segformer-b5-finetuned-ade-640-640](https://replicate.com/simbrams/segformer-b5-finetuned-ade-640-640) | Semantic Segmentation | 2032 |
| [jagilley/controlnet-hough](https://replicate.com/jagilley/controlnet-hough) | Modify images using M-LSD line detection | 1903 |
| [mark3labs/embeddings-gte-base](https://replicate.com/mark3labs/embeddings-gte-base) | General Text Embeddings (GTE) model. | 1855 |
| [konieshadow/fooocus-api](https://replicate.com/konieshadow/fooocus-api) | Third party Fooocus replicate model | 1854 |
| [batouresearch/sdxl-controlnet-lora](https://replicate.com/batouresearch/sdxl-controlnet-lora) | '''Last update: Now supports img2img.''' SDXL Canny controlnet with LoRA support. | 1766 |
| [ostris/flux-dev-lora-trainer](https://replicate.com/ostris/flux-dev-lora-trainer) | Fine-tune FLUX.1-dev using ai-toolkit | 1749 |
| [cuuupid/idm-vton](https://replicate.com/cuuupid/idm-vton) | Best-in-class clothing virtual try on in the wild (non-commercial use only) | 1675 |
| [bingbangboom-lab/flux-dreamscape](https://replicate.com/bingbangboom-lab/flux-dreamscape) | Flux lora, use "BSstyle004" to trigger image generation | 1647 |
| [cjwbw/anything-v4.0](https://replicate.com/cjwbw/anything-v4.0) | high-quality, highly detailed anime-style Stable Diffusion models | 1643 |
| [ardianfe/music-gen-fn-200e](https://replicate.com/ardianfe/music-gen-fn-200e) | Create music for your content | 1628 |
| [fofr/face-to-sticker](https://replicate.com/fofr/face-to-sticker) | Turn a face into a sticker | 1608 |
| [camenduru/instantmesh](https://replicate.com/camenduru/instantmesh) | InstantMesh: Efficient 3D Mesh Generation from a Single Image with Sparse-view Large Reconstruction Models | 1590 |
| [yorickvp/llava-v1.6-34b](https://replicate.com/yorickvp/llava-v1.6-34b) | LLaVA v1.6: Large Language and Vision Assistant (Nous-Hermes-2-34B) | 1528 |
| [pseudoram/rvc-v2](https://replicate.com/pseudoram/rvc-v2) | Speech to speech with any RVC v2 trained AI voice | 1481 |
| [simbrams/ri](https://replicate.com/simbrams/ri) | Realistic Inpainting with ControlNET (M-LSD + SEG) | 1477 |
| [zsxkib/instant-id](https://replicate.com/zsxkib/instant-id) | Make realistic images of real people instantly | 1452 |
| [zsxkib/ic-light](https://replicate.com/zsxkib/ic-light) | ‚úçÔ∏è‚ú®Prompts to auto-magically relights your images | 1435 |
| [juergengunz/real-esrgan-v2](https://replicate.com/juergengunz/real-esrgan-v2) | Real-ESRGAN Upscale with AI Face Correction | 1411 |
| [pnyompen/sdxl-controlnet-lora-small](https://replicate.com/pnyompen/sdxl-controlnet-lora-small) | SDXL Canny controlnet with LoRA support. | 1389 |
| [zust-ai/supir](https://replicate.com/zust-ai/supir) | null | 1263 |
| [mrhan1993/fooocus-api](https://replicate.com/mrhan1993/fooocus-api) | null | 1258 |
| [adirik/t2i-adapter-sdxl-depth-midas](https://replicate.com/adirik/t2i-adapter-sdxl-depth-midas) | Modify images using depth maps | 1249 |
| [pengdaqian2020/image-tagger](https://replicate.com/pengdaqian2020/image-tagger) | image tagger | 1246 |
| [zylim0702/remove-object](https://replicate.com/zylim0702/remove-object) | The LaMa (Large Mask Inpainting) model is an advanced image inpainting system designed to address the challenges of handling large missing areas, complex geometric structures, and high-resolution images. | 1201 |
| [lucataco/florence-2-large](https://replicate.com/lucataco/florence-2-large) | Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks | 1184 |
| [fofr/any-comfyui-workflow](https://replicate.com/fofr/any-comfyui-workflow) | Run any ComfyUI workflow. Guide: https://github.com/fofr/cog-comfyui | 1181 |
| [shanginn/supir](https://replicate.com/shanginn/supir) | null | 1172 |
| [usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5](https://replicate.com/usamaehsan/controlnet-x-ip-adapter-realistic-vision-v5) | Inpainting || multi-controlnet || single-controlnet || ip-adapter || ip adapter face || ip adapter plus || No ip adapter | 1170 |
| [jagilley/controlnet-scribble](https://replicate.com/jagilley/controlnet-scribble) | Generate detailed images from scribbled drawings | 1168 |
| [meta/llama-2-13b-chat](https://replicate.com/meta/llama-2-13b-chat) | A 13 billion parameter language model from Meta, fine tuned for chat completions | 1139 |
| [lucataco/xtts-v2](https://replicate.com/lucataco/xtts-v2) | Coqui XTTS-v2: Multilingual Text To Speech Voice Cloning | 1070 |
| [mcai/absolutebeauty-v1.0-img2img](https://replicate.com/mcai/absolutebeauty-v1.0-img2img) | Generate a new image from an input image with AbsoluteReality v1.0 | 1045 |
| [playgroundai/playground-v2-1024px-aesthetic](https://replicate.com/playgroundai/playground-v2-1024px-aesthetic) | Playground v2 is a diffusion-based text-to-image generative model trained from scratch by the research team at Playground | 1038 |
| [zf-kbot/photo-to-anime](https://replicate.com/zf-kbot/photo-to-anime) | Convert images to anime style | 1023 |
| [prompthero/openjourney-v4](https://replicate.com/prompthero/openjourney-v4) | SD 1.5 trained with +124k MJv4 images by PromptHero | 1021 |
| [asiryan/juggernaut-xl-v7](https://replicate.com/asiryan/juggernaut-xl-v7) | Juggernaut XL v7 Model (Text2Img, Img2Img and Inpainting) | 1020 |
| [logerzhu/ad-inpaint](https://replicate.com/logerzhu/ad-inpaint) | Product advertising image generator | 1020 |
| [xlabs-ai/flux-dev-controlnet](https://replicate.com/xlabs-ai/flux-dev-controlnet) | XLabs v3 canny, depth and soft edge controlnets for Flux.1 Dev | 995 |
| [rossjillian/controlnet](https://replicate.com/rossjillian/controlnet) | Control diffusion models | 971 |
| [tstramer/material-diffusion](https://replicate.com/tstramer/material-diffusion) | Stable diffusion fork for generating tileable outputs using v1.5 model | 961 |
| [batouresearch/magic-image-refiner](https://replicate.com/batouresearch/magic-image-refiner) | A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling. | 945 |
| [fofr/realvisxl-v3](https://replicate.com/fofr/realvisxl-v3) | Amazing photorealism with RealVisXL_V3.0, based on SDXL, trainable | 938 |
| [philz1337x/controlnet-deliberate](https://replicate.com/philz1337x/controlnet-deliberate) | Modify images with canny edge detection and Deliberate model twitter: @philz1337x | 926 |
| [zylim0702/qr_code_controlnet](https://replicate.com/zylim0702/qr_code_controlnet) | ControlNet QR Code Generator: Simplify QR code creation for various needs using ControlNet's user-friendly neural interface, making integration a breeze. Just key in the url ! | 925 |
| [huage001/adaattn](https://replicate.com/huage001/adaattn) | Arbitrary Neural Style Transfer | 908 |
| [fofr/latent-consistency-model](https://replicate.com/fofr/latent-consistency-model) | Super-fast, 0.6s per image. LCM with img2img, large batching and canny controlnet | 903 |
| [swartype/sdxl-pixar](https://replicate.com/swartype/sdxl-pixar) | Create Pixar poster easily with SDXL Pixar. | 891 |
| [0xtuba/archillect-lora](https://replicate.com/0xtuba/archillect-lora) | Generates images in the style of Archillect | 841 |
| [tgohblio/instant-id-multicontrolnet](https://replicate.com/tgohblio/instant-id-multicontrolnet) | InstantID. ControlNets. More base SDXL models. And the latest ByteDance's ‚ö°Ô∏èSDXL-Lightning !‚ö°Ô∏è | 831 |
| [jingyunliang/swinir](https://replicate.com/jingyunliang/swinir) | Image Restoration Using Swin Transformer | 827 |
| [prompthero/openjourney](https://replicate.com/prompthero/openjourney) | Stable Diffusion fine tuned on Midjourney v4 images. | 824 |
| [hnesk/whisper-wordtimestamps](https://replicate.com/hnesk/whisper-wordtimestamps) | openai/whisper with exposed settings for word_timestamps | 823 |
| [yuval-alaluf/sam](https://replicate.com/yuval-alaluf/sam) | Only a Matter of Style: Age Transformation Using a Style-Based Regression Model | 803 |
| [konieshadow/fooocus-api-anime](https://replicate.com/konieshadow/fooocus-api-anime) | Third party Fooocus replicate model with preset 'anime' | 798 |
| [lucataco/ai-toolkit](https://replicate.com/lucataco/ai-toolkit) | Ostris AI-Toolkit for Flux LoRA Training MVP (Use ostris/flux-dev-lora-trainer) | 774 |
| [fofr/epicrealismxl-lightning-hades](https://replicate.com/fofr/epicrealismxl-lightning-hades) | Fast and high quality lightning model, epiCRealismXL-Lightning Hades | 761 |
| [mixinmax1990/realisitic-vision-v3-inpainting](https://replicate.com/mixinmax1990/realisitic-vision-v3-inpainting) | Realistic Vision V3.0 Inpainting | 757 |
| [peter65374/sam-vit](https://replicate.com/peter65374/sam-vit) | SAM(Segment Anything) ViT-H image encoder | 729 |
| [adirik/interior-design](https://replicate.com/adirik/interior-design) | Realistic interior design with text and image inputs | 726 |
| [juergengunz/ultimate-portrait-upscale](https://replicate.com/juergengunz/ultimate-portrait-upscale) | Upscale Portrait Images with ControlNet Tile | 707 |
| [lucataco/ssd-1b](https://replicate.com/lucataco/ssd-1b) | Segmind Stable Diffusion Model (SSD-1B) is a distilled 50% smaller version of SDXL, offering a 60% speedup while maintaining high-quality text-to-image generation capabilities | 707 |
| [jagilley/controlnet-depth2img](https://replicate.com/jagilley/controlnet-depth2img) | Modify images using depth maps | 706 |
| [mserro/upscaler-pro](https://replicate.com/mserro/upscaler-pro) | AI Photorealistic Image Ultra-Resolution, Restoration and Upscale! | 684 |
| [mcai/deliberate-v2](https://replicate.com/mcai/deliberate-v2) | Generate a new image given any input text with Deliberate v2 | 665 |
| [mcai/babes-v2.0-img2img](https://replicate.com/mcai/babes-v2.0-img2img) | Generate a new image from an input image with Babes 2.0 | 657 |
| [zsxkib/realistic-voice-cloning](https://replicate.com/zsxkib/realistic-voice-cloning) | Create song covers with any RVC v2 trained AI voice from audio files. | 648 |
| [meta/meta-llama-guard-2-8b](https://replicate.com/meta/meta-llama-guard-2-8b) | A llama-3 based moderation and safeguarding language model | 641 |
| [levelsio/neon-tokyo](https://replicate.com/levelsio/neon-tokyo) | Take photos in the style of rainy Tokyo nights with neon lights | 631 |
| [catacolabs/sdxl-ad-inpaint](https://replicate.com/catacolabs/sdxl-ad-inpaint) | Product advertising image generator using SDXL | 622 |
| [nateraw/video-llava](https://replicate.com/nateraw/video-llava) | Video-LLaVA: Learning United Visual Representation by Alignment Before Projection | 596 |
| [mcai/edge-of-realism-v2.0-img2img](https://replicate.com/mcai/edge-of-realism-v2.0-img2img) | Generate a new image from an input image with Edge Of Realism - EOR v2.0 | 584 |
| [cjwbw/midas](https://replicate.com/cjwbw/midas) | Robust Monocular Depth Estimation | 581 |
| [wolverinn/realistic-background](https://replicate.com/wolverinn/realistic-background) | replace background with Stable Diffusion and ControlNet | 573 |
| [chigozienri/mediapipe-face](https://replicate.com/chigozienri/mediapipe-face) | batch or individual face detection with mediapipe | 565 |
| [tgohblio/instant-id-albedobase-xl](https://replicate.com/tgohblio/instant-id-albedobase-xl) | InstantID : Zero-shot Identity-Preserving Generation in Seconds with ‚ö°Ô∏èLCM-LoRA‚ö°Ô∏è. Using AlbedoBase-XL v2.0 as base model. | 563 |
| [cjwbw/supir](https://replicate.com/cjwbw/supir) | Practicing Model Scaling for Photo-Realistic Image Restoration In the Wild. This version uses LLaVA-13b for captioning. | 556 |
| [fofr/sdxl-fresh-ink](https://replicate.com/fofr/sdxl-fresh-ink) | SDXL fine-tuned on photos of freshly inked tattoos | 556 |
| [fofr/become-image](https://replicate.com/fofr/become-image) | Adapt any picture of a face into another image | 538 |
| [sdsgitaccount/flux-gmoveus](https://replicate.com/sdsgitaccount/flux-gmoveus) | Flux lora, use "GMOVEUS" to trigger movement MEME | 533 |
| [fofr/pulid-base](https://replicate.com/fofr/pulid-base) | Use a face to make images. Uses SDXL fine-tuned checkpoints. | 524 |
| [fofr/live-portrait](https://replicate.com/fofr/live-portrait) | Portrait animation using a driving video source | 519 |
| [cuuupid/glm-4v-9b](https://replicate.com/cuuupid/glm-4v-9b) | GLM-4V is a multimodal model released by Tsinghua University that is competitive with GPT-4o and establishes a new SOTA on several benchmarks, including OCR. | 515 |
| [pvitoria/chromagan](https://replicate.com/pvitoria/chromagan) | An Adversarial Approach for Picture Colorization | 505 |
| [microsoft/bringing-old-photos-back-to-life](https://replicate.com/microsoft/bringing-old-photos-back-to-life) | Bringing Old Photos Back to Life | 503 |
| [schananas/grounded_sam](https://replicate.com/schananas/grounded_sam) | Mask prompting based on Grounding DINO & Segment Anything | Integral cog of doiwear.it | 497 |
| [atrifat/hate-speech-detector](https://replicate.com/atrifat/hate-speech-detector) | Detect hate speech or toxic comments in tweets/texts | 484 |
| [piddnad/ddcolor](https://replicate.com/piddnad/ddcolor) | Towards Photo-Realistic Image Colorization via Dual Decoders | 484 |
| [zsxkib/flux-dev-inpainting](https://replicate.com/zsxkib/flux-dev-inpainting) | üé® Fill in masked parts of images with FLUX.1-dev üñåÔ∏è | 473 |
| [batouresearch/high-resolution-controlnet-tile](https://replicate.com/batouresearch/high-resolution-controlnet-tile) | UPDATE: new upscaling algorithm for a much improved image quality. Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination. | 470 |
| [ai-forever/kandinsky-2.2](https://replicate.com/ai-forever/kandinsky-2.2) | multilingual text2image latent diffusion model | 467 |
| [codeplugtech/face-swap](https://replicate.com/codeplugtech/face-swap) | null | 465 |
| [adirik/flux-cinestill](https://replicate.com/adirik/flux-cinestill) | Flux lora, use "CNSTLL" to trigger | 440 |
| [apolinario/flux-tarot-v1](https://replicate.com/apolinario/flux-tarot-v1) | Flux lora, use "in the style of TOK a trtcrd tarot style" to trigger image generation | 437 |
| [timothybrooks/instruct-pix2pix](https://replicate.com/timothybrooks/instruct-pix2pix) | Edit images with human instructions | 416 |
| [lucataco/gfpgan](https://replicate.com/lucataco/gfpgan) | Practical face restoration algorithm for *old photos* or *AI-generated faces* (for larger images) | 395 |
| [usamaehsan/flux-multi-controlnet](https://replicate.com/usamaehsan/flux-multi-controlnet) | 8-step-lora-and-canny-controlnet > more are coming soon | 388 |
| [rmokady/clip_prefix_caption](https://replicate.com/rmokady/clip_prefix_caption) | Simple image captioning model using CLIP and GPT-2 | 388 |
| [lucataco/dreamshaper-xl-turbo](https://replicate.com/lucataco/dreamshaper-xl-turbo) | DreamShaper is a general purpose SD model that aims at doing everything well, photos, art, anime, manga. It's designed to match Midjourney and DALL-E. | 373 |
| [soykertje/spleeter](https://replicate.com/soykertje/spleeter) | Spleeter is Deezer source separation library with pretrained models written in Python and uses Tensorflow. | 361 |
| [andreasjansson/illusion](https://replicate.com/andreasjansson/illusion) | Monster Labs' control_v1p_sd15_qrcode_monster ControlNet on top of SD 1.5 | 348 |
| [google-research/maxim](https://replicate.com/google-research/maxim) | Multi-Axis MLP for Image Processing | 347 |
| [lucataco/moondream2](https://replicate.com/lucataco/moondream2) | moondream2 is a small vision language model designed to run efficiently on edge devices | 340 |
| [okaris/live-portrait](https://replicate.com/okaris/live-portrait) | null | 323 |
| [fofr/illusions](https://replicate.com/fofr/illusions) | Create illusions with img2img and masking support | 323 |
| [ali-vilab/i2vgen-xl](https://replicate.com/ali-vilab/i2vgen-xl) | RESEARCH/NON-COMMERCIAL USE ONLY: High-Quality Image-to-Video Synthesis via Cascaded Diffusion Models | 313 |
| [batouresearch/open-dalle-1.1-lora](https://replicate.com/batouresearch/open-dalle-1.1-lora) | Better than SDXL at both prompt adherence and image quality, by dataautogpt3 | 313 |
| [orpatashnik/styleclip](https://replicate.com/orpatashnik/styleclip) | Text-Driven Manipulation of StyleGAN Imagery | 305 |
| [yxzwayne/bge-reranker-v2-m3](https://replicate.com/yxzwayne/bge-reranker-v2-m3) | Newest balance-striking reranker model from BAAI. Outputs rank scores for query-doc pairs. FP16 inference enabled. | 304 |
| [lucataco/gemma2-9b-it](https://replicate.com/lucataco/gemma2-9b-it) | Google's Gemma2 9b instruct model | 302 |
| [wglodell/cog-whisperx-withprompt](https://replicate.com/wglodell/cog-whisperx-withprompt) | WhisperX transcription with inital_prompt | 300 |
| [zsxkib/aura-sr-v2](https://replicate.com/zsxkib/aura-sr-v2) | AuraSR v2: Second-gen GAN-based Super-Resolution for real-world applications | 290 |
| [prompthero/dreamshaper](https://replicate.com/prompthero/dreamshaper) | Generate a new image given any input text with Dreamshaper v7 | 278 |
| [riffusion/riffusion](https://replicate.com/riffusion/riffusion) | Stable diffusion for real-time music generation | 277 |
| [adirik/styletts2](https://replicate.com/adirik/styletts2) | Generates speech from text | 276 |
| [cjwbw/bigcolor](https://replicate.com/cjwbw/bigcolor) | Colorization using a Generative Color Prior for Natural Images | 269 |
| [mikeei/dolphin-2.9-llama3-70b-gguf](https://replicate.com/mikeei/dolphin-2.9-llama3-70b-gguf) | Dolphin is uncensored. I have filtered the dataset to remove alignment and bias. This makes the model more compliant. | 268 |
| [lucataco/hyper-flux-16step](https://replicate.com/lucataco/hyper-flux-16step) | Hyper FLUX 16-step by ByteDance | 267 |
| [google-research/frame-interpolation](https://replicate.com/google-research/frame-interpolation) | Frame Interpolation for Large Scene Motion | 265 |
| [lucataco/animate-diff](https://replicate.com/lucataco/animate-diff) | Animate Your Personalized Text-to-Image Diffusion Models | 260 |
| [cjwbw/cogvlm](https://replicate.com/cjwbw/cogvlm) | powerful open-source visual language model | 256 |
| [jagilley/controlnet-hed](https://replicate.com/jagilley/controlnet-hed) | Modify images using HED maps | 249 |
| [lambdal/stable-diffusion-image-variation](https://replicate.com/lambdal/stable-diffusion-image-variation) | Image Variations with Stable Diffusion | 246 |
| [andreasjansson/stable-diffusion-inpainting](https://replicate.com/andreasjansson/stable-diffusion-inpainting) | Inpainting using RunwayML's stable-diffusion-inpainting checkpoint | 233 |
| [fewjative/ultimate-sd-upscale](https://replicate.com/fewjative/ultimate-sd-upscale) | Ultimate SD Upscale with ControlNet Tile | 231 |
| [google-deepmind/gemma-7b-it](https://replicate.com/google-deepmind/gemma-7b-it) | 7B instruct version of Google‚Äôs Gemma model | 227 |
| [megvii-research/nafnet](https://replicate.com/megvii-research/nafnet) | Nonlinear Activation Free Network for Image Restoration | 224 |
| [cjwbw/stable-diffusion-v2-inpainting](https://replicate.com/cjwbw/stable-diffusion-v2-inpainting) | stable-diffusion-v2-inpainting | 218 |
| [samsa-ai/flux-childbook-illustration](https://replicate.com/samsa-ai/flux-childbook-illustration) | Flux Lora, use "in the style of TOK" in your prompt as trigger | 217 |
| [cjwbw/dreamshaper](https://replicate.com/cjwbw/dreamshaper) | Dream Shaper stable diffusion | 216 |
| [01-ai/yi-34b-chat](https://replicate.com/01-ai/yi-34b-chat) | The Yi series models are large language models trained from scratch by developers at 01.AI. | 212 |
| [awerks/neon-tts](https://replicate.com/awerks/neon-tts) | NeonAI Coqui AI TTS Plugin. | 210 |
| [lucataco/sdxl-lightning-multi-controlnet](https://replicate.com/lucataco/sdxl-lightning-multi-controlnet) | SDXL lightning mult-controlnet, img2img & inpainting | 209 |
| [krthr/clip-embeddings](https://replicate.com/krthr/clip-embeddings) | Generate CLIP (clip-vit-large-patch14) text & image embeddings | 205 |
| [fofr/tooncrafter](https://replicate.com/fofr/tooncrafter) | Create videos from illustrated input images | 203 |
| [yorickvp/llava-v1.6-mistral-7b](https://replicate.com/yorickvp/llava-v1.6-mistral-7b) | LLaVA v1.6: Large Language and Vision Assistant (Mistral-7B) | 203 |
| [konieshadow/fooocus-api-realistic](https://replicate.com/konieshadow/fooocus-api-realistic) | Third party Fooocus replicate model with preset 'realistic' | 203 |
| [adirik/realvisxl-v3.0-turbo](https://replicate.com/adirik/realvisxl-v3.0-turbo) | Photorealism with RealVisXL V3.0 Turbo based on SDXL | 201 |
| [hvision-nku/storydiffusion](https://replicate.com/hvision-nku/storydiffusion) | Consistent Self-Attention for Long-Range Image and Video Generation | 200 |
| [catacolabs/cartoonify](https://replicate.com/catacolabs/cartoonify) | Turn your image into a cartoon | 199 |
| [lucataco/hotshot-xl](https://replicate.com/lucataco/hotshot-xl) | üòä Hotshot-XL is an AI text-to-GIF model trained to work alongside Stable Diffusion XL | 198 |
| [asiryan/absolutereality-v1.8.1](https://replicate.com/asiryan/absolutereality-v1.8.1) | AbsoluteReality V1.8.1 Model (Text2Img, Img2Img and Inpainting) | 196 |
| [cjwbw/sadtalker](https://replicate.com/cjwbw/sadtalker) | Stylized Audio-Driven Single Image Talking Face Animation | 195 |
| [batouresearch/sdxl-outpainting-lora](https://replicate.com/batouresearch/sdxl-outpainting-lora) | An improved outpainting model that supports LoRA urls. This model uses PatchMatch to improve the mask quality. | 185 |
| [christophy/stable-video-diffusion](https://replicate.com/christophy/stable-video-diffusion) | stable-video-diffusion | 185 |
| [cjwbw/demucs](https://replicate.com/cjwbw/demucs) | Demucs Music Source Separation | 184 |
| [lucataco/sdxl](https://replicate.com/lucataco/sdxl) | SDXL v1.0 - A text-to-image generative AI model that creates beautiful images | 181 |
| [prompthero/lookbook](https://replicate.com/prompthero/lookbook) | Fashion Diffusion by Dreamshot | 179 |
| [lucataco/sdxl-niji-se](https://replicate.com/lucataco/sdxl-niji-se) | SDXL_Niji_Special Edition | 178 |
| [cloversid099/deepfake](https://replicate.com/cloversid099/deepfake) | DeepFake AI | 177 |
| [lucataco/realistic-vision-v5](https://replicate.com/lucataco/realistic-vision-v5) | Realistic Vision v5.0 with VAE | 177 |
| [fictions-ai/autocaption](https://replicate.com/fictions-ai/autocaption) | Automatically add captions to a video | 173 |
| [lucataco/sdxl-lcm](https://replicate.com/lucataco/sdxl-lcm) | Latent Consistency Model (LCM): SDXL, distills the original model into a version that requires fewer steps (4 to 8 instead of the original 25 to 50) | 165 |
| [soykertje/whisper](https://replicate.com/soykertje/whisper) | Convert speech in audio to text | 162 |
| [kyrick/prompt-parrot](https://replicate.com/kyrick/prompt-parrot) | Prompt Parrot generates text2image prompts from finetuned distilgpt2 | 159 |
| [daanelson/minigpt-4](https://replicate.com/daanelson/minigpt-4) | A model which generates text in response to an input image and prompt. | 158 |
| [lucataco/qwen-vl-chat](https://replicate.com/lucataco/qwen-vl-chat) | A multimodal LLM-based AI assistant, which is trained with alignment techniques. Qwen-VL-Chat supports more flexible interaction, such as multi-round question answering, and creative capabilities. | 158 |
| [zsxkib/blip-3](https://replicate.com/zsxkib/blip-3) | Blip 3 / XGen-MM, Answers questions about images ({blip3,xgen-mm}-phi3-mini-base-r-v1) | 157 |
| [lucataco/real-esrgan-video](https://replicate.com/lucataco/real-esrgan-video) | Real-ESRGAN Video Upscaler | 157 |
| [cdingram/face-swap](https://replicate.com/cdingram/face-swap) | Image to image face swapping | 156 |
| [lucataco/open-dalle-v1.1](https://replicate.com/lucataco/open-dalle-v1.1) | A unique fusion that showcases exceptional prompt adherence and semantic understanding, it seems to be a step above base SDXL and a step closer to DALLE-3 in terms of prompt comprehension | 156 |
| [sunfjun/stable-video-diffusion](https://replicate.com/sunfjun/stable-video-diffusion) | null | 155 |
| [heedster/realistic-vision-v5](https://replicate.com/heedster/realistic-vision-v5) | Deployment of Realistic vision v5.0 with xformers for fast inference | 155 |
| [lucataco/dreamshaper-xl-lightning](https://replicate.com/lucataco/dreamshaper-xl-lightning) | dreamshaper-xl-lightning is a Stable Diffusion model that has been fine-tuned on SDXL | 151 |
| [stability-ai/stable-diffusion-img2img](https://replicate.com/stability-ai/stable-diffusion-img2img) | Generate a new image from an input image with Stable Diffusion | 149 |
| [nandycc/sdxl-app-icons](https://replicate.com/nandycc/sdxl-app-icons) | Fine tuned to generate awesome app icons, by aistartupkit.com | 148 |
| [zsxkib/clip-age-predictor](https://replicate.com/zsxkib/clip-age-predictor) | Age prediction using CLIP - Patched version of `https://replicate.com/andreasjansson/clip-age-predictor` that works with the new version of cog! | 148 |
| [zsxkib/film-frame-interpolation-for-large-motion](https://replicate.com/zsxkib/film-frame-interpolation-for-large-motion) | FILM: Frame Interpolation for Large Motion, In ECCV 2022. | 144 |
| [lucataco/illusion-diffusion-hq](https://replicate.com/lucataco/illusion-diffusion-hq) | Monster Labs QrCode ControlNet on top of SD Realistic Vision v5.1 | 144 |
| [daanelson/whisperx](https://replicate.com/daanelson/whisperx) | Accelerated transcription of audio using WhisperX | 135 |
| [mv-lab/swin2sr](https://replicate.com/mv-lab/swin2sr) | 3 Million Runs! AI Photorealistic Image Super-Resolution and Restoration | 133 |
| [aleksa-codes/flux-ghibsky-illustration](https://replicate.com/aleksa-codes/flux-ghibsky-illustration) | Flux LoRA, use 'GHIBSKY style' to trigger generation, creates serene and enchanting landscapes with vibrant, surreal skies and intricate, Ghibli-inspired elements reminiscent of the atmospheric beauty found in Makoto Shinkai's works | 128 |
| [cswry/seesr](https://replicate.com/cswry/seesr) | SeeSR: Towards Semantics-Aware Real-World Image Super-Resolution | 126 |
| [cjwbw/anything-v3-better-vae](https://replicate.com/cjwbw/anything-v3-better-vae) | high-quality, highly detailed anime style stable-diffusion with better VAE | 124 |
| [juliananev/frutiger-aero](https://replicate.com/juliananev/frutiger-aero) | null | 123 |
| [levelsio/disposable-camera](https://replicate.com/levelsio/disposable-camera) | Take photos with a disposable camera. Like this? Use this with yourself in it on my app PhotoAI.com | 120 |
| [hexiaochun/img2video](https://replicate.com/hexiaochun/img2video) | ËæìÂÖ•ÂõæÁâáÂíåÈü≥È¢ëÂêàÂπ∂ÂÖ≥ÈîÆÂ∏ßËßÜÈ¢ë | 118 |
| [davisbrown/flux-half-illustration](https://replicate.com/davisbrown/flux-half-illustration) | Flux lora, use "in the style of TOK" to trigger generation, creates half photo half illustrated elements | 115 |
| [batouresearch/magic-style-transfer](https://replicate.com/batouresearch/magic-style-transfer) | Restyle an image with the style of another one. I strongly suggest to upscale the results with Clarity AI | 115 |
| [saattrupdan/multilingual-e5-large-instruct](https://replicate.com/saattrupdan/multilingual-e5-large-instruct) | multilingual-e5-large-instruct: A multi-language text embedding model with custom query instructions. | 113 |
| [ai-forever/kandinsky-2](https://replicate.com/ai-forever/kandinsky-2) | text2img model trained on LAION HighRes and fine-tuned on internal datasets | 113 |
| [lucataco/flux-vlta](https://replicate.com/lucataco/flux-vlta) | A Flux finetune of an AI character named: Violeta | 111 |
| [bxclib2/flux_img2img](https://replicate.com/bxclib2/flux_img2img) | A ready to use image to image workflow of flux | 111 |
| [yoyo-nb/thin-plate-spline-motion-model](https://replicate.com/yoyo-nb/thin-plate-spline-motion-model) | Thin-Plate Spline Motion Model for Image Animation | 111 |
| [arielreplicate/deoldify_image](https://replicate.com/arielreplicate/deoldify_image) | Add colours to old images | 110 |
| [zsxkib/st-mfnet](https://replicate.com/zsxkib/st-mfnet) | üìΩÔ∏è Increase Framerate üé¨ ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation | 108 |
| [men1scus/birefnet](https://replicate.com/men1scus/birefnet) | Bilateral Reference for High-Resolution Dichotomous Image Segmentation (CAAI AIR 2024) | 107 |
| [chenxwh/openvoice](https://replicate.com/chenxwh/openvoice) | Updated to OpenVoice v2: Versatile Instant Voice Cloning | 107 |
| [lucataco/seine](https://replicate.com/lucataco/seine) | Image-to-video - SEINE: Short-to-Long Video Diffusion Model for Generative Transition and Prediction | 107 |
| [fofr/flux-mona-lisa](https://replicate.com/fofr/flux-mona-lisa) | Flux lora, use the term "MNALSA" to trigger generation | 106 |
| [prompthero/majicmix](https://replicate.com/prompthero/majicmix) | Generate a new image given any input text with majicMix realistic v6 | 105 |
| [m1guelpf/whisper-subtitles](https://replicate.com/m1guelpf/whisper-subtitles) | Generate subtitles from an audio file, using OpenAI's Whisper model. | 105 |
| [ryan5453/demucs](https://replicate.com/ryan5453/demucs) | Demucs is an audio source separator created by Facebook Research. | 104 |
